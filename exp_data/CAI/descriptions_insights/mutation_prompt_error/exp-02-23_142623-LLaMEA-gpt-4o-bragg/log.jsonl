{"id": "41a3035e-1d04-4d4a-a8b1-411b951c81af", "solution": "import numpy as np\n\nclass AdaptiveNeighborhoodDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]\n\n# Example usage:\n# optimizer = AdaptiveNeighborhoodDifferentialEvolution(budget=10000, dim=5)\n# best_solution, best_value = optimizer(func)", "name": "AdaptiveNeighborhoodDifferentialEvolution", "description": "The algorithm combines differential evolution with adaptive neighborhood search to dynamically balance exploration and exploitation in black box optimization.", "configspace": "", "generation": 0, "fitness": 0.7471715449825793, "feedback": "The algorithm AdaptiveNeighborhoodDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.747 with standard deviation 0.019. And the mean value of best solutions found was 0.203 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.728996554690173, 0.7386386364994106, 0.7738794437581542], "final_y": [0.19507421023168314, 0.2099054024599164, 0.202548121735438]}, "mutation_prompt": null}
{"id": "7a8dca50-f1c4-42a6-8864-f3fb278b3d9b", "solution": "import numpy as np\n\nclass AdaptiveNeighborhoodDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                diversity_metric = np.std(population, axis=0).mean()  # Calculate diversity\n                self.CR = max(0.1, min(0.9, 1 - diversity_metric))  # Adjust CR based on diversity\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]\n\n# Example usage:\n# optimizer = AdaptiveNeighborhoodDifferentialEvolution(budget=10000, dim=5)\n# best_solution, best_value = optimizer(func)", "name": "AdaptiveNeighborhoodDifferentialEvolution", "description": "The algorithm enhances the balance between exploration and exploitation by dynamically adjusting crossover probability based on population diversity metrics.", "configspace": "", "generation": 1, "fitness": 0.6741854795185156, "feedback": "The algorithm AdaptiveNeighborhoodDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.674 with standard deviation 0.031. And the mean value of best solutions found was 0.222 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "41a3035e-1d04-4d4a-a8b1-411b951c81af", "metadata": {"aucs": [0.63082622245257, 0.7038925156685631, 0.6878377004344135], "final_y": [0.2567989223028254, 0.20940229100237406, 0.20077538113164783]}, "mutation_prompt": null}
{"id": "201aea4c-31e7-42d1-921e-d21af1df88bb", "solution": "import numpy as np\n\nclass AdaptiveNeighborhoodDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            variance = np.var(population, axis=0)  # Calculate variance of the population\n            self.CR = 1.0 - np.mean(variance)  # Update CR based on variance\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]\n\n# Example usage:\n# optimizer = AdaptiveNeighborhoodDifferentialEvolution(budget=10000, dim=5)\n# best_solution, best_value = optimizer(func)", "name": "AdaptiveNeighborhoodDifferentialEvolution", "description": "The algorithm enhances diversity by dynamically adjusting the crossover probability (CR) based on the variance of the population to improve exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.49515907996067376, "feedback": "The algorithm AdaptiveNeighborhoodDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.495 with standard deviation 0.005. And the mean value of best solutions found was 0.409 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "41a3035e-1d04-4d4a-a8b1-411b951c81af", "metadata": {"aucs": [0.49666061503708203, 0.4887423048434897, 0.5000743200014495], "final_y": [0.4073425911909888, 0.41379549904142665, 0.4051421831226424]}, "mutation_prompt": null}
{"id": "7b420c6c-28d2-4ecd-aef8-c56bc35cdf91", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.success_rate_threshold = 0.2\n        self.adaptation_factor = 0.1\n\n    def adapt_parameters(self, success_rate):\n        if success_rate < self.success_rate_threshold:\n            self.F = min(1.0, self.F + self.adaptation_factor)\n            self.CR = max(0.0, self.CR - self.adaptation_factor)\n        else:\n            self.F = max(0.1, self.F - self.adaptation_factor)\n            self.CR = min(1.0, self.CR + self.adaptation_factor)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        success_count = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    success_count += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = success_count / self.population_size\n            self.adapt_parameters(success_rate)\n            success_count = 0\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]\n\n# Example usage:\n# optimizer = EnhancedAdaptiveDifferentialEvolution(budget=10000, dim=5)\n# best_solution, best_value = optimizer(func)", "name": "EnhancedAdaptiveDifferentialEvolution", "description": "An improved Adaptive Neighborhood Differential Evolution algorithm incorporating dynamic adaptation of control parameters F and CR based on success rates to enhance optimization performance.", "configspace": "", "generation": 3, "fitness": 0.7604665776391973, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.760 with standard deviation 0.049. And the mean value of best solutions found was 0.236 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "41a3035e-1d04-4d4a-a8b1-411b951c81af", "metadata": {"aucs": [0.8095838887059088, 0.6931709713496301, 0.7786448728620528], "final_y": [0.21837048262717962, 0.2690474069583101, 0.22171215255777688]}, "mutation_prompt": null}
{"id": "bcb44e58-9999-49fd-b1c0-bab0839f057f", "solution": "import numpy as np\n\nclass DynamicOrthogonalDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.success_rate_threshold = 0.2\n        self.adaptation_factor = 0.1\n        self.orthogonal_factor = 0.2\n\n    def adapt_parameters(self, success_rate):\n        if success_rate < self.success_rate_threshold:\n            self.F = min(1.0, self.F + self.adaptation_factor)\n            self.CR = max(0.0, self.CR - self.adaptation_factor)\n        else:\n            self.F = max(0.1, self.F - self.adaptation_factor)\n            self.CR = min(1.0, self.CR + self.adaptation_factor)\n\n    def orthogonal_crossover(self, base, mutant):\n        orthogonal_vector = np.random.uniform(-1, 1, self.dim) * self.orthogonal_factor\n        return np.clip(mutant + orthogonal_vector * (base - mutant), 0, 1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        success_count = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                orthogonal_mutant = self.orthogonal_crossover(population[i], mutant)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, orthogonal_mutant, population[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    success_count += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = success_count / self.population_size\n            self.adapt_parameters(success_rate)\n            success_count = 0\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "DynamicOrthogonalDifferentialEvolution", "description": "Enhanced Differential Evolution with Dynamic Orthogonal Crossover (DODE) incorporating orthogonal crossover operation to improve exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.5000239947022068, "feedback": "The algorithm DynamicOrthogonalDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.500 with standard deviation 0.009. And the mean value of best solutions found was 0.403 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "7b420c6c-28d2-4ecd-aef8-c56bc35cdf91", "metadata": {"aucs": [0.5112553592616814, 0.4887423048434897, 0.5000743200014495], "final_y": [0.3915430875916104, 0.41379549904142665, 0.4051421831226424]}, "mutation_prompt": null}
{"id": "4a1d4c14-0243-4409-b82a-a9c075a55fd2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.success_rate_threshold = 0.2\n        self.adaptation_factor = 0.1\n\n    def adapt_parameters(self, success_rate):\n        if success_rate < self.success_rate_threshold:\n            self.F = min(1.0, self.F + self.adaptation_factor)\n            self.CR = max(0.0, self.CR - self.adaptation_factor)\n            self.population_size = max(4, int(self.initial_population_size / 1.5))  # Adjust population\n        else:\n            self.F = max(0.1, self.F - self.adaptation_factor)\n            self.CR = min(1.0, self.CR + self.adaptation_factor)\n            self.population_size = min(self.initial_population_size, int(self.initial_population_size * 1.5))  # Adjust\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        success_count = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    success_count += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = success_count / self.population_size\n            self.adapt_parameters(success_rate)\n            success_count = 0\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]\n\n# Example usage:\n# optimizer = EnhancedAdaptiveDifferentialEvolution(budget=10000, dim=5)\n# best_solution, best_value = optimizer(func)", "name": "EnhancedAdaptiveDifferentialEvolution", "description": "EnhancedAdaptiveDifferentialEvolution with a dynamic population size adjustment based on success rate for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.7604665776391973, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.760 with standard deviation 0.049. And the mean value of best solutions found was 0.236 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "7b420c6c-28d2-4ecd-aef8-c56bc35cdf91", "metadata": {"aucs": [0.8095838887059088, 0.6931709713496301, 0.7786448728620528], "final_y": [0.21837048262717962, 0.2690474069583101, 0.22171215255777688]}, "mutation_prompt": null}
{"id": "33f57669-4af7-46b1-b6b4-ff17e80c1048", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.alpha = 0.75  # Exploration weight\n        self.beta = 0.25   # Exploitation weight\n        self.gamma = 0.9   # Inertia weight\n        self.best_global_position = None\n        self.best_global_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocity[i] = (\n                    self.gamma * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (self.best_global_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_position, self.best_global_value\n\n# Example usage:\n# optimizer = QuantumInspiredParticleSwarmOptimization(budget=10000, dim=5)\n# best_solution, best_value = optimizer(func)", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Quantum-inspired Particle Swarm Optimization leverages quantum behaviors and probabilistic decision-making to dynamically explore and exploit the search space for global optimization.", "configspace": "", "generation": 6, "fitness": 0.86490157952691, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.020. And the mean value of best solutions found was 0.202 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "7b420c6c-28d2-4ecd-aef8-c56bc35cdf91", "metadata": {"aucs": [0.8500518988583936, 0.8927021242250787, 0.8519507154972576], "final_y": [0.20604257273216975, 0.19114341050944006, 0.2074445107738513]}, "mutation_prompt": null}
{"id": "59d38b57-483f-476e-8686-817ce2016f66", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.alpha = 0.75  # Exploration weight\n        self.beta = 0.25   # Exploitation weight\n        self.gamma = 0.9   # Inertia weight\n        self.best_global_position = None\n        self.best_global_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        while evaluations < self.budget:\n            adaptive_beta = self.beta + 0.1 * (evaluations / self.budget)  # Adaptive exploitation\n            for i in range(self.population_size):\n                velocity[i] = (\n                    self.gamma * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    adaptive_beta * np.random.rand(self.dim) * (self.best_global_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_position, self.best_global_value", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-inspired Particle Swarm Optimization with adaptive exploration and exploitation balance for improved global convergence.", "configspace": "", "generation": 7, "fitness": 0.8620725577903449, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.016. And the mean value of best solutions found was 0.203 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "33f57669-4af7-46b1-b6b4-ff17e80c1048", "metadata": {"aucs": [0.849316102222244, 0.8848904354669845, 0.8520111356818058], "final_y": [0.20644948308537325, 0.19421415522093444, 0.20747127244425712]}, "mutation_prompt": null}
{"id": "b74aaffc-4055-4892-8d12-02ca17b73148", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.alpha = 0.75  # Exploration weight\n        self.beta = 0.25   # Exploitation weight\n        self.gamma = 0.9   # Inertia weight\n        self.best_global_position = None\n        self.best_global_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Adaptive parameter tuning\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                velocity[i] = (\n                    self.gamma * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (self.best_global_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_position, self.best_global_value", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-inspired Particle Swarm Optimization with adaptive parameter tuning to improve convergence speed and solution quality.", "configspace": "", "generation": 8, "fitness": 0.8791667806745003, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.016. And the mean value of best solutions found was 0.192 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "33f57669-4af7-46b1-b6b4-ff17e80c1048", "metadata": {"aucs": [0.8892046697412024, 0.8566221207333024, 0.8916735515489962], "final_y": [0.18926528108265783, 0.19541757500229207, 0.18982316650726638]}, "mutation_prompt": null}
{"id": "845d513d-d08a-4858-ab9b-868cbbd6a7b3", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.alpha = 0.75  # Exploration weight\n        self.beta = 0.25   # Exploitation weight\n        self.gamma = 0.9   # Inertia weight\n        self.best_global_position = None\n        self.best_global_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Adaptive parameter tuning\n                self.alpha = 0.6 + 0.4 * np.random.rand()  # Changed line\n                self.beta = 0.4 - 0.4 * np.random.rand()   # Changed line\n                velocity[i] = (\n                    self.gamma * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (self.best_global_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_position, self.best_global_value", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Slightly modified adaptive parameter tuning in Quantum-inspired Particle Swarm Optimization to enhance convergence speed and solution quality.", "configspace": "", "generation": 9, "fitness": 0.8336467952580899, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.074. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "b74aaffc-4055-4892-8d12-02ca17b73148", "metadata": {"aucs": [0.8390438065708087, 0.7410384640735672, 0.9208581151298939], "final_y": [0.20862160237814087, 0.2518568943852627, 0.17565882336493932]}, "mutation_prompt": null}
{"id": "c992f6c2-e88b-4867-af31-66866e48a79e", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.alpha = 0.75  # Exploration weight\n        self.beta = 0.25   # Exploitation weight\n        self.gamma = 0.9   # Inertia weight\n        self.best_global_position = None\n        self.best_global_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4  # New: Dynamic inertia weight range\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget)  # New: Update inertia weight\n            for i in range(self.population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                velocity[i] = (\n                    omega * velocity[i] +  # Changed: from self.gamma to omega\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (self.best_global_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_position, self.best_global_value", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Improved Quantum-inspired Particle Swarm Optimization by incorporating a dynamic velocity update mechanism to enhance exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8823226767443973, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.041. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b74aaffc-4055-4892-8d12-02ca17b73148", "metadata": {"aucs": [0.9079121314049204, 0.8246971100167525, 0.9143587888115194], "final_y": [0.17393297913909966, 0.1840627163433739, 0.17470440629045925]}, "mutation_prompt": null}
{"id": "c2fa6b02-54d6-49c6-99cd-ea9b2f4927cc", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.gamma = 0.9\n        self.best_global_position = None\n        self.best_global_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget)\n            diversity = np.std(personal_best_positions, axis=0)  # New: Calculate diversity\n            for i in range(self.population_size):\n                learning_factor = np.clip(1 - diversity[i] / (ub - lb), 0.1, 0.9)  # New: Adaptive learning factor\n                self.alpha = learning_factor * np.random.rand()\n                self.beta = (1 - learning_factor) * np.random.rand()\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (self.best_global_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_position, self.best_global_value", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-inspired Particle Swarm Optimization with adaptive learning factors and diversity-based local search to improve convergence and solution quality.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "c992f6c2-e88b-4867-af31-66866e48a79e", "metadata": {}, "mutation_prompt": null}
{"id": "06694b3d-871a-4ceb-841a-3bf372a7999c", "solution": "import numpy as np\n\nclass AntColonyGradientBasedOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_ants = 10 * self.dim\n        self.pheromone = 0.1  # Initial pheromone strength\n        self.evaporation_rate = 0.1  # Pheromone evaporation rate\n        self.best_position = None\n        self.best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.num_ants, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness_values = np.array([func(pos) for pos in positions])\n            evaluations += self.num_ants\n\n            if np.min(fitness_values) < self.best_value:\n                self.best_value = np.min(fitness_values)\n                self.best_position = positions[np.argmin(fitness_values)]\n\n            # Apply pheromone update rule\n            sorted_indices = np.argsort(fitness_values)\n            for rank, idx in enumerate(sorted_indices):\n                reinforcement = (self.num_ants - rank) / self.num_ants\n                for d in range(self.dim):\n                    delta = np.random.normal(0, self.pheromone)\n                    positions[idx][d] += reinforcement * delta\n                    positions[idx][d] = np.clip(positions[idx][d], lb[d], ub[d])\n\n            # Evaporate old pheromone\n            self.pheromone *= (1 - self.evaporation_rate)\n\n            # Adaptive gradient descent step\n            for i in range(self.num_ants):\n                gradient = (positions[i] - self.best_position) / np.linalg.norm(positions[i] - self.best_position)\n                step_size = self.pheromone * np.random.rand()\n                positions[i] = np.clip(positions[i] - step_size * gradient, lb, ub)\n\n        return self.best_position, self.best_value", "name": "AntColonyGradientBasedOptimization", "description": "Novel Ant Colony Gradient-Based Optimization combines ant colony behavior with adaptive gradient descent to efficiently explore and exploit the search space.", "configspace": "", "generation": 12, "fitness": 0.4950583207652664, "feedback": "The algorithm AntColonyGradientBasedOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.495 with standard deviation 0.005. And the mean value of best solutions found was 0.409 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c992f6c2-e88b-4867-af31-66866e48a79e", "metadata": {"aucs": [0.49656023671338967, 0.4886401830797876, 0.49997454250262197], "final_y": [0.4073425911909888, 0.41379549904142665, 0.4051421831226424]}, "mutation_prompt": null}
{"id": "b9a8d015-daa1-4b35-acd5-fae350c8c3a4", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.alpha = 0.75  # Exploration weight\n        self.beta = 0.25   # Exploitation weight\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5  # New: Neighborhood size for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget) \n            for i in range(self.population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf  # New: Initialize local best value\n                local_best_position = None  # New: Initialize local best position\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False) # New: Select neighbors\n                for neighbor in neighbors:  # New: Loop to find local best\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i])  # New: Use local best\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_position, self.best_global_value", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-inspired Particle Swarm Optimization by integrating an adaptive neighborhood-based search strategy for improved convergence speed and solution quality.", "configspace": "", "generation": 13, "fitness": 0.8898588615442263, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.018. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c992f6c2-e88b-4867-af31-66866e48a79e", "metadata": {"aucs": [0.87008422884432, 0.8861603368864166, 0.9133320189019423], "final_y": [0.17503355741333926, 0.17656122310253108, 0.16996198315117395]}, "mutation_prompt": null}
{"id": "d68280e1-609f-4bd8-b7fe-1bceed30639b", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(10 * self.dim, self.budget)  # Changed: Adaptive population size\n        self.alpha = 0.75  # Exploration weight\n        self.beta = 0.25   # Exploitation weight\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5  # Neighborhood size for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget) \n            for i in range(self.population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_global_position, self.best_global_value", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-inspired Particle Swarm Optimization with adaptive population size for improved resource allocation and convergence.", "configspace": "", "generation": 14, "fitness": 0.8898588615442263, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.018. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b9a8d015-daa1-4b35-acd5-fae350c8c3a4", "metadata": {"aucs": [0.87008422884432, 0.8861603368864166, 0.9133320189019423], "final_y": [0.17503355741333926, 0.17656122310253108, 0.16996198315117395]}, "mutation_prompt": null}
{"id": "282ca1e0-769a-4788-99df-90b442df723e", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.alpha = 0.75  # Exploration weight\n        self.beta = 0.25   # Exploitation weight\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5  # Neighborhood size for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget) \n            for i in range(self.population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n            \n            elite_idx = np.argmin(personal_best_values)  # New: Identify the elite\n            population[np.random.choice(self.population_size)] = personal_best_positions[elite_idx]  # New: Introduce elitism\n\n        return self.best_global_position, self.best_global_value", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Improved Quantum-inspired Particle Swarm Optimization by incorporating inertia weight adaptation and elitism for enhanced convergence and robustness.", "configspace": "", "generation": 15, "fitness": 0.8975490384647754, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.017. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b9a8d015-daa1-4b35-acd5-fae350c8c3a4", "metadata": {"aucs": [0.8762217804623409, 0.8979194819049049, 0.9185058530270803], "final_y": [0.17048615076437867, 0.17121892626997515, 0.16724691634758926]}, "mutation_prompt": null}
{"id": "2b5ad380-59df-4cf1-9bd3-c688ee456e1b", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.alpha = 0.75  # Exploration weight\n        self.beta = 0.25   # Exploitation weight\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5  # Neighborhood size for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget) \n            self.neighborhood_size = int(3 + 2 * np.sin(evaluations * 2 * np.pi / self.budget))  # Dynamic neighborhood size\n            for i in range(self.population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n            \n            elite_idx = np.argmin(personal_best_values)  # New: Identify the elite\n            population[np.random.choice(self.population_size)] = personal_best_positions[elite_idx]  # New: Introduce elitism\n\n        return self.best_global_position, self.best_global_value", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-inspired Particle Swarm Optimization by dynamic adjustment of neighborhood size for improved exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.8737204393730705, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.038. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "282ca1e0-769a-4788-99df-90b442df723e", "metadata": {"aucs": [0.89402898164268, 0.8202020945357738, 0.9069302419407581], "final_y": [0.170791642505714, 0.17693959425275552, 0.1702934892092497]}, "mutation_prompt": null}
{"id": "d60ec40a-60df-4963-b37f-d04c6f1671ff", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.alpha = 0.75  # Exploration weight\n        self.beta = 0.25   # Exploitation weight\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5  # Neighborhood size for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget) \n            for i in range(self.population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                self.neighborhood_size = max(2, self.neighborhood_size - 1) if personal_best_values[i] < self.best_global_value else self.neighborhood_size + 1  # Change 1\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n            \n            elite_idx = np.argmin(personal_best_values)  # New: Identify the elite\n            population[np.random.choice(self.population_size)] = personal_best_positions[elite_idx]  # New: Introduce elitism\n\n        return self.best_global_position, self.best_global_value", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-inspired Particle Swarm Optimization by integrating dynamic neighborhood size adjustment based on solution quality for improved exploration-exploitation balance.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "282ca1e0-769a-4788-99df-90b442df723e", "metadata": {}, "mutation_prompt": null}
{"id": "5b4cda44-dc82-4b1f-bdb8-faa74f519025", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.alpha = 0.75  # Exploration weight\n        self.beta = 0.25   # Exploitation weight\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5  # Neighborhood size for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget) \n            self.neighborhood_size = max(1, int(5 - 4 * (evaluations / self.budget)))  # Change 1 line here\n            for i in range(self.population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n            \n            elite_idx = np.argmin(personal_best_values)  # New: Identify the elite\n            population[np.random.choice(self.population_size)] = personal_best_positions[elite_idx]  # New: Introduce elitism\n\n        return self.best_global_position, self.best_global_value", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-inspired Particle Swarm Optimization by introducing adaptive neighborhood size for dynamic exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.8905049953328622, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.016. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "282ca1e0-769a-4788-99df-90b442df723e", "metadata": {"aucs": [0.9112281112585818, 0.8867046798436734, 0.8735821948963313], "final_y": [0.1703862123560267, 0.1717756688674439, 0.17324925010258296]}, "mutation_prompt": null}
{"id": "47516690-1706-4abc-83e3-7e1f597873a2", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget)\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            # Adaptive mutation\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-inspired Particle Swarm Optimization by integrating dynamic population resizing and adaptive mutation for improved exploration-exploitation balance and convergence speed.", "configspace": "", "generation": 19, "fitness": 0.908959273934378, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "282ca1e0-769a-4788-99df-90b442df723e", "metadata": {"aucs": [0.9094685944223495, 0.896909786529658, 0.9204994408511266], "final_y": [0.16496111007373981, 0.16501931024303507, 0.16487997136527854]}, "mutation_prompt": null}
{"id": "83b5dab1-a373-4c36-8f46-e7167faa4dd6", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n        self.evolutionary_step_size = 0.1  # New step size for evolutionary strategy\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.85, 0.35  # Adjusted inertia weight range\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget)\n            for i in range(self.current_population_size):\n                self.alpha = 0.6 + 0.4 * np.random.rand()  # Adjusted alpha range\n                self.beta = 0.4 - 0.4 * np.random.rand()  # Adjusted beta range\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(3, self.current_population_size // 2)  # More aggressive resizing\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            # Guided Evolutionary Strategy\n            for i in range(self.current_population_size):\n                if np.random.rand() < 0.2 * (1 - evaluations / self.budget):  # Adjusted mutation probability\n                    new_position = personal_best_positions[i] + self.evolutionary_step_size * np.random.normal(0, 1, self.dim)\n                    new_position = np.clip(new_position, lb, ub)\n                    new_fitness = func(new_position)\n                    if new_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = new_position\n                        personal_best_values[i] = new_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Hybrid Quantum-Inspired Particle Swarm Optimization with Guided Evolutionary Strategy for improved global exploration and enhanced convergence.", "configspace": "", "generation": 20, "fitness": 0.9079704833280967, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.011. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "47516690-1706-4abc-83e3-7e1f597873a2", "metadata": {"aucs": [0.8961996484911968, 0.9054270075989204, 0.9222847938941732], "final_y": [0.166121745759227, 0.1680473773830754, 0.16520069280695837]}, "mutation_prompt": null}
{"id": "59cd045f-2b97-431c-acd6-d97195ac75a3", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        neighborhood_memory = np.copy(personal_best_positions)\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget) * (0.5 + 0.5 * np.random.rand())\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            # Adaptive mutation\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Improved Quantum-inspired Particle Swarm Optimization by introducing a dynamic inertia weight and neighborhood memory to enhance adaptability and convergence.", "configspace": "", "generation": 21, "fitness": 0.9171122679800203, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "47516690-1706-4abc-83e3-7e1f597873a2", "metadata": {"aucs": [0.9027295341335972, 0.914982059913901, 0.9336252098925627], "final_y": [0.16577779383881697, 0.16486692511479395, 0.164894409896425]}, "mutation_prompt": null}
{"id": "9f38d7f8-2c85-446c-ab70-3e9d5ce4c6cc", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        neighborhood_memory = np.copy(personal_best_positions)\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget) * (0.5 + 0.5 * np.random.rand())\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            # Adaptive mutation\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # modified line\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-inspired Particle Swarm Optimization with a strategic increase in mutation probability for better exploration.", "configspace": "", "generation": 22, "fitness": 0.9129988656138125, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "59cd045f-2b97-431c-acd6-d97195ac75a3", "metadata": {"aucs": [0.9027819569666387, 0.8984430816667247, 0.9377715582080742], "final_y": [0.16497383311093583, 0.16511763094261633, 0.16527283413314708]}, "mutation_prompt": null}
{"id": "4cf9feac-3103-405c-a7a8-7cbcab7c2c11", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        neighborhood_memory = np.copy(personal_best_positions)\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget) * (0.5 + 0.5 * np.random.rand())\n            diversity = np.std(population, axis=0).mean()  # Calculate population diversity\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                c1 = 1.5 + diversity  # Adaptive cognitive coefficient\n                c2 = 1.5 - diversity  # Adaptive social coefficient\n                velocity[i] = (\n                    omega * velocity[i] +\n                    c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    c2 * np.random.rand(self.dim) * (local_best_position - population[i])\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            # Adaptive mutation\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced adaptability in Quantum-inspired Particle Swarm Optimization by integrating adaptive cognitive and social coefficients based on the population diversity.", "configspace": "", "generation": 23, "fitness": 0.6354642217974446, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.635 with standard deviation 0.018. And the mean value of best solutions found was 0.216 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "59cd045f-2b97-431c-acd6-d97195ac75a3", "metadata": {"aucs": [0.6258935494792495, 0.6199778928442972, 0.6605212230687871], "final_y": [0.21370554315769774, 0.24246761083928747, 0.19156657806189048]}, "mutation_prompt": null}
{"id": "b16d9b16-9e91-46b0-b403-b192389af7e9", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        neighborhood_memory = np.copy(personal_best_positions)\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget) * (0.5 + 0.5 * np.random.rand())\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.1 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Added communication factor\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            # Adaptive mutation\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced adaptation in Quantum-inspired Particle Swarm Optimization by incorporating a communication factor in velocity updates.", "configspace": "", "generation": 24, "fitness": 0.9276302328204385, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "59cd045f-2b97-431c-acd6-d97195ac75a3", "metadata": {"aucs": [0.9292695882537216, 0.925789964384994, 0.9278311458226], "final_y": [0.16541138995014015, 0.1650820723782329, 0.16536165816792558]}, "mutation_prompt": null}
{"id": "2fc7b999-5207-42c5-bb58-7b8d60318575", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        neighborhood_memory = np.copy(personal_best_positions)\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * (evaluations / self.budget)\n            omega += 0.1 * np.random.rand()  # Adaptive inertia weight\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.1 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.5, self.dim)  # Reduced mutation step\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Improved adaptation in Quantum-inspired Particle Swarm Optimization by integrating adaptive inertia weight and enhanced local exploration.", "configspace": "", "generation": 25, "fitness": 0.9255046567209386, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b16d9b16-9e91-46b0-b403-b192389af7e9", "metadata": {"aucs": [0.9276241804438863, 0.9367220034398446, 0.9121677862790851], "final_y": [0.164922652452682, 0.1648721784982341, 0.16518155211122487]}, "mutation_prompt": null}
{"id": "3f966612-7278-4ae0-a3cd-00670922d229", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        neighborhood_memory = np.copy(personal_best_positions)\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 2)\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.1 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) + \n                    0.05 * (np.random.rand(self.dim) * (np.mean(population, axis=0) - population[i])) # Elite info-sharing\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Improved Exploration-Exploitation Balance in Quantum-inspired Particle Swarm Optimization by introducing an Adaptive Omega Factor and Elite Information Sharing.", "configspace": "", "generation": 26, "fitness": 0.9335299836003417, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.934 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b16d9b16-9e91-46b0-b403-b192389af7e9", "metadata": {"aucs": [0.9186162016506318, 0.938167200258238, 0.9438065488921552], "final_y": [0.16493136760082971, 0.16489886595278636, 0.16498080936755088]}, "mutation_prompt": null}
{"id": "8bece063-9bfa-4784-abd6-b4f9cfe763ca", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        neighborhood_memory = np.copy(personal_best_positions)\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 2)\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                self.neighborhood_size = max(2, int(5 * (1 - evaluations / self.budget))) # Dynamic neighborhood\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.1 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) + \n                    0.05 * (np.random.rand(self.dim) * (np.mean(population, axis=0) - population[i])) # Elite info-sharing\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget) # Increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-inspired Particle Swarm Optimization with Dynamic Neighborhood and Adaptive Mutation Rate to improve global search capability.", "configspace": "", "generation": 27, "fitness": 0.9234444083139218, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.013. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f966612-7278-4ae0-a3cd-00670922d229", "metadata": {"aucs": [0.9048226653142981, 0.9352837680692281, 0.9302267915582395], "final_y": [0.16687006678047822, 0.16556879929974833, 0.16589680939336726]}, "mutation_prompt": null}
{"id": "be55cce9-44d9-4f7d-ab71-20d10afa9b19", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        neighborhood_memory = np.copy(personal_best_positions)\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 2)\n            self.neighborhood_size = max(3, int(0.1 * self.current_population_size))  # Dynamic Neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.15 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) +  # Adaptive Elite Sharing\n                    0.05 * (np.random.rand(self.dim) * (np.mean(population, axis=0) - population[i])) \n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Improved Quantum-Inspired Particle Swarm Optimization with Dynamic Neighborhood Size and Adaptive Elite Information Sharing for enhanced convergence.", "configspace": "", "generation": 28, "fitness": 0.9365526487356197, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.937 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f966612-7278-4ae0-a3cd-00670922d229", "metadata": {"aucs": [0.9340342744382203, 0.9298601994468786, 0.9457634723217601], "final_y": [0.16601318639161633, 0.16504131877133033, 0.16530214262976006]}, "mutation_prompt": null}
{"id": "46a26f67-326d-4040-82f1-e8da17b1161e", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        neighborhood_memory = np.copy(personal_best_positions)\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 2)\n            self.neighborhood_size = max(3, int(0.1 * self.current_population_size))  # Dynamic Neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.15 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) +  # Adaptive Elite Sharing\n                    0.05 * (np.random.rand(self.dim) * (np.mean(population, axis=0) - population[i])) \n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, int(self.current_population_size * (0.9)))  # Decrease population\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.05 * (1 - evaluations / self.budget)  # Adjusted mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Integrate self-adaptive population resizing and neighborhood probability adjustments to enhance solution diversity and convergence.", "configspace": "", "generation": 29, "fitness": 0.9293750001943625, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.010. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "be55cce9-44d9-4f7d-ab71-20d10afa9b19", "metadata": {"aucs": [0.9171590341312124, 0.9306213169191254, 0.9403446495327493], "final_y": [0.17411720962976962, 0.1672633785782055, 0.1676070338728839]}, "mutation_prompt": null}
{"id": "bfc4b6e3-2ec8-490c-b11d-7d6a9176b30a", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 2)\n            self.neighborhood_size = max(3, int(0.1 * self.current_population_size))  # Adaptive Neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.15 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) +  # Adaptive Elite Sharing\n                    0.05 * (np.random.rand(self.dim) * (np.mean(personal_best_positions, axis=0) - population[i]))  # Elite-Guided Perturbation\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV2", "description": "Quantum-Inspired Particle Swarm Optimization enhanced with Adaptive Neighborhood Strategy and Elite-Guided Perturbation for improved convergence and exploration-exploitation balance.", "configspace": "", "generation": 30, "fitness": 0.9389805691581391, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be55cce9-44d9-4f7d-ab71-20d10afa9b19", "metadata": {"aucs": [0.9379344396663538, 0.92998474120714, 0.9490225266009232], "final_y": [0.16513570381868659, 0.16537874828348742, 0.1657778831250789]}, "mutation_prompt": null}
{"id": "33328378-972d-41e0-bfbb-6fe7a30b94f3", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 2)\n            self.neighborhood_size = max(3, int(0.05 * self.current_population_size))  # Dynamic Neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.1 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) +  # Reduced Elite Influence\n                    0.05 * (np.random.rand(self.dim) * (np.mean(personal_best_positions, axis=0) - population[i]))  # Elite-Guided Perturbation\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.5, self.dim)  # Reduced mutation step size\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV3", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Velocity Control and Dynamic Neighborhood Adjustment for superior exploration-exploitation synergy.", "configspace": "", "generation": 31, "fitness": 0.9302157276707143, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bfc4b6e3-2ec8-490c-b11d-7d6a9176b30a", "metadata": {"aucs": [0.9165685445502001, 0.9388924783527077, 0.9351861601092347], "final_y": [0.1653814173569178, 0.16531509265417366, 0.16528286819285398]}, "mutation_prompt": null}
{"id": "d7d24050-a2a5-4f57-9da4-a600180d6954", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 2)\n            self.neighborhood_size = max(3, int(0.1 * self.current_population_size))  # Adaptive Neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.15 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) +  # Adaptive Elite Sharing\n                    0.05 * (np.random.rand(self.dim) * (np.mean(personal_best_positions, axis=0) - population[i]))  # Elite-Guided Perturbation\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.2 * (1 - evaluations / self.budget)  # Adaptive Mutation Probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim) * (ub - lb) * 0.1  # Larger Mutation Steps\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV2", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Mutation and Improved Elite Selection for superior convergence and solution quality.  ", "configspace": "", "generation": 32, "fitness": 0.9078935861763164, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.008. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "bfc4b6e3-2ec8-490c-b11d-7d6a9176b30a", "metadata": {"aucs": [0.9085252943740981, 0.8979057814009102, 0.9172496827539409], "final_y": [0.17982984864508755, 0.16942671964110145, 0.16720122549954153]}, "mutation_prompt": null}
{"id": "026d3b03-5962-44ba-bf8e-f9db0ea26475", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 2)\n            self.neighborhood_size = max(3, int(0.15 * self.current_population_size))  # Refined Adaptive Neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.15 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) +\n                    0.05 * (np.random.rand(self.dim) * (np.mean(personal_best_positions, axis=0) - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]  # Dynamic Elite Retention\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV3", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Refined Adaptive Neighborhood and Dynamic Elite Retention for Robust Performance.", "configspace": "", "generation": 33, "fitness": 0.9449387724357584, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.006. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bfc4b6e3-2ec8-490c-b11d-7d6a9176b30a", "metadata": {"aucs": [0.9518739385573272, 0.938375574974167, 0.9445668037757811], "final_y": [0.16634326480088757, 0.16549987920738474, 0.16572511677859914]}, "mutation_prompt": null}
{"id": "a18023d5-ebc8-4bbf-843e-2629fe850178", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 2)\n            self.neighborhood_size = max(3, int(0.15 * self.current_population_size))  # Refined Adaptive Neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.15 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) +\n                    0.05 * (np.random.rand(self.dim) * (np.mean(personal_best_positions, axis=0) - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.2 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim) * np.random.uniform(0, 1)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]  # Dynamic Elite Retention\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV3", "description": "Enhance the exploration-exploitation balance by adjusting the mutation probability and incorporating a blend of normal and uniform mutations.", "configspace": "", "generation": 34, "fitness": 0.9303968878447879, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "026d3b03-5962-44ba-bf8e-f9db0ea26475", "metadata": {"aucs": [0.9220940133837255, 0.9259411592848836, 0.9431554908657549], "final_y": [0.16500177895003243, 0.1650734323144184, 0.1652292947768943]}, "mutation_prompt": null}
{"id": "041c87ac-e835-4fa9-9a7b-4d6b80f8c65e", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n        \n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 2)\n            self.neighborhood_size = max(3, int(0.15 * self.current_population_size))  \n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.5 * np.random.rand()\n                self.beta = 0.5 - 0.5 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.15 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) +\n                    0.05 * (np.random.rand(self.dim) * (np.mean(personal_best_positions, axis=0) - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n                \n                if evaluations >= self.budget:\n                    break\n\n            diversity = np.std(population, axis=0).mean()\n            mutation_prob = 0.1 * (1 - evaluations / self.budget) if diversity > self.diversity_threshold else 0.2\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]  \n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV4", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Mutation Rate and Dynamic Diversity Control for Improved Convergence.", "configspace": "", "generation": 35, "fitness": 0.9373952261100081, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.937 with standard deviation 0.007. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "026d3b03-5962-44ba-bf8e-f9db0ea26475", "metadata": {"aucs": [0.9467013449035059, 0.9302714302738532, 0.9352129031526657], "final_y": [0.1702255272862947, 0.16695324999962446, 0.1684214818629931]}, "mutation_prompt": null}
{"id": "29e95ab5-a946-4406-81e6-2239b09f0507", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.20 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Increased global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV4", "description": "Improved Quantum-Inspired Particle Swarm Optimization with Adaptive Inertia and Exploration-Exploitation Balance for Enhanced Convergence.", "configspace": "", "generation": 36, "fitness": 0.9534239601836753, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "026d3b03-5962-44ba-bf8e-f9db0ea26475", "metadata": {"aucs": [0.9564571067655666, 0.950823064941744, 0.9529917088437151], "final_y": [0.1648937523069386, 0.1649466959737771, 0.16513266689442074]}, "mutation_prompt": null}
{"id": "0b292684-250f-4ea3-89da-7f104e482ce5", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.5, self.dim)  # Refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV4", "description": "Enhanced exploration through stochastic phase adjustment and refined mutation strategy.", "configspace": "", "generation": 37, "fitness": 0.9566642224073365, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "29e95ab5-a946-4406-81e6-2239b09f0507", "metadata": {"aucs": [0.9548885587703709, 0.9558905184364207, 0.959213590015218], "final_y": [0.16486386759523575, 0.1648594342218931, 0.16487603530817807]}, "mutation_prompt": null}
{"id": "3720bdd1-9f20-4bc5-b158-540488ed02b8", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 1.5)  # Adaptive inertia modified\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3, self.dim)  # Refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV4", "description": "Enhanced convergence through adaptive inertia and dynamic mutation strategy.", "configspace": "", "generation": 38, "fitness": 0.9475825985472256, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0b292684-250f-4ea3-89da-7f104e482ce5", "metadata": {"aucs": [0.944679015217046, 0.9421995975811918, 0.9558691828434388], "final_y": [0.16485922289756816, 0.16503227751489313, 0.16489518723403296]}, "mutation_prompt": null}
{"id": "b02a03d7-09cb-4846-9690-9a94d766db04", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # More refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV4", "description": "Enhanced adaptive mutation strategy and refined neighborhood influence to improve convergence.", "configspace": "", "generation": 39, "fitness": 0.9570086098522417, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0b292684-250f-4ea3-89da-7f104e482ce5", "metadata": {"aucs": [0.9606940022488221, 0.9514662084405437, 0.9588656188673593], "final_y": [0.1648764091985685, 0.16487398224607464, 0.16490815726036112]}, "mutation_prompt": null}
{"id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.2, self.dim)  # More refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV5", "description": "Introduce self-adaptive inertia and mutation rate adjustments based on performance feedback to enhance convergence.", "configspace": "", "generation": 40, "fitness": 0.9571497811003861, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b02a03d7-09cb-4846-9690-9a94d766db04", "metadata": {"aucs": [0.960184312976294, 0.9519324248940678, 0.9593326054307965], "final_y": [0.16489172505036143, 0.16485808792144474, 0.1649065541558894]}, "mutation_prompt": null}
{"id": "ab50ed86-8301-41cf-80b6-147d9d869900", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.1 * (1 - personal_best_values[i]/self.best_global_value), self.dim)  # Dynamic mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV5", "description": "Incorporate a dynamic adjustment to mutation scale based on performance to enhance exploitation ability.", "configspace": "", "generation": 41, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {}, "mutation_prompt": null}
{"id": "25aa45f1-56c8-4e08-9dc6-e21697b97013", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.3 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Increased global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.2, self.dim)  # More refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV5", "description": "Enhance convergence by slightly increasing the global influence factor to balance local and global search.  ", "configspace": "", "generation": 42, "fitness": 0.9508283899551832, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9473553858620026, 0.9557397115028032, 0.9493900725007435], "final_y": [0.16487254903219173, 0.16487782056882538, 0.16492243761473258]}, "mutation_prompt": null}
{"id": "52ec50fd-a2c1-4c71-a387-c061745eaaaf", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, int(0.1 * self.current_population_size), replace=False)  # Dynamically adjusted neighborhood\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.2, self.dim)  # More refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Introduce adaptive local search intensification by dynamically adjusting the neighborhood size for improved convergence.", "configspace": "", "generation": 43, "fitness": 0.9386424235663599, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9354956359906905, 0.9297278848554519, 0.9507037498529372], "final_y": [0.16497809001864439, 0.16495524217862145, 0.1648791318232843]}, "mutation_prompt": null}
{"id": "f340bbe2-cbb8-4cd1-bcc0-94fc434a89ba", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        while evaluations < self.budget:\n            progress_ratio = evaluations / self.budget\n            omega = 0.9 - 0.5 * ((progress_ratio) ** 0.5)  # Adaptive inertia weight\n            dynamic_alpha = 0.5 + 0.5 * (1 - progress_ratio)  # Dynamic learning rate\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size)) \n            for i in range(self.current_population_size):\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    dynamic_alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    (0.3 - progress_ratio) * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.2 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                self.current_population_size = max(5, self.current_population_size // 2)\n                population = population[:self.current_population_size]\n                velocity = velocity[:self.current_population_size]\n                personal_best_positions = personal_best_positions[:self.current_population_size]\n                personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.1 * (1 - progress_ratio)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.1, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Introduce a dynamic learning rate and velocity control mechanism based on current progress and diversity in the solution space to enhance exploration and exploitation balance.", "configspace": "", "generation": 44, "fitness": 0.9255220098092488, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.015. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9297079918392649, 0.9059680194532355, 0.9408900181352461], "final_y": [0.16652371817421274, 0.16757146238555176, 0.16696003914057056]}, "mutation_prompt": null}
{"id": "24649a69-f955-41ea-bfe1-8dda4bf0419f", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 12 * self.dim  # Adjusted initial population size\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.65  # Adjusted alpha\n        self.beta = 0.35  # Adjusted beta\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.dynamic_neighborhood_factor = 0.3  # New dynamic neighborhood factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-0.5, 0.5, (self.current_population_size, self.dim))  # Adjusted velocity range\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.85, 0.3  # Adjusted omega\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)\n            self.neighborhood_size = max(3, int(self.dynamic_neighborhood_factor * self.current_population_size))  # Dynamic neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.4 + 0.4 * np.random.rand()  # Adjusted alpha range\n                self.beta = 0.2 + 0.2 * np.random.rand()  # Adjusted beta range\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.2 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 4) == 0:  # Adjusted frequency\n                new_population_size = max(6, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.2 * (1 - evaluations / self.budget)  # Adjusted mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.15, self.dim)  # Adjusted mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Introduce dynamic neighborhood and adaptive velocity scaling for more robust convergence in varying search spaces. ", "configspace": "", "generation": 45, "fitness": 0.9411846817933623, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.014. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.921313892803814, 0.9518618261688575, 0.9503783264074153], "final_y": [0.1695804893878865, 0.16606088786124118, 0.1655314426988772]}, "mutation_prompt": null}
{"id": "c824c2e2-7846-4312-8bec-4f5e9d7a0d7d", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.2, self.dim)  # More refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n            # Stochastic reinitialization if stagnation detected\n            if evaluations % (self.budget // 10) == 0 and np.allclose(personal_best_values, self.best_global_value, atol=1e-4):\n                population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))  # Reinitialize\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV5", "description": "Introduce stochastic reinitialization of particles when they stagnate to avoid local optima.", "configspace": "", "generation": 46, "fitness": 0.9571494722374277, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9601838731957129, 0.9519324177842999, 0.9593321257322708], "final_y": [0.16489558904102974, 0.16485824729082643, 0.1649135142108843]}, "mutation_prompt": null}
{"id": "10b3e72b-05bf-465f-825f-64354854ce02", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            diversity = np.std(population, axis=0).mean()  # Compute diversity\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                adaptive_neighborhood_size = max(4, int(self.neighborhood_size * (1 + diversity)))  # Dynamic neighborhood\n                neighbors = np.random.choice(self.current_population_size, adaptive_neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                adaptive_velocity_scale = 0.5 + 0.5 * np.random.rand()  # Adaptive velocity scaling\n                velocity[i] = (\n                    adaptive_velocity_scale * (\n                        omega * velocity[i] +\n                        self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                        self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                        0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                    )  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.2, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Enhance global exploration by introducing dynamic neighborhood size based on population diversity and adaptive velocity scaling.", "configspace": "", "generation": 47, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {}, "mutation_prompt": null}
{"id": "f5770a6e-30d5-4f09-9aba-bcf303c8b120", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.15 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.2, self.dim)  # More refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Enhance convergence through dynamic neighborhood adaptation and strategic velocity updates.", "configspace": "", "generation": 48, "fitness": 0.9538561328003391, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9556639164919083, 0.9517385424717699, 0.9541659394373391], "final_y": [0.16485956675548852, 0.16494687864278645, 0.16490485126753307]}, "mutation_prompt": null}
{"id": "dd635809-54c3-4690-9ab3-2a7f6e00a742", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.8)  # Adjusted adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.2, self.dim)  # More refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV5", "description": "Fine-tune the adaptive inertia weight calculation to enhance convergence speed and solution precision.", "configspace": "", "generation": 49, "fitness": 0.9507116072927225, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9464053240102009, 0.9537120901353657, 0.9520174077326009], "final_y": [0.16564602960529884, 0.16486024610269578, 0.16524101930405666]}, "mutation_prompt": null}
{"id": "027e4ffd-aa27-411f-a2f2-452d3d0d05bc", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            # Introduce diversity via Gaussian perturbation\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.1, self.dim)  # Smaller mutation scale for fine-tuning\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Introduce dynamic population resizing and diversity preservation via Gaussian perturbation to enhance search exploration and exploitation balance.", "configspace": "", "generation": 50, "fitness": 0.9571017469473478, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9604637495897249, 0.9519307644980279, 0.9589107267542909], "final_y": [0.16487511969765922, 0.1648569526562279, 0.16506335488828316]}, "mutation_prompt": null}
{"id": "56a89985-bc6e-4431-b9a0-143eea1e8275", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.3 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.2, self.dim)  # More refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV5", "description": "Introduce a modestly elevated global influence to improve convergence precision.", "configspace": "", "generation": 51, "fitness": 0.9508283899551832, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9473553858620026, 0.9557397115028032, 0.9493900725007435], "final_y": [0.16487254903219173, 0.16487782056882538, 0.16492243761473258]}, "mutation_prompt": null}
{"id": "9b5cbf41-b7d9-4161-b0f5-751e90d730ff", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.35 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.25 + np.random.rand() * (0.35 - 0.25)  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.25, self.dim)  # More refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV5", "description": "Introduce dynamic adaptive components for velocity and mutation strategies to improve convergence.", "configspace": "", "generation": 52, "fitness": 0.9562127357484899, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9539392138578969, 0.9650137841831454, 0.9496852092044272], "final_y": [0.1649264043786841, 0.1648817194378034, 0.16492115020395626]}, "mutation_prompt": null}
{"id": "60384a92-ee37-487b-865b-e838ddc072aa", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(3, int(0.15 * self.current_population_size))  # More dynamic neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.2, self.dim)  # More refined mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n            # Introduce diversity in elite particles\n            if np.random.rand() < 0.1:\n                diversity_step = np.random.normal(0, 0.1, self.dim)\n                population[elite_idx] = np.clip(population[elite_idx] + diversity_step, lb, ub)\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV5", "description": "Introduce dynamic neighborhood adjustment and elite diversity to enhance exploration and maintain solution diversity.", "configspace": "", "generation": 53, "fitness": 0.9439940505362748, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9447798991036274, 0.9405768483130922, 0.9466254041921051], "final_y": [0.16500489269539886, 0.16486834091653524, 0.16495263787044323]}, "mutation_prompt": null}
{"id": "029fee9f-ec6d-4f1c-8050-ef544c44633e", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5) \n            self.neighborhood_size = max(3, int(0.15 * self.current_population_size))  # Dynamically adjusted neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.1, self.dim)  # Reduced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV5", "description": "Introduce dynamic neighborhood size adjustments and improved mutation scaling based on progress feedback for enhanced exploration and convergence.", "configspace": "", "generation": 54, "fitness": 0.9505991872947467, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9512421266755019, 0.9446605981224919, 0.9558948370862462], "final_y": [0.16487407393091447, 0.1648937624990774, 0.16509870806398452]}, "mutation_prompt": null}
{"id": "15b84918-3b56-4857-a196-f7d06acc8540", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)  # Dynamically adjusted mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_idx = np.argmin(personal_best_values)\n            population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV5", "description": "Further refine mutation strategy by dynamically adjusting mutation step size based on feedback control theory for improved adaptability and convergence.", "configspace": "", "generation": 55, "fitness": 0.9570533080801272, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9601985113595591, 0.9519643418732179, 0.9589970710076048], "final_y": [0.1649263704419428, 0.16486158354438052, 0.16507887903173768]}, "mutation_prompt": null}
{"id": "e3846db4-5544-4555-95f1-91257533fbeb", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Integrate an elitist strategy by preserving multiple elite solutions and improving the mutation strategy to enhance diversity.", "configspace": "", "generation": 56, "fitness": 0.9586006740705564, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bc7707bb-789b-47a8-bd1f-6bf835acc32b", "metadata": {"aucs": [0.9607600130362365, 0.9566360596254104, 0.9584059495500222], "final_y": [0.16489135478500005, 0.16489122451902716, 0.1649599152537915]}, "mutation_prompt": null}
{"id": "c90daedd-c2e4-404d-b04e-12f0c35ea267", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            elite_change = np.std(personal_best_values[:2])  # Track change in elite solutions\n            mutation_prob = 0.15 * (1 - evaluations / self.budget) * (1 + elite_change)  # Adaptive mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Introduce adaptive mutation probability based on elite solution improvements to enhance convergence.", "configspace": "", "generation": 57, "fitness": 0.9582709109387978, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e3846db4-5544-4555-95f1-91257533fbeb", "metadata": {"aucs": [0.9590249406255239, 0.9580625922279751, 0.9577251999628941], "final_y": [0.16486942523965797, 0.16485788729656192, 0.1648733454146074]}, "mutation_prompt": null}
{"id": "43b21012-efb6-4daf-9b03-9836d9c1feda", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int((1 - evaluations / self.budget) * self.current_population_size))  # Adaptive neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Introduce an adaptive neighborhood size to dynamically balance between exploration and exploitation.", "configspace": "", "generation": 58, "fitness": 0.9476948641992783, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e3846db4-5544-4555-95f1-91257533fbeb", "metadata": {"aucs": [0.9436472361657691, 0.9386796892309557, 0.9607576672011104], "final_y": [0.16496629791858286, 0.16515776841554308, 0.16487060079617222]}, "mutation_prompt": null}
{"id": "fbfeb3e8-7abf-4216-bf7e-ff3b77d82ea8", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                scaling_factor = 0.5 + 0.5 * np.random.rand()  # Adaptive velocity scaling factor\n                velocity[i] = (\n                    omega * velocity[i] * scaling_factor +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Enhance the exploration by incorporating an adaptive velocity scaling factor to balance exploration and exploitation phases.", "configspace": "", "generation": 59, "fitness": 0.9521865161645898, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e3846db4-5544-4555-95f1-91257533fbeb", "metadata": {"aucs": [0.9469187198358969, 0.9508769915163292, 0.9587638371415433], "final_y": [0.1649036246554555, 0.1648687322589032, 0.16485760379642866]}, "mutation_prompt": null}
{"id": "c33995f3-1d8d-4eb6-987d-8f4262ae6c03", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.1 * self.current_population_size))  # Reduced neighborhood size\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.25 * (1 - evaluations / self.budget)  # Significantly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Introduces dynamic neighborhood sizes and a more impactful mutation strategy to bolster solution diversity.", "configspace": "", "generation": 60, "fitness": 0.9491776668478423, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e3846db4-5544-4555-95f1-91257533fbeb", "metadata": {"aucs": [0.9309959223074751, 0.9617931766448428, 0.9547439015912089], "final_y": [0.16488046441593152, 0.16485628529049323, 0.16491182605690768]}, "mutation_prompt": null}
{"id": "49032966-9bc1-4daa-91e4-28f1ed08c533", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4 \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.20 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Adjust the mutation probability for better exploration by making it a decaying function of evaluations. ", "configspace": "", "generation": 61, "fitness": 0.958153316519328, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e3846db4-5544-4555-95f1-91257533fbeb", "metadata": {"aucs": [0.9584969204969646, 0.955664678226275, 0.9602983508347445], "final_y": [0.16486535821389225, 0.16486641974182759, 0.16486897366653508]}, "mutation_prompt": null}
{"id": "47123b8b-c696-47b1-9c10-0f01884b8803", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Refine inertia weight decay to improve convergence speed and solution accuracy.", "configspace": "", "generation": 62, "fitness": 0.9589619009657677, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e3846db4-5544-4555-95f1-91257533fbeb", "metadata": {"aucs": [0.9608557941396046, 0.9515414307438124, 0.9644884780138862], "final_y": [0.16498045506903947, 0.16492335214976583, 0.16488169951649334]}, "mutation_prompt": null}
{"id": "3c849b66-f119-4f4a-ae92-4a9679f151b1", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.3 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Enhance the influence of the global best position by adjusting the coefficient for better convergence.", "configspace": "", "generation": 63, "fitness": 0.9521576312064935, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {"aucs": [0.9468790000821958, 0.952199322190781, 0.957394571346504], "final_y": [0.1649205060658684, 0.16496533361918997, 0.16486423890960655]}, "mutation_prompt": null}
{"id": "f1f245b1-c412-4828-b9c4-0116c047aa97", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size + 0.05 * (self.budget - evaluations)))  # Dynamic adaptation\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Introduce dynamic neighborhood size adaptation based on convergence rate to achieve better solution quality with minimal code alteration.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {}, "mutation_prompt": null}
{"id": "3f16373d-6aec-4123-8fb1-3d7c337f6608", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.3 * self.current_population_size))  # Increased neighborhood exploration\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.2 * (1 - evaluations / self.budget)  # Further increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Enhance neighborhood exploration and mutation strategy for improved convergence.", "configspace": "", "generation": 65, "fitness": 0.9587667214122636, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {"aucs": [0.9556561967204633, 0.9637549378410697, 0.9568890296752581], "final_y": [0.16489631142542738, 0.1648581741434515, 0.1649132472007443]}, "mutation_prompt": null}
{"id": "d1b44ba3-feaf-4aab-aee6-e8656f20111e", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.3 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Increased global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Slightly increase global influence to enhance exploration capability.", "configspace": "", "generation": 66, "fitness": 0.9521576312064935, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {"aucs": [0.9468790000821958, 0.952199322190781, 0.957394571346504], "final_y": [0.1649205060658684, 0.16496533361918997, 0.16486423890960655]}, "mutation_prompt": null}
{"id": "717833ea-13a5-4f9d-bd66-f36df7c89403", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.2 * (1 - evaluations / self.budget)  # Enhanced mutation probability decay\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Enhance mutation probability decay for improved exploration-exploitation balance.", "configspace": "", "generation": 67, "fitness": 0.9575576827151675, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {"aucs": [0.9592307516862213, 0.953449552238045, 0.9599927442212364], "final_y": [0.16488581730134977, 0.1648882892072997, 0.16493081198088633]}, "mutation_prompt": null}
{"id": "951eda37-8608-4edc-9a76-54a60b2dacfe", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.3 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Refine global influence in velocity update to enhance convergence precision.", "configspace": "", "generation": 68, "fitness": 0.9521576312064935, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {"aucs": [0.9468790000821958, 0.952199322190781, 0.957394571346504], "final_y": [0.1649205060658684, 0.16496533361918997, 0.16486423890960655]}, "mutation_prompt": null}
{"id": "cc664169-2c69-4c9c-8513-22f5c1070f56", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.5 * (1 - evaluations / self.budget)  # Dynamic adjustment for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Introduce dynamic beta adjustment based on iteration to improve exploration-exploitation balance.", "configspace": "", "generation": 69, "fitness": 0.9577652963512113, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {"aucs": [0.9532205421172412, 0.9609286521394088, 0.9591466947969842], "final_y": [0.16496628576605699, 0.16492001530231593, 0.16492552197783783]}, "mutation_prompt": null}
{"id": "121019cc-942f-4d72-9918-a0d1554f5262", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                velocity[i] = np.tanh(velocity[i])  # Added nonlinear velocity constraint\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Enhance velocity update by integrating a nonlinear velocity constraint for stability and efficiency improvement.", "configspace": "", "generation": 70, "fitness": 0.6507031962955827, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.651 with standard deviation 0.024. And the mean value of best solutions found was 0.260 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {"aucs": [0.6432519156755708, 0.6255548266607106, 0.6833028465504667], "final_y": [0.26450232022607156, 0.27238292727038427, 0.24449220004239414]}, "mutation_prompt": null}
{"id": "12ac1d73-6eaf-435e-a726-984391c02d6b", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.35 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Enhanced global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Enhance the global influence factor to better guide particles towards optimal solutions.", "configspace": "", "generation": 71, "fitness": 0.9538893663805502, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {"aucs": [0.9454615251207045, 0.9569728905483351, 0.9592336834726112], "final_y": [0.16503941376875042, 0.16486087394421456, 0.16488351546357638]}, "mutation_prompt": null}
{"id": "5a28cb5d-e8fb-402f-97dc-aabe8054939e", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.6)  # Modified exponent for omega calculation\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))  # Slightly increased neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  # Adjusted range for alpha\n                self.beta = 0.3 - 0.3 * np.random.rand()  # Adjusted range for beta\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))  # Adjusted global influence\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Slightly increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim)  # Enhanced mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  # Improved mutation acceptance\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:2]  # Preserve top 2 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV6", "description": "Modify omega calculation to improve convergence robustness.", "configspace": "", "generation": 72, "fitness": 0.958776831415136, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {"aucs": [0.9601788622220516, 0.9576115393089444, 0.9585400927144119], "final_y": [0.16490703713402943, 0.16486949460148503, 0.16516957588978276]}, "mutation_prompt": null}
{"id": "8d1791fa-6339-45ea-ab96-47dfc70789e1", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.1 * self.current_population_size))  # Further increased neighborhood dynamic\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()  \n                self.beta = 0.3 - 0.3 * np.random.rand() \n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) \n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget) \n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.4, self.dim) \n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:  \n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Incorporate dynamic neighborhood adjustment and adaptive elitism to enhance convergence. ", "configspace": "", "generation": 73, "fitness": 0.9504247289371112, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {"aucs": [0.9471061678818105, 0.9488777975126431, 0.9552902214168801], "final_y": [0.1651139107568489, 0.16493723905653668, 0.16487958274541392]}, "mutation_prompt": null}
{"id": "78efe9b5-1e30-4444-a279-4d7f3f9fc602", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.5, self.dim)  # Adjust mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Enhance local and global search balance using adaptive mutation and elite reinforcement.", "configspace": "", "generation": 74, "fitness": 0.9616278521132289, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "47123b8b-c696-47b1-9c10-0f01884b8803", "metadata": {"aucs": [0.9611499274857196, 0.9596195778466171, 0.9641140510073499], "final_y": [0.16492601598176737, 0.16522301429029784, 0.16502100593306557]}, "mutation_prompt": null}
{"id": "3e3392c1-d6ba-46dd-ba17-233c4f217dbf", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.15 * self.current_population_size))  # Dynamic adjustment\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.5, self.dim)  # Adjust mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                random_idx = np.random.choice(self.current_population_size, 1)  # Refined reinforcement\n                population[random_idx] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce dynamic neighborhood adjustment and refine elite solution reinforcement for enhanced convergence.", "configspace": "", "generation": 75, "fitness": 0.9565052337650647, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "78efe9b5-1e30-4444-a279-4d7f3f9fc602", "metadata": {"aucs": [0.9565019970078453, 0.9510547837235355, 0.961958920563813], "final_y": [0.1649664706751669, 0.16493191085718562, 0.16495441734687177]}, "mutation_prompt": null}
{"id": "48a35f99-f1a0-4a00-b55f-99c42b5a5a94", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.5 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Enhance adaptive mutation by incorporating fitness-aware scaling to improve solution diversity and convergence.", "configspace": "", "generation": 76, "fitness": 0.9620097194056966, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "78efe9b5-1e30-4444-a279-4d7f3f9fc602", "metadata": {"aucs": [0.96145863291978, 0.9599496675361986, 0.9646208577611113], "final_y": [0.1648778437299947, 0.1650750557739471, 0.16496052057665533]}, "mutation_prompt": null}
{"id": "dba5272d-cfd6-4de9-b913-95c7725200b2", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.1 * self.current_population_size))  # Changed from 0.2 to 0.1\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.5 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:5]  # Changed to preserve top 5 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce dynamic neighborhood size adjustment and elite preservation to improve convergence speed and solution accuracy.", "configspace": "", "generation": 77, "fitness": 0.9582342004541401, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "48a35f99-f1a0-4a00-b55f-99c42b5a5a94", "metadata": {"aucs": [0.9527092714632697, 0.9559804469653634, 0.9660128829337875], "final_y": [0.1653313447796796, 0.16510530898242093, 0.1648773817848065]}, "mutation_prompt": null}
{"id": "f5e34bbf-bce9-4c77-945e-ba7217ad61f7", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size * (1 - evaluations / self.budget)))  # Dynamic neighborhood size\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.5 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce a dynamic neighborhood size based on the current evaluation stage to enhance local exploration adaptively.", "configspace": "", "generation": 78, "fitness": 0.9606375355173359, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "48a35f99-f1a0-4a00-b55f-99c42b5a5a94", "metadata": {"aucs": [0.9584601670389378, 0.960276437231085, 0.9631760022819844], "final_y": [0.16497332616049387, 0.1649643777070573, 0.16495891367808557]}, "mutation_prompt": null}
{"id": "5dd3e8a7-4e06-4630-bae4-2cc2736f8e55", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.3 * (1 - evaluations / self.budget) * self.current_population_size))  # Adaptive neighborhood size\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.5 * (personal_best_values[i] / self.best_global_value), self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step * (ub - lb), lb, ub)  # Dynamic boundary handling in mutation\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Further optimize solution convergence by incorporating an adaptive neighborhood size and dynamic boundary handling in the mutation step.", "configspace": "", "generation": 79, "fitness": 0.9583085871622251, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "48a35f99-f1a0-4a00-b55f-99c42b5a5a94", "metadata": {"aucs": [0.9591343528190546, 0.9565873511775761, 0.9592040574900443], "final_y": [0.16488979134364135, 0.16512743494306714, 0.16496069578136596]}, "mutation_prompt": null}
{"id": "38ae8057-1935-48c4-8eb2-2ec38a74d343", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                random_factor = (1 - evaluations / self.budget) * np.random.rand(self.dim)  # New diminishing random factor\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i])) +\n                    random_factor\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.5 * (personal_best_values[i] / self.best_global_value), self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce a diminishing random factor to the velocity to enhance convergence precision.", "configspace": "", "generation": 80, "fitness": 0.9411661284985282, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.006. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "48a35f99-f1a0-4a00-b55f-99c42b5a5a94", "metadata": {"aucs": [0.937482056237701, 0.9493621439847217, 0.9366541852731619], "final_y": [0.16592351439397757, 0.16514336116351358, 0.1706078033712466]}, "mutation_prompt": null}
{"id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Enhance adaptive mutation by refining the fitness-aware scaling strategy to better exploit solution quality and improve convergence.", "configspace": "", "generation": 81, "fitness": 0.9622838398842167, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "48a35f99-f1a0-4a00-b55f-99c42b5a5a94", "metadata": {"aucs": [0.9613542338071192, 0.961136236490778, 0.9643610493547532], "final_y": [0.16488860466937239, 0.16494333615927337, 0.1649733721339256]}, "mutation_prompt": null}
{"id": "7ec92f7b-4548-4c8a-8dc0-5d0c07f4d72d", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget) * (self.best_global_value / np.min(personal_best_values))  # Adjusted mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduced dynamic adjustment of mutation probability based on current best solution to enhance exploration in challenging landscapes.", "configspace": "", "generation": 82, "fitness": 0.9622838398842167, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "metadata": {"aucs": [0.9613542338071192, 0.961136236490778, 0.9643610493547532], "final_y": [0.16488860466937239, 0.16494333615927337, 0.1649733721339256]}, "mutation_prompt": null}
{"id": "8ef7346f-561d-4ba1-b21b-952504bba969", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  \n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  \n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (self.best_global_value / np.min(personal_best_values))  \n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (personal_best_values[i] / self.best_global_value), self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  \n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV8", "description": "Introduce a dynamic mutation probability based on current performance relative to initial conditions to enhance exploration and exploitation balance.", "configspace": "", "generation": 83, "fitness": 0.9610708134452666, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "metadata": {"aucs": [0.9641384202874834, 0.9582152462317446, 0.9608587738165716], "final_y": [0.16486294786488853, 0.16487279361579044, 0.1648609899842114]}, "mutation_prompt": null}
{"id": "9d884100-f2ca-4cf3-aca8-61e7af932985", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                replace_idx = np.random.choice(self.current_population_size)  # Dynamic particle replacement\n                population[replace_idx] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce a dynamic particle replacement strategy to better explore the search space and enhance convergence.", "configspace": "", "generation": 84, "fitness": 0.9622838398842167, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "metadata": {"aucs": [0.9613542338071192, 0.961136236490778, 0.9643610493547532], "final_y": [0.16488860466937239, 0.16494333615927337, 0.1649733721339256]}, "mutation_prompt": null}
{"id": "484cd650-eaa8-4f57-ab8f-00fa58ad6a5b", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            # Modified line for adaptive inertia\n            omega = omega_start - (omega_start - omega_end) * (1 - (evaluations / self.budget) ** 2)  # Refined adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce a refined inertia update mechanism by utilizing a more dynamic scaling based on the function evaluations ratio.", "configspace": "", "generation": 85, "fitness": 0.9474687073626331, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "metadata": {"aucs": [0.9461101092000589, 0.9574566716698527, 0.938839341217988], "final_y": [0.16487281839503498, 0.16486370038673703, 0.1648578776105888]}, "mutation_prompt": null}
{"id": "6e55c21b-65b9-4417-8cbb-a3a95f03cc8f", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 1.5)  # Dynamic adjustment to inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Improve global exploration by adding dynamic adjustment to the inertia weight update strategy for faster convergence.", "configspace": "", "generation": 86, "fitness": 0.9423946296129392, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "metadata": {"aucs": [0.9389241934405488, 0.9435417636891165, 0.9447179317091522], "final_y": [0.16494052692877736, 0.16548079336942945, 0.1649422392904193]}, "mutation_prompt": null}
{"id": "ebc70ed1-d5fc-4b8b-b8ca-c3e44ed9a90b", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                velocity[i] *= np.random.uniform(0.9, 1.1)  # Adaptive velocity scaling for local exploration\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Enhance quantum-inspired PSO by refining local exploration through adaptive velocity scaling.", "configspace": "", "generation": 87, "fitness": 0.94283214608337, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.943 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "metadata": {"aucs": [0.9486157399617035, 0.9304988035877468, 0.9493818947006595], "final_y": [0.1648588643301807, 0.16490710941520204, 0.1648762881433562]}, "mutation_prompt": null}
{"id": "6813f9ba-5d97-44e5-b366-d977ec616ca2", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size + int(3 * (1 - evaluations / self.budget)), replace=False)  # Dynamic neighborhood adjustment\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce a dynamic neighborhood adjustment mechanism to enhance local exploration and adaptation.", "configspace": "", "generation": 88, "fitness": 0.9591245454240483, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "metadata": {"aucs": [0.9536868106592479, 0.9594378792061717, 0.9642489464067255], "final_y": [0.1659193312289744, 0.16531347851282352, 0.16487961834398135]}, "mutation_prompt": null}
{"id": "0d2b79a9-be85-4fd1-9afc-b5fc18468cfc", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n            \n            omega_end = 0.5 if np.min(personal_best_values) < 0.1 else omega_end  # Elite-driven parameter tuning\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce elite-driven adaptive parameter tuning to refine the convergence dynamics of the algorithm.", "configspace": "", "generation": 89, "fitness": 0.9622838398842167, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "metadata": {"aucs": [0.9613542338071192, 0.961136236490778, 0.9643610493547532], "final_y": [0.16488860466937239, 0.16494333615927337, 0.1649733721339256]}, "mutation_prompt": null}
{"id": "b54f2592-9511-4444-a8a9-06bbe4ae625e", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - (evaluations / self.budget) ** 1.1)  # Dynamic mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce dynamic mutation probability adjustment for enhanced exploration and exploitation balance.", "configspace": "", "generation": 90, "fitness": 0.9601793324148361, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "metadata": {"aucs": [0.9651808121378803, 0.9561882506252373, 0.9591689344813906], "final_y": [0.16487344574053342, 0.16491502016890014, 0.1648918005917711]}, "mutation_prompt": null}
{"id": "932f1e1b-feb9-4f01-a9a0-a5ba80cec14b", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size * (1 - evaluations / self.budget)))  # Dynamic neighborhood\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (personal_best_values[i] / self.best_global_value), self.dim)  # Fitness-aware mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce a dynamic neighborhood scaling to improve local search by reducing neighborhood size adaptively as evaluations progress.", "configspace": "", "generation": 91, "fitness": 0.9609182336472148, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "metadata": {"aucs": [0.9584540476269511, 0.9605501248563136, 0.9637505284583797], "final_y": [0.1649186621880273, 0.1649816000459614, 0.1649524768651952]}, "mutation_prompt": null}
{"id": "057d50ae-9889-45a1-87ee-f94189fed2f3", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (self.best_global_value / (personal_best_values[i] + 1e-10)), self.dim)  # Adaptive mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Enhance mutation strategy by introducing an adaptive Gaussian scale based on the current global best to improve exploration.", "configspace": "", "generation": 92, "fitness": 0.9625495553366644, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c8c22a33-16f8-4aa2-8b81-5d2ebbd9561c", "metadata": {"aucs": [0.9611078484764092, 0.9613354449027101, 0.9652053726308741], "final_y": [0.16505676559605087, 0.16492944205184334, 0.16487124312252177]}, "mutation_prompt": null}
{"id": "e1cf64d6-171d-4c8b-b445-9c4c45831a30", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        adaptive_culling_threshold = self.budget // 4  # New threshold for adaptive culling\n\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(3, int(0.1 * self.current_population_size) + 2)  # Dynamic neighborhood sizing\n\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % adaptive_culling_threshold == 0:\n                self.current_population_size = max(5, self.current_population_size // 2)  # Adaptive culling\n                population = population[:self.current_population_size]\n                velocity = velocity[:self.current_population_size]\n                personal_best_positions = personal_best_positions[:self.current_population_size]\n                personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (self.best_global_value / (personal_best_values[i] + 1e-10)), self.dim)  # Adaptive mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV8", "description": "Introduce dynamic neighborhood sizing and adaptive culling to streamline exploration and refine convergence in particle swarm optimization.", "configspace": "", "generation": 93, "fitness": 0.9482807902884433, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "057d50ae-9889-45a1-87ee-f94189fed2f3", "metadata": {"aucs": [0.9473101618251886, 0.9454466262433278, 0.9520855827968134], "final_y": [0.1653880962151798, 0.16496884415999724, 0.16518940873310872]}, "mutation_prompt": null}
{"id": "18b4b1b5-b337-4f8b-b009-259301477094", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size * (1 - evaluations / self.budget)))  # Dynamic neighborhood size\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (self.best_global_value / (personal_best_values[i] + 1e-10)), self.dim)  # Adaptive mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce a dynamic neighborhood size reduction to improve convergence speed in the latter stages of optimization.", "configspace": "", "generation": 94, "fitness": 0.9608713403242962, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "057d50ae-9889-45a1-87ee-f94189fed2f3", "metadata": {"aucs": [0.9582269574752125, 0.9607119964267935, 0.9636750670708822], "final_y": [0.1648771990322181, 0.16503008971529243, 0.1649641343834647]}, "mutation_prompt": null}
{"id": "94d5fd93-641c-4bfc-8e3e-be679d53e56d", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - (evaluations / self.budget) ** 1.5)  # Introduced decay factor\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (self.best_global_value / (personal_best_values[i] + 1e-10)), self.dim)  # Adaptive mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Introduce a decay factor to gradually reduce mutation probability over iterations for improved convergence.", "configspace": "", "generation": 95, "fitness": 0.9592703403487418, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "057d50ae-9889-45a1-87ee-f94189fed2f3", "metadata": {"aucs": [0.9641122659252571, 0.9596945900871456, 0.9540041650338229], "final_y": [0.16488097393288081, 0.16486005652459257, 0.16486221412364144]}, "mutation_prompt": null}
{"id": "ae39d257-7d26-4691-90c7-f61afe40ccea", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.4  # Changed omega_end to 0.4 for dynamic adaptation\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.7)  # Modified adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    step_size = np.random.standard_cauchy()  # Using Levy flights for mutation\n                    mutation_step = step_size * np.random.normal(0, 0.3 * (self.best_global_value / (personal_best_values[i] + 1e-10)), self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV8", "description": "Introduce a dynamic inertia weight and enhanced local refinement using levy flights to improve exploration and convergence.", "configspace": "", "generation": 96, "fitness": 0.9542921582900218, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "057d50ae-9889-45a1-87ee-f94189fed2f3", "metadata": {"aucs": [0.9541432321292305, 0.9500656760684457, 0.9586675666723892], "final_y": [0.16492226589353132, 0.16487266089876595, 0.16496114652046667]}, "mutation_prompt": null}
{"id": "e1144d90-89ad-4823-b4b7-8374d65cffe7", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)  # Linearly decrease mutation probability to zero\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (self.best_global_value / (personal_best_values[i] + 1e-10)), self.dim)  # Adaptive mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Adjust mutation probability to linearly decrease to zero for enhanced convergence stability.", "configspace": "", "generation": 97, "fitness": 0.9625495553366644, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "057d50ae-9889-45a1-87ee-f94189fed2f3", "metadata": {"aucs": [0.9611078484764092, 0.9613354449027101, 0.9652053726308741], "final_y": [0.16505676559605087, 0.16492944205184334, 0.16487124312252177]}, "mutation_prompt": null}
{"id": "f9c35cae-d34c-4d0e-923c-fc8bd7c794f0", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3  # Adjusted omega_end to 0.3 for refined inertia\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)  # Adaptive inertia\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * (local_best_position - population[i]) +\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.20 * (1 - evaluations / self.budget)  # Increased mutation probability\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (self.best_global_value / (personal_best_values[i] + 1e-10)), self.dim)  # Adaptive mutation scale\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]  # Preserve top 3 elite solutions\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV7", "description": "Increase the mutation probability to further enhance exploration and avoid premature convergence.", "configspace": "", "generation": 98, "fitness": 0.9606726509663641, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "057d50ae-9889-45a1-87ee-f94189fed2f3", "metadata": {"aucs": [0.959515296709615, 0.9591317517783461, 0.963370904411131], "final_y": [0.16488178190300795, 0.16486374674777926, 0.1648635904899598]}, "mutation_prompt": null}
{"id": "8bd30e6c-1b3c-48ea-8733-d1fefa12c41c", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.current_population_size = self.initial_population_size\n        self.alpha = 0.75\n        self.beta = 0.25\n        self.best_global_position = None\n        self.best_global_value = np.inf\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_values = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n\n        if np.min(personal_best_values) < self.best_global_value:\n            self.best_global_value = np.min(personal_best_values)\n            self.best_global_position = population[np.argmin(personal_best_values)]\n\n        omega_start, omega_end = 0.9, 0.3\n        while evaluations < self.budget:\n            omega = omega_start - (omega_start - omega_end) * ((evaluations / self.budget) ** 0.5)\n            self.neighborhood_size = max(4, int(0.2 * self.current_population_size))\n            for i in range(self.current_population_size):\n                self.alpha = 0.5 + 0.3 * np.random.rand()\n                self.beta = 0.3 - 0.3 * np.random.rand()\n                local_best_value = np.inf\n                local_best_position = None\n                neighbors = np.random.choice(self.current_population_size, self.neighborhood_size, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_values[neighbor] < local_best_value:\n                        local_best_value = personal_best_values[neighbor]\n                        local_best_position = personal_best_positions[neighbor]\n                velocity[i] = (\n                    omega * velocity[i] +\n                    self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                    self.beta * np.random.rand(self.dim) * np.power((local_best_position - population[i]), 0.75) +  # Modification here\n                    0.25 * (np.random.rand(self.dim) * (self.best_global_position - population[i]))\n                )\n                position = np.clip(population[i] + velocity[i], lb, ub)\n                fitness = func(position)\n                evaluations += 1\n\n                if fitness < personal_best_values[i]:\n                    personal_best_positions[i] = position\n                    personal_best_values[i] = fitness\n\n                if fitness < self.best_global_value:\n                    self.best_global_value = fitness\n                    self.best_global_position = position\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                new_population_size = max(5, self.current_population_size // 2)\n                if new_population_size < self.current_population_size:\n                    self.current_population_size = new_population_size\n                    population = population[:self.current_population_size]\n                    velocity = velocity[:self.current_population_size]\n                    personal_best_positions = personal_best_positions[:self.current_population_size]\n                    personal_best_values = personal_best_values[:self.current_population_size]\n\n            mutation_prob = 0.15 * (1 - evaluations / self.budget)\n            for i in range(self.current_population_size):\n                if np.random.rand() < mutation_prob:\n                    mutation_step = np.random.normal(0, 0.3 * (self.best_global_value / (personal_best_values[i] + 1e-10)), self.dim)\n                    mutated_position = np.clip(population[i] + mutation_step, lb, ub)\n                    mutated_fitness = func(mutated_position)\n                    if mutated_fitness < personal_best_values[i]:\n                        personal_best_positions[i] = mutated_position\n                        personal_best_values[i] = mutated_fitness\n\n            elite_indices = np.argsort(personal_best_values)[:3]\n            for elite_idx in elite_indices:\n                population[np.random.choice(self.current_population_size, 1)] = personal_best_positions[elite_idx]\n\n        return self.best_global_position, self.best_global_value", "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV8", "description": "Introduce perturbation in position update using power of particle's local best to improve convergence.", "configspace": "", "generation": 99, "fitness": 0.6190744825450478, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.619 with standard deviation 0.049. And the mean value of best solutions found was 0.324 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "057d50ae-9889-45a1-87ee-f94189fed2f3", "metadata": {"aucs": [0.5699767578324006, 0.6004839438794112, 0.6867627459233316], "final_y": [0.353502925191725, 0.3329515147938862, 0.28627799608339144]}, "mutation_prompt": null}
