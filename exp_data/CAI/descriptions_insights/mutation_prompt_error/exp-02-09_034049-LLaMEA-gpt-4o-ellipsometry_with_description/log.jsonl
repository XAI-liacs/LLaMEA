{"id": "7073feb8-fdb7-42f2-bb89-6f3b7eb1f197", "solution": "import numpy as np\n\nclass AdaptiveQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(size=(swarm_size, dim))\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        \n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate the function\n                score = func(self.positions[i])\n                num_evaluations += 1\n                \n                # Update personal best\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                # Quantum-inspired update for position\n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + self.c1 * phi * (self.best_positions[i] - self.positions[i]) \n                                      + self.c2 * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i]\n                \n            # Dynamic adaptation of parameters\n            self.w = 0.4 + 0.5 * (num_evaluations / self.budget)  # decreasing inertia over time\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumPSO", "description": "\"Adaptive Quantum Particle Swarm Optimization: Utilizes quantum-inspired position updates within a particle swarm framework to efficiently explore and exploit the search space, dynamically adapting based on feedback from function evaluations.\"", "configspace": "", "generation": 0, "fitness": 0.0691091192581617, "feedback": "The algorithm AdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.069 with standard deviation 0.005. And the mean value of best solutions found was 4.833 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.07591994403961355, 0.06498020279719241, 0.06642721093767912], "final_y": [4.83303721568489, 4.833041088965261, 4.833041336234214]}, "mutation_prompt": null}
{"id": "73a95757-ed87-46d4-934c-b5861ad0988d", "solution": "import numpy as np\n\nclass HybridQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(size=(swarm_size, dim))\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        \n    def levy_flight(self, lambda_val=1.5):\n        sigma = (np.math.gamma(1 + lambda_val) * np.sin(np.pi * lambda_val / 2) /\n                 (np.math.gamma((1 + lambda_val) / 2) * lambda_val * 2 ** ((lambda_val - 1) / 2))) ** (1 / lambda_val)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        return u / np.abs(v) ** (1 / lambda_val)\n        \n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                score = func(self.positions[i])\n                num_evaluations += 1\n                \n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + self.c1 * phi * (self.best_positions[i] - self.positions[i]) \n                                      + self.c2 * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i] + self.levy_flight()\n                \n            self.w = 0.4 + 0.5 * (num_evaluations / self.budget)\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "HybridQuantumPSO", "description": "Hybrid Quantum-Inspired PSO with Lévy Flight: Integrates a quantum-inspired particle swarm optimization with Lévy flight strategy to enhance exploration and exploitation dynamically, improving convergence on complex landscapes.", "configspace": "", "generation": 1, "fitness": 0.011494193098759839, "feedback": "The algorithm HybridQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.011 with standard deviation 0.014. And the mean value of best solutions found was 26.674 (0. is the best) with standard deviation 18.310.", "error": "", "parent_id": "7073feb8-fdb7-42f2-bb89-6f3b7eb1f197", "metadata": {"aucs": [0.0014302014393985374, 0.0014302014393985374, 0.03162217641748244], "final_y": [39.62096385286244, 39.62096385286244, 0.7806145041509832]}, "mutation_prompt": null}
{"id": "9915b4a3-ae26-44c1-8986-331042f2d43f", "solution": "import numpy as np\n\nclass CellularAutomataEvolution:\n    def __init__(self, budget, dim, grid_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.grid_size = grid_size\n        self.population = np.random.uniform(size=(grid_size, grid_size, dim))\n        self.scores = np.full((grid_size, grid_size), np.inf)\n        self.best_position = np.zeros(dim)\n        self.best_score = np.inf\n        self.neighborhood = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # Von Neumann neighborhood\n\n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.grid_size):\n                for j in range(self.grid_size):\n                    # Ensure positions are within bounds\n                    self.population[i, j] = np.clip(self.population[i, j], func.bounds.lb, func.bounds.ub)\n                    \n                    # Evaluate the function\n                    score = func(self.population[i, j])\n                    num_evaluations += 1\n                    self.scores[i, j] = score\n                    \n                    # Update global best\n                    if score < self.best_score:\n                        self.best_score = score\n                        self.best_position = self.population[i, j].copy()\n                    \n                    # Cellular automata-based local competition\n                    neighbors = [(i + dx, j + dy) for dx, dy in self.neighborhood]\n                    valid_neighbors = [(x % self.grid_size, y % self.grid_size) for x, y in neighbors]\n                    for x, y in valid_neighbors:\n                        if self.scores[x, y] < self.scores[i, j]:\n                            # Evolve to neighbor's position with a mutation\n                            mutation = np.random.normal(0, 0.1, size=self.dim)\n                            self.population[i, j] = self.population[x, y] + mutation\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.best_position, self.best_score", "name": "CellularAutomataEvolution", "description": "Cellular Automata-based Evolutionary Search: Combines cellular automata principles with evolutionary strategies to explore and exploit the search space through localized interactions and global competition.", "configspace": "", "generation": 2, "fitness": 0.0066850569237575375, "feedback": "The algorithm CellularAutomataEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.007 with standard deviation 0.000. And the mean value of best solutions found was 35.271 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7073feb8-fdb7-42f2-bb89-6f3b7eb1f197", "metadata": {"aucs": [0.0066850569237575375, 0.0066850569237575375, 0.0066850569237575375], "final_y": [35.2709446015432, 35.2709446015432, 35.2709446015432]}, "mutation_prompt": null}
{"id": "9ff7fb9f-9d25-41ab-a558-837ba0cce5b5", "solution": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(size=(swarm_size, dim))\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.local_search_prob = 0.1  # probability to perform local search\n\n    def adaptive_local_search(self, position, func):\n        # Perform a small local search around a given position\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        candidate = position + np.random.uniform(-step_size, step_size)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        return candidate, func(candidate)\n\n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                score = func(self.positions[i])\n                num_evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + self.c1 * phi * (self.best_positions[i] - self.positions[i]) \n                                      + self.c2 * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i]\n                \n                if np.random.rand() < self.local_search_prob:\n                    candidate_position, candidate_score = self.adaptive_local_search(self.positions[i], func)\n                    num_evaluations += 1\n                    if candidate_score < self.best_scores[i]:\n                        self.best_scores[i] = candidate_score\n                        self.best_positions[i] = candidate_position\n                        \n                    if candidate_score < self.global_best_score:\n                        self.global_best_score = candidate_score\n                        self.global_best_position = candidate_position\n\n            self.w = 0.4 + 0.5 * (num_evaluations / self.budget)\n            self.local_search_prob = 0.1 + 0.4 * (1 - num_evaluations / self.budget)\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "EnhancedQuantumPSO", "description": "Enhanced Quantum Particle Swarm Optimization with Adaptive Local Search: Integrates adaptive quantum position updates and a strategic local search mechanism to intensify exploitation around promising regions, converging more effectively on high-quality solutions.", "configspace": "", "generation": 3, "fitness": 0.18533574851146517, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.185 with standard deviation 0.006. And the mean value of best solutions found was 0.044 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": "7073feb8-fdb7-42f2-bb89-6f3b7eb1f197", "metadata": {"aucs": [0.17985671129669134, 0.19378292804838837, 0.1823676061893158], "final_y": [0.026994581453250194, 0.007430590346092324, 0.09797127391523397]}, "mutation_prompt": null}
{"id": "552c5cba-1ce2-456b-aff1-a8f15e645a91", "solution": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(size=(swarm_size, dim))\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.local_search_prob = 0.1  # probability to perform local search\n\n    def adaptive_local_search(self, position, func):\n        # Perform a small local search around a given position\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        candidate = position + np.random.uniform(-step_size, step_size)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        return candidate, func(candidate)\n\n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                score = func(self.positions[i])\n                num_evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + self.c1 * phi * (self.best_positions[i] - self.positions[i]) \n                                      + self.c2 * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i]\n                \n                if np.random.rand() < self.local_search_prob:\n                    candidate_position, candidate_score = self.adaptive_local_search(self.positions[i], func)\n                    num_evaluations += 1\n                    if candidate_score < self.best_scores[i]:\n                        self.best_scores[i] = candidate_score\n                        self.best_positions[i] = candidate_position\n                        \n                    if candidate_score < self.global_best_score:\n                        self.global_best_score = candidate_score\n                        self.global_best_position = candidate_position\n\n            self.w = np.random.uniform(0.4, 0.9)  # Stochastic inertia adaptation\n            self.local_search_prob = 0.1 + 0.4 * (1 - num_evaluations / self.budget)\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "EnhancedQuantumPSO", "description": "Enhanced Quantum Particle Swarm Optimization with Stochastic Inertia Adaptation: Introduces stochastic modulation of inertia weight to balance exploration and exploitation dynamically, enhancing convergence.", "configspace": "", "generation": 4, "fitness": 0.018126988309825842, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.018 with standard deviation 0.000. And the mean value of best solutions found was 27.380 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9ff7fb9f-9d25-41ab-a558-837ba0cce5b5", "metadata": {"aucs": [0.018126988309825842, 0.018126988309825842, 0.018126988309825842], "final_y": [27.380476579807357, 27.380476579807357, 27.380476579807357]}, "mutation_prompt": null}
{"id": "b12890ea-a89f-4176-a572-a1778bed7f26", "solution": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(size=(swarm_size, dim))\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.local_search_prob = 0.1  # probability to perform local search\n\n    def adaptive_local_search(self, position, func):\n        # Perform a small local search around a given position\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        candidate = position + np.random.uniform(-step_size, step_size)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        return candidate, func(candidate)\n\n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                score = func(self.positions[i])\n                num_evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + self.c1 * phi * (self.best_positions[i] - self.positions[i]) \n                                      + self.c2 * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i]\n                \n                if np.random.rand() < self.local_search_prob:\n                    candidate_position, candidate_score = self.adaptive_local_search(self.positions[i], func)\n                    num_evaluations += 1\n                    if candidate_score < self.best_scores[i]:\n                        self.best_scores[i] = candidate_score\n                        self.best_positions[i] = candidate_position\n                        \n                    if candidate_score < self.global_best_score:\n                        self.global_best_score = candidate_score\n                        self.global_best_position = candidate_position\n\n            self.w = 0.6 + 0.3 * (num_evaluations / self.budget)  # Adjusted inertia weight formula\n            self.local_search_prob = 0.1 + 0.4 * (1 - num_evaluations / self.budget)\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "EnhancedQuantumPSO", "description": "Slightly increased exploration by adjusting the inertia weight formula, providing a more balanced search across diverse regions.", "configspace": "", "generation": 5, "fitness": 0.21012218748327008, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.210 with standard deviation 0.020. And the mean value of best solutions found was 0.024 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9ff7fb9f-9d25-41ab-a558-837ba0cce5b5", "metadata": {"aucs": [0.2148832532327608, 0.23224353145440513, 0.18323977776264433], "final_y": [0.02476994533110616, 0.01404500423525332, 0.0345386337953758]}, "mutation_prompt": null}
{"id": "0d0709fd-be89-40be-89c2-16b8ab12b854", "solution": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(size=(swarm_size, dim))\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.local_search_prob = 0.1  # probability to perform local search\n\n    def adaptive_local_search(self, position, func):\n        # Perform a small local search around a given position\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        candidate = position + np.random.uniform(-step_size, step_size)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        return candidate, func(candidate)\n\n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                score = func(self.positions[i])\n                num_evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + self.c1 * phi * (self.best_positions[i] - self.positions[i]) \n                                      + self.c2 * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i]\n                \n                if np.random.rand() < self.local_search_prob:\n                    candidate_position, candidate_score = self.adaptive_local_search(self.positions[i], func)\n                    num_evaluations += 1\n                    if candidate_score < self.best_scores[i]:\n                        self.best_scores[i] = candidate_score\n                        self.best_positions[i] = candidate_position\n                        \n                    if candidate_score < self.global_best_score:\n                        self.global_best_score = candidate_score\n                        self.global_best_position = candidate_position\n            \n            mutation_prob = 0.05 + 0.15 * (1 - num_evaluations / self.budget)\n            if np.random.rand() < mutation_prob:\n                self.positions += np.random.normal(0, 0.1, self.positions.shape)\n                \n            self.w = 0.6 + 0.3 * (num_evaluations / self.budget)  # Adjusted inertia weight formula\n            self.local_search_prob = 0.1 + 0.4 * (1 - num_evaluations / self.budget)\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "EnhancedQuantumPSO", "description": "Increase swarm diversity by introducing a mutation strategy to escape local optima.", "configspace": "", "generation": 6, "fitness": 0.018126988309825842, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.018 with standard deviation 0.000. And the mean value of best solutions found was 27.380 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b12890ea-a89f-4176-a572-a1778bed7f26", "metadata": {"aucs": [0.018126988309825842, 0.018126988309825842, 0.018126988309825842], "final_y": [27.380476579807357, 27.380476579807357, 27.380476579807357]}, "mutation_prompt": null}
{"id": "1c2e7eb5-e18f-4618-80bc-caa70819a02a", "solution": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(size=(swarm_size, dim))\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.local_search_prob = 0.1  # probability to perform local search\n\n    def adaptive_local_search(self, position, func):\n        # Perform a small local search around a given position\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        candidate = position + np.random.uniform(-step_size, step_size)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        return candidate, func(candidate)\n\n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                score = func(self.positions[i])\n                num_evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + (self.c1 + 0.5 * num_evaluations / self.budget) * phi * (self.best_positions[i] - self.positions[i]) \n                                      + (self.c2 - 0.5 * num_evaluations / self.budget) * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i]\n                \n                if np.random.rand() < self.local_search_prob:\n                    candidate_position, candidate_score = self.adaptive_local_search(self.positions[i], func)\n                    num_evaluations += 1\n                    if candidate_score < self.best_scores[i]:\n                        self.best_scores[i] = candidate_score\n                        self.best_positions[i] = candidate_position\n                        \n                    if candidate_score < self.global_best_score:\n                        self.global_best_score = candidate_score\n                        self.global_best_position = candidate_position\n\n            self.w = 0.6 + 0.3 * (num_evaluations / self.budget)  # Adjusted inertia weight formula\n            self.local_search_prob = 0.1 + 0.4 * (1 - num_evaluations / self.budget)\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "EnhancedQuantumPSO", "description": "Introduced dynamic cognitive and social coefficients to enhance convergence rate and solution precision.", "configspace": "", "generation": 7, "fitness": 0.001610395766028394, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.002 with standard deviation 0.000. And the mean value of best solutions found was 39.463 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b12890ea-a89f-4176-a572-a1778bed7f26", "metadata": {"aucs": [0.001610395766028394, 0.001610395766028394, 0.001610395766028394], "final_y": [39.46326988953336, 39.46326988953336, 39.46326988953336]}, "mutation_prompt": null}
{"id": "3d013596-f228-4e6b-bd4e-2100ba27c2bc", "solution": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(swarm_size, dim))  # Modified initialization\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.local_search_prob = 0.1  # probability to perform local search\n\n    def adaptive_local_search(self, position, func):\n        # Perform a small local search around a given position\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        candidate = position + np.random.uniform(-step_size, step_size)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        return candidate, func(candidate)\n\n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                score = func(self.positions[i])\n                num_evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + self.c1 * phi * (self.best_positions[i] - self.positions[i]) \n                                      + self.c2 * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i]\n                \n                if np.random.rand() < self.local_search_prob:\n                    candidate_position, candidate_score = self.adaptive_local_search(self.positions[i], func)\n                    num_evaluations += 1\n                    if candidate_score < self.best_scores[i]:\n                        self.best_scores[i] = candidate_score\n                        self.best_positions[i] = candidate_position\n                        \n                    if candidate_score < self.global_best_score:\n                        self.global_best_score = candidate_score\n                        self.global_best_position = candidate_position\n\n            self.w = 0.6 + 0.4 * (num_evaluations / self.budget)  # Adjusted inertia weight formula\n            self.local_search_prob = 0.1 + 0.4 * (1 - num_evaluations / self.budget)\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "EnhancedQuantumPSO", "description": "Enhanced exploration and diversity by modifying the inertia weight formula and random particle initialization.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "b12890ea-a89f-4176-a572-a1778bed7f26", "metadata": {}, "mutation_prompt": null}
{"id": "24037872-d345-4607-8543-7dcb843b404c", "solution": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(size=(swarm_size, dim))\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.local_search_prob = 0.1  # probability to perform local search\n\n    def adaptive_local_search(self, position, func):\n        # Perform a small local search around a given position\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        candidate = position + np.random.uniform(-step_size, step_size)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        return candidate, func(candidate)\n\n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                score = func(self.positions[i])\n                num_evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + self.c1 * phi * (self.best_positions[i] - self.positions[i]) \n                                      + self.c2 * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i]\n                \n                if np.random.rand() < self.local_search_prob:\n                    candidate_position, candidate_score = self.adaptive_local_search(self.positions[i], func)\n                    num_evaluations += 1\n                    if candidate_score < self.best_scores[i]:\n                        self.best_scores[i] = candidate_score\n                        self.best_positions[i] = candidate_position\n                        \n                    if candidate_score < self.global_best_score:\n                        self.global_best_score = candidate_score\n                        self.global_best_position = candidate_position\n\n            self.w = 0.6 + 0.3 * (num_evaluations / self.budget)  # Adjusted inertia weight formula\n            self.local_search_prob = 0.1 + 0.5 * (1 - num_evaluations / self.budget)  # Slightly increased adjustment\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "EnhancedQuantumPSO", "description": "Enhanced local search adaptation with dynamic probability adjustment to improve exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.0049623361717789916, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.005 with standard deviation 0.000. And the mean value of best solutions found was 36.642 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b12890ea-a89f-4176-a572-a1778bed7f26", "metadata": {"aucs": [0.0049623361717789916, 0.0049623361717789916, 0.0049623361717789916], "final_y": [36.641674888964424, 36.641674888964424, 36.641674888964424]}, "mutation_prompt": null}
{"id": "4129ce64-9d62-4cad-9bc7-3c05f66e0d5c", "solution": "import numpy as np\n\nclass AdaptiveDE_CMA:\n    def __init__(self, budget, dim, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.population = np.random.uniform(size=(pop_size, dim))\n        self.scores = np.full(pop_size, np.inf)\n        self.best_position = None\n        self.best_score = np.inf\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.sigma = 0.3  # CMA-ES initial step size\n\n    def cma_es_step(self, x, grad):\n        return x + self.sigma * grad\n\n    def optimize(self, func):\n        num_evaluations = 0\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(self.population)\n\n            for i in range(self.pop_size):\n                indices = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = self.population[indices]\n\n                # Differential evolution mutation\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n                trial_population[i] = trial\n\n                trial_score = func(trial)\n                num_evaluations += 1\n\n                # Select the better solution\n                if trial_score < self.scores[i]:\n                    self.scores[i] = trial_score\n                    self.population[i] = trial\n\n                # Update global best\n                if trial_score < self.best_score:\n                    self.best_score = trial_score\n                    self.best_position = trial.copy()\n\n            # Apply a CMA-ES step if beneficial\n            if num_evaluations / self.budget > 0.5:\n                gradients = (trial_population - self.population) * (self.scores[:, None] - self.best_score)\n                adaptive_step = np.mean(gradients, axis=0)\n                self.population += self.cma_es_step(self.population, adaptive_step)\n                self.population = np.clip(self.population, func.bounds.lb, func.bounds.ub)\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.best_position, self.best_score", "name": "AdaptiveDE_CMA", "description": "Introduce a self-adaptive strategy combining differential evolution (DE) and covariance matrix adaptation (CMA-ES) to balance exploration and exploitation dynamically.", "configspace": "", "generation": 10, "fitness": 0.06760797234524019, "feedback": "The algorithm AdaptiveDE_CMA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.068 with standard deviation 0.028. And the mean value of best solutions found was 5.419 (0. is the best) with standard deviation 2.386.", "error": "", "parent_id": "b12890ea-a89f-4176-a572-a1778bed7f26", "metadata": {"aucs": [0.05181310963454322, 0.10679205518005752, 0.04421875222111982], "final_y": [5.705987720797507, 2.3639493582119924, 8.188142595560677]}, "mutation_prompt": null}
{"id": "4b1bdbbb-9c3f-4090-9f9f-8c1ca2417411", "solution": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(size=(swarm_size, dim))\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.local_search_prob = 0.1  # probability to perform local search\n\n    def adaptive_local_search(self, position, func):\n        # Perform a small local search around a given position\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        candidate = position + np.random.uniform(-step_size, step_size)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        return candidate, func(candidate)\n\n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                score = func(self.positions[i])\n                num_evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + self.c1 * phi * (self.best_positions[i] - self.positions[i]) \n                                      + self.c2 * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i]\n                \n                if np.random.rand() < self.local_search_prob:\n                    candidate_position, candidate_score = self.adaptive_local_search(self.positions[i], func)\n                    num_evaluations += 1\n                    if candidate_score < self.best_scores[i]:\n                        self.best_scores[i] = candidate_score\n                        self.best_positions[i] = candidate_position\n                        \n                    if candidate_score < self.global_best_score:\n                        self.global_best_score = candidate_score\n                        self.global_best_position = candidate_position\n\n            self.w = 0.6 + 0.3 * (num_evaluations / self.budget)  # Adjusted inertia weight formula\n            self.c1 = 1.2 + 0.3 * (num_evaluations / self.budget)  # Adaptive cognitive coefficient\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "EnhancedQuantumPSO", "description": "Introduced an adaptive cognitive coefficient to enhance convergence balance between exploration and exploitation.", "configspace": "", "generation": 11, "fitness": 0.005134784209539833, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.005 with standard deviation 0.000. And the mean value of best solutions found was 36.502 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b12890ea-a89f-4176-a572-a1778bed7f26", "metadata": {"aucs": [0.005134784209539833, 0.005134784209539833, 0.005134784209539833], "final_y": [36.50209601314525, 36.50209601314525, 36.50209601314525]}, "mutation_prompt": null}
{"id": "c96223e5-5629-4afe-a14b-864adbacda87", "solution": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(size=(swarm_size, dim))\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.local_search_prob = 0.1  # probability to perform local search\n\n    def adaptive_local_search(self, position, func):\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        candidate = position + np.random.uniform(-step_size, step_size)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        return candidate, func(candidate)\n\n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                score = func(self.positions[i])\n                num_evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + self.c1 * phi * (self.best_positions[i] - self.positions[i]) \n                                      + self.c2 * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i]\n                \n                if np.random.rand() < self.local_search_prob:\n                    candidate_position, candidate_score = self.adaptive_local_search(self.positions[i], func)\n                    num_evaluations += 1\n                    if candidate_score < self.best_scores[i]:\n                        self.best_scores[i] = candidate_score\n                        self.best_positions[i] = candidate_position\n                        \n                    if candidate_score < self.global_best_score:\n                        self.global_best_score = candidate_score\n                        self.global_best_position = candidate_position\n\n            self.w = 0.6 + 0.3 * (num_evaluations / self.budget)  # Adjusted inertia weight formula\n            self.local_search_prob = 0.1 + 0.4 * (1 - num_evaluations / self.budget)\n            self.c1 = 1.5 - 0.5 * np.sin(np.pi * num_evaluations / self.budget)  # Dynamic adjustment\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "EnhancedQuantumPSO", "description": "Enhanced exploration by dynamically adjusting cognitive and social coefficients with a simple line change.", "configspace": "", "generation": 12, "fitness": 0.018126988309825842, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.018 with standard deviation 0.000. And the mean value of best solutions found was 27.380 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b12890ea-a89f-4176-a572-a1778bed7f26", "metadata": {"aucs": [0.018126988309825842, 0.018126988309825842, 0.018126988309825842], "final_y": [27.380476579807357, 27.380476579807357, 27.380476579807357]}, "mutation_prompt": null}
{"id": "07af7a40-ff01-4ead-8e4d-6cf7976b0ce7", "solution": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim, swarm_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.positions = np.random.uniform(size=(swarm_size, dim))\n        self.velocities = np.random.uniform(size=(swarm_size, dim))\n        self.best_positions = self.positions.copy()\n        self.best_scores = np.full(swarm_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.local_search_prob = 0.1  # probability to perform local search\n\n    def adaptive_local_search(self, position, func):\n        # Perform a small local search around a given position\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        candidate = position + np.random.uniform(-step_size, step_size)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        return candidate, func(candidate)\n\n    def optimize(self, func):\n        num_evaluations = 0\n        \n        while num_evaluations < self.budget:\n            for i in range(self.swarm_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n                score = func(self.positions[i])\n                num_evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.positions[i].copy()\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n                \n                phi = np.random.uniform(0, 1)\n                self.velocities[i] = (self.w * self.velocities[i] \n                                      + self.c1 * phi * (self.best_positions[i] - self.positions[i]) \n                                      + self.c2 * phi * (self.global_best_position - self.positions[i]))\n                \n                self.positions[i] += self.velocities[i]\n                \n                if np.random.rand() < self.local_search_prob:\n                    candidate_position, candidate_score = self.adaptive_local_search(self.positions[i], func)\n                    num_evaluations += 1\n                    if candidate_score < self.best_scores[i]:\n                        self.best_scores[i] = candidate_score\n                        self.best_positions[i] = candidate_position\n                        \n                    if candidate_score < self.global_best_score:\n                        self.global_best_score = candidate_score\n                        self.global_best_position = candidate_position\n\n            self.w = 0.6 + 0.3 * (num_evaluations / self.budget)  # Adjusted inertia weight formula\n            self.c1, self.c2 = 1.5 + 0.5 * (num_evaluations / self.budget), 1.5 + 0.5 * (1 - num_evaluations / self.budget)\n            self.local_search_prob = 0.1 + 0.4 * (1 - num_evaluations / self.budget)\n\n    def __call__(self, func):\n        self.optimize(func)\n        return self.global_best_position, self.global_best_score", "name": "EnhancedQuantumPSO", "description": "Introduced adaptive learning rates for cognitive and social coefficients for improved balance between exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.018126988309825842, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.018 with standard deviation 0.000. And the mean value of best solutions found was 27.380 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b12890ea-a89f-4176-a572-a1778bed7f26", "metadata": {"aucs": [0.018126988309825842, 0.018126988309825842, 0.018126988309825842], "final_y": [27.380476579807357, 27.380476579807357, 27.380476579807357]}, "mutation_prompt": null}
