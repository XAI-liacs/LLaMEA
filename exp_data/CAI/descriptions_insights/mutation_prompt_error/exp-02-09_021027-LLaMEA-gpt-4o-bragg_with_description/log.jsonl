{"id": "9bf32276-4fec-42ec-bb40-1c1c9618a265", "solution": "import numpy as np\n\nclass DynamicDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * 0.5\n            self.F = np.clip(self.F, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "DynamicDifferentialEvolution", "description": "The algorithm combines differential evolution with a dynamic scaling mechanism to adaptively balance exploration and exploitation across diverse problem landscapes.", "configspace": "", "generation": 0, "fitness": 0.22975738980679772, "feedback": "The algorithm DynamicDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.230 with standard deviation 0.000. And the mean value of best solutions found was 0.211 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.22975738980679772, 0.22975738980679772, 0.22975738980679772], "final_y": [0.21080804827537625, 0.21080804827537625, 0.21080804827537625]}, "mutation_prompt": null}
{"id": "7ac96474-458b-40df-9e98-1549a5ecf6d1", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.alpha = 0.75  # Quantum parameter\n        self.beta = 0.75   # Adaptive parameter\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_fitness = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        evaluations = self.swarm_size\n\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                # Quantum-inspired update\n                local_attractor = personal_best[i] + self.alpha * (global_best - personal_best[i])\n                velocities[i] = self.beta * velocities[i] + np.random.uniform(low=lb, high=ub) * (local_attractor - swarm[i])\n                swarm[i] = np.clip(swarm[i] + velocities[i], lb, ub)\n                \n                # Evaluate new positions\n                fitness = func(swarm[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if fitness < personal_best_fitness[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_fitness[i] = fitness\n                    if fitness < global_best_fitness:\n                        global_best = swarm[i]\n                        global_best_fitness = fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive parameter update\n            self.beta = 0.5 + (np.var(personal_best_fitness) / np.mean(personal_best_fitness)) * 0.5\n            self.beta = np.clip(self.beta, 0.1, 1.0)\n\n        return global_best", "name": "AdaptiveQuantumInspiredPSO", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization (AQPSO) enhances traditional PSO with quantum mechanics principles, incorporating adaptive local attractors for superior balance between exploration and exploitation across complex problem landscapes.", "configspace": "", "generation": 1, "fitness": 0.20566155429300836, "feedback": "The algorithm AdaptiveQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.206 with standard deviation 0.000. And the mean value of best solutions found was 0.424 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9bf32276-4fec-42ec-bb40-1c1c9618a265", "metadata": {"aucs": [0.20566155429300836, 0.20566155429300836, 0.20566155429300836], "final_y": [0.4239687323344362, 0.4239687323344362, 0.4239687323344362]}, "mutation_prompt": null}
{"id": "fcc34ee2-32e9-4a9c-8bcb-0a9927218902", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm integrates a differential evolution framework with a dynamic scaling mechanism and adaptive crossover rates to balance exploration and exploitation, tailored to suit problem complexity by adjusting parameters based on population diversity.", "configspace": "", "generation": 2, "fitness": 0.23658839506997187, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.000. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9bf32276-4fec-42ec-bb40-1c1c9618a265", "metadata": {"aucs": [0.23658839506997187, 0.23658839506997187, 0.23658839506997187], "final_y": [0.1760739117138258, 0.1760739117138258, 0.1760739117138258]}, "mutation_prompt": null}
{"id": "c37a177c-056f-4704-847a-f2e29006c383", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Integrate a dynamic adaptation of the mutation factor based on the diversity of trial solutions to enhance exploration.", "configspace": "", "generation": 3, "fitness": 0.23658839506997187, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.000. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fcc34ee2-32e9-4a9c-8bcb-0a9927218902", "metadata": {"aucs": [0.23658839506997187, 0.23658839506997187, 0.23658839506997187], "final_y": [0.1760739117138258, 0.1760739117138258, 0.1760739117138258]}, "mutation_prompt": null}
{"id": "36135576-5e80-49a7-afe9-84357e1e0218", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Changed from 10 to 12\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm enhances its exploration capability by slightly increasing the population size, improving its search efficiency within the constrained budget.", "configspace": "", "generation": 4, "fitness": 0.22971619099530793, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.230 with standard deviation 0.000. And the mean value of best solutions found was 0.213 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fcc34ee2-32e9-4a9c-8bcb-0a9927218902", "metadata": {"aucs": [0.22971619099530793, 0.22971619099530793, 0.22971619099530793], "final_y": [0.21324861479656754, 0.21324861479656754, 0.21324861479656754]}, "mutation_prompt": null}
{"id": "0d12ad28-062d-48b2-b2fc-8a2866418fc8", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Modified the adaptation rate calculation mechanism to enhance exploration-exploitation balance dynamically.", "configspace": "", "generation": 5, "fitness": 0.23658839506997187, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.000. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fcc34ee2-32e9-4a9c-8bcb-0a9927218902", "metadata": {"aucs": [0.23658839506997187, 0.23658839506997187, 0.23658839506997187], "final_y": [0.1760739117138258, 0.1760739117138258, 0.1760739117138258]}, "mutation_prompt": null}
{"id": "b94f8818-e1d5-4a78-912a-ee9b63aa041d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.15  # Adjustment from 0.1 to 0.15\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm leverages Adaptive Differential Evolution with a refined adaptation rate adjustment based on current population diversity to improve exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.23287805681109242, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.000. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fcc34ee2-32e9-4a9c-8bcb-0a9927218902", "metadata": {"aucs": [0.23287805681109242, 0.23287805681109242, 0.23287805681109242], "final_y": [0.17873940660518484, 0.17873940660518484, 0.17873940660518484]}, "mutation_prompt": null}
{"id": "ac99b0e2-3491-4846-b9a2-e35042185651", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.linalg.norm(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm dynamically adapts the mutation factor and crossover rate to enhance exploration and exploitation balance, now including norm-based scaling for more robust parameter adaptation.", "configspace": "", "generation": 7, "fitness": 0.22276662794349045, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.223 with standard deviation 0.000. And the mean value of best solutions found was 0.245 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fcc34ee2-32e9-4a9c-8bcb-0a9927218902", "metadata": {"aucs": [0.22276662794349045, 0.22276662794349045, 0.22276662794349045], "final_y": [0.24543484944709637, 0.24543484944709637, 0.24543484944709637]}, "mutation_prompt": null}
{"id": "d6857cdf-495d-4ce4-ba9f-11e3fe04a8d2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic population size adjustment\n            self.population_size = int(max(5, 0.05 * self.budget / (1 + np.std(fitness))))\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhances Adaptive Differential Evolution by incorporating a focus on promising regions via fitness-based selection and introducing a dynamic population size for improved adaptability.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 338 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 338 is out of bounds for axis 0 with size 100')", "parent_id": "fcc34ee2-32e9-4a9c-8bcb-0a9927218902", "metadata": {}, "mutation_prompt": null}
{"id": "e2016601-131d-4fe4-9c2d-f8a8ed5cc3b4", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Refined dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * (self.adaptation_rate * 1.1)  # Changed line\n            \n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Integrating a differential evolution framework with a refined dynamic scaling method and adaptive crossover rates enhances solution quality by adjusting parameters more responsively to fitness variations.", "configspace": "", "generation": 9, "fitness": 0.23441440412203496, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.234 with standard deviation 0.000. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fcc34ee2-32e9-4a9c-8bcb-0a9927218902", "metadata": {"aucs": [0.23441440412203496, 0.23441440412203496, 0.23441440412203496], "final_y": [0.17644030743722494, 0.17644030743722494, 0.17644030743722494]}, "mutation_prompt": null}
{"id": "c02d89f3-896e-412d-b42f-01ea05f90fe0", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            # Dynamic population size adjustment\n            self.population_size = int(np.clip(self.population_size * (1 + 0.01 * np.mean(successful_trials)), 5, 20 * self.dim))\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic population size adjustment to better handle diverse optimization landscapes.", "configspace": "", "generation": 10, "fitness": 0.23658839506997187, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.000. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fcc34ee2-32e9-4a9c-8bcb-0a9927218902", "metadata": {"aucs": [0.23658839506997187, 0.23658839506997187, 0.23658839506997187], "final_y": [0.1760739117138258, 0.1760739117138258, 0.1760739117138258]}, "mutation_prompt": null}
{"id": "de977f7b-70b8-4991-abdc-1eb8bb30afef", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + (self.adaptation_rate + np.random.uniform(-0.01, 0.01)) * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm integrates a differential evolution framework with a dynamic scaling mechanism and adaptive crossover rates, enhanced by introducing a probabilistic element in the adaptation rate to diversify the search.", "configspace": "", "generation": 11, "fitness": 0.2343611666154043, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.234 with standard deviation 0.000. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fcc34ee2-32e9-4a9c-8bcb-0a9927218902", "metadata": {"aucs": [0.2343611666154043, 0.2343611666154043, 0.2343611666154043], "final_y": [0.17803379037833622, 0.17803379037833622, 0.17803379037833622]}, "mutation_prompt": null}
{"id": "6a68c754-86a5-49f7-882d-02c4be17cc0d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a), lb, ub)  # Modified mutation strategy\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm enhances adaptive mechanisms by dynamically adjusting the population size based on fitness diversity and improving the mutation strategy to better balance exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.23988983981234024, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fcc34ee2-32e9-4a9c-8bcb-0a9927218902", "metadata": {"aucs": [0.23988983981234024, 0.23988983981234024, 0.23988983981234024], "final_y": [0.16642418432872175, 0.16642418432872175, 0.16642418432872175]}, "mutation_prompt": null}
{"id": "88aeaab0-b68c-4a5c-848f-00c0c426c115", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a), lb, ub)  # Modified mutation strategy\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.2)  # Increased upper limit of F by 0.2\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhancing mutation step size to improve exploration capabilities by slightly increasing the scale factor F's upper limit.", "configspace": "", "generation": 13, "fitness": 0.23988983981234024, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6a68c754-86a5-49f7-882d-02c4be17cc0d", "metadata": {"aucs": [0.23988983981234024, 0.23988983981234024, 0.23988983981234024], "final_y": [0.16642418432872175, 0.16642418432872175, 0.16642418432872175]}, "mutation_prompt": null}
{"id": "f782941b-9354-4381-9b2c-2c498606978e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + 0.1 * (population[i] - a), lb, ub)  # Enhanced mutation strategy\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm uses an enhanced mutation strategy by adding a scaling factor to the difference vector, promoting better exploration while maintaining the balance with exploitation.", "configspace": "", "generation": 14, "fitness": 0.2373469748269259, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.000. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6a68c754-86a5-49f7-882d-02c4be17cc0d", "metadata": {"aucs": [0.2373469748269259, 0.2373469748269259, 0.2373469748269259], "final_y": [0.16902856761165097, 0.16902856761165097, 0.16902856761165097]}, "mutation_prompt": null}
{"id": "21ffc300-7a69-45fb-a0a7-a0685c0f7cad", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)  # Reverted mutation strategy\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm dynamically adjusts population scaling and mutation strategies with enhanced adaptive mechanisms.", "configspace": "", "generation": 15, "fitness": 0.23658839506997187, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.000. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6a68c754-86a5-49f7-882d-02c4be17cc0d", "metadata": {"aucs": [0.23658839506997187, 0.23658839506997187, 0.23658839506997187], "final_y": [0.1760739117138258, 0.1760739117138258, 0.1760739117138258]}, "mutation_prompt": null}
{"id": "7caf157a-4496-4867-89e3-8aff84c7675e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * np.log1p(b - c) + self.F * (population[i] - a), lb, ub)  # Modified mutation strategy\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.std(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance mutation strategy by using the logarithmic difference for improved exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.2282369491949543, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.228 with standard deviation 0.000. And the mean value of best solutions found was 0.255 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6a68c754-86a5-49f7-882d-02c4be17cc0d", "metadata": {"aucs": [0.2282369491949543, 0.2282369491949543, 0.2282369491949543], "final_y": [0.2551591053902049, 0.2551591053902049, 0.2551591053902049]}, "mutation_prompt": null}
{"id": "6f34fa42-d8b2-44aa-aaa4-e984ab33dfb9", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a), lb, ub)  # Modified mutation strategy\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic scaling mechanism\n            self.F = 0.5 + (np.var(fitness) / np.mean(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm adjusts the scaling factor based on fitness variance to enhance exploration in diverse search spaces.", "configspace": "", "generation": 17, "fitness": 0.24204547794138342, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6a68c754-86a5-49f7-882d-02c4be17cc0d", "metadata": {"aucs": [0.24204547794138342, 0.24204547794138342, 0.24204547794138342], "final_y": [0.1654793166873466, 0.1654793166873466, 0.1654793166873466]}, "mutation_prompt": null}
{"id": "3050124f-b7b7-4521-8475-0c3cd88d0a0f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a), lb, ub)  # Modified mutation strategy\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate  # Slight change from mean to max\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm dynamically adjusts the scale factor and crossover rate to balance exploration and exploitation, focusing on fitness variance and crossover success rate.", "configspace": "", "generation": 18, "fitness": 0.242385227768939, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6f34fa42-d8b2-44aa-aaa4-e984ab33dfb9", "metadata": {"aucs": [0.242385227768939, 0.242385227768939, 0.242385227768939], "final_y": [0.16538885493177813, 0.16538885493177813, 0.16538885493177813]}, "mutation_prompt": null}
{"id": "94b4a1d1-6e11-4f94-9066-1b82b81d20f2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a), lb, ub)  # Modified mutation strategy\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.mean(fitness)) * self.adaptation_rate  # Changed max to mean for variance influence\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced adaptation by modifying fitness variance influence on the scale factor for more effective exploration-exploitation trade-off.", "configspace": "", "generation": 19, "fitness": 0.24204547794138342, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3050124f-b7b7-4521-8475-0c3cd88d0a0f", "metadata": {"aucs": [0.24204547794138342, 0.24204547794138342, 0.24204547794138342], "final_y": [0.1654793166873466, 0.1654793166873466, 0.1654793166873466]}, "mutation_prompt": null}
{"id": "4cdffb7b-74b5-4e65-9d98-f3e2e8e8d18c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)  # Reverted to original mutation strategy\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate  # Slight change from mean to max\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm adaptively modifies mutation strategy to enhance exploration, using variance-based adjustment and trial success feedback to balance search dynamics.", "configspace": "", "generation": 20, "fitness": 0.2357015224417165, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.236 with standard deviation 0.000. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3050124f-b7b7-4521-8475-0c3cd88d0a0f", "metadata": {"aucs": [0.2357015224417165, 0.2357015224417165, 0.2357015224417165], "final_y": [0.17946742919601277, 0.17946742919601277, 0.17946742919601277]}, "mutation_prompt": null}
{"id": "bdcc09dc-e9eb-4722-aa7d-7029e3bb014f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * 0.01, lb, ub)  # Added random noise\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate  # Slight change from mean to max\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce an additional mutation strategy to improve exploration capabilities in the Adaptive Differential Evolution algorithm.", "configspace": "", "generation": 21, "fitness": 0.24360011216056832, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3050124f-b7b7-4521-8475-0c3cd88d0a0f", "metadata": {"aucs": [0.24360011216056832, 0.24360011216056832, 0.24360011216056832], "final_y": [0.16504192781319638, 0.16504192781319638, 0.16504192781319638]}, "mutation_prompt": null}
{"id": "b49fe47f-ca8f-43c5-9ad1-8ecb217b4a9e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = (1.0 - evaluations / self.budget) * 0.1  # Dynamic noise scaling\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate  # Slight change from mean to max\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration by introducing dynamic noise scaling in the mutation strategy of Adaptive Differential Evolution.", "configspace": "", "generation": 22, "fitness": 0.2420861710328991, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bdcc09dc-e9eb-4722-aa7d-7029e3bb014f", "metadata": {"aucs": [0.2420861710328991, 0.2420861710328991, 0.2420861710328991], "final_y": [0.16527827021086294, 0.16527827021086294, 0.16527827021086294]}, "mutation_prompt": null}
{"id": "30a487e8-3441-4d01-b108-28ee5af451d8", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * 0.02, lb, ub)  # Slightly increased random noise\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate  # Slight change from mean to max\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Slightly tweak the mutation strategy with an additional noise component to enhance diversity and improve exploration.", "configspace": "", "generation": 23, "fitness": 0.2433878296075791, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bdcc09dc-e9eb-4722-aa7d-7029e3bb014f", "metadata": {"aucs": [0.2433878296075791, 0.2433878296075791, 0.2433878296075791], "final_y": [0.16524340606196686, 0.16524340606196686, 0.16524340606196686]}, "mutation_prompt": null}
{"id": "d765425f-818c-4a95-93af-b45a0d42f811", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * 0.01, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            # Dynamic population size adjustment\n            self.population_size = max(4, int(10 * dim * (1 - evaluations / self.budget)))  # Changing this line\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic population size strategy to balance exploration and exploitation in Adaptive Differential Evolution.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'dim' is not defined\").", "error": "NameError(\"name 'dim' is not defined\")", "parent_id": "bdcc09dc-e9eb-4722-aa7d-7029e3bb014f", "metadata": {}, "mutation_prompt": null}
{"id": "55185ddb-e0df-4a96-94d8-16fe850523bc", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Modified mutation noise scaling\n                noise_scale = 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate  # Slight change from mean to max\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance mutation noise adaptability based on fitness variance to improve exploration in Adaptive Differential Evolution.", "configspace": "", "generation": 25, "fitness": 0.24360015878550179, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "bdcc09dc-e9eb-4722-aa7d-7029e3bb014f", "metadata": {"aucs": [0.24360015878550179, 0.24360015878550179, 0.24360015878550179], "final_y": [0.16504203019740082, 0.16504203019740082, 0.16504203019740082]}, "mutation_prompt": null}
{"id": "b935321a-df2f-4d8f-bc5b-6437d22a0528", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Modified mutation noise scaling\n                noise_scale = 0.01 * (1 + np.var(fitness) / (np.mean(fitness) + 1e-8))  # Add small constant to avoid division by zero\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate  # Slight change from mean to max\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution using dynamic noise scaling and crossover rate adjustment based on fitness variance and trial success.", "configspace": "", "generation": 26, "fitness": 0.24360015878550179, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "55185ddb-e0df-4a96-94d8-16fe850523bc", "metadata": {"aucs": [0.24360015878550179, 0.24360015878550179, 0.24360015878550179], "final_y": [0.16504203019739816, 0.16504203019739816, 0.16504203019739816]}, "mutation_prompt": null}
{"id": "7867bad1-49cf-400b-8301-baba730625f0", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Modified mutation noise scaling\n                noise_scale = 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate  # Slight change from mean to max\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            # Stochastic adaptation rate modulation\n            self.adaptation_rate *= 0.95 + 0.1 * np.random.rand()\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce stochastic adaptation rate modulation based on convergence progression to enhance adaptive differential evolution.", "configspace": "", "generation": 27, "fitness": 0.24264814188579753, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "55185ddb-e0df-4a96-94d8-16fe850523bc", "metadata": {"aucs": [0.24264814188579753, 0.24264814188579753, 0.24264814188579753], "final_y": [0.16577065863697327, 0.16577065863697327, 0.16577065863697327]}, "mutation_prompt": null}
{"id": "72f5b1c1-09cb-437c-9e7d-6e48bd3fcb92", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Modified mutation noise scaling\n                noise_scale = 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate  # Slight change from mean to max\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0 + 0.01 * np.var(fitness))  # Changed this line\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce variance-based dynamic adaptation to both mutation scale and crossover rate in Adaptive Differential Evolution.", "configspace": "", "generation": 28, "fitness": 0.24360015878550179, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "55185ddb-e0df-4a96-94d8-16fe850523bc", "metadata": {"aucs": [0.24360015878550179, 0.24360015878550179, 0.24360015878550179], "final_y": [0.16504203019740082, 0.16504203019740082, 0.16504203019740082]}, "mutation_prompt": null}
{"id": "387f0d28-7690-4e44-b864-1a4fb2715725", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Modified mutation noise scaling\n                noise_scale = 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate  # Slight change from mean to max\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.2, 1.0)  # Adjusted lower bound for CR\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive noise scaling based on fitness variance and improve crossover strategy in Adaptive Differential Evolution.", "configspace": "", "generation": 29, "fitness": 0.24360015878550179, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "55185ddb-e0df-4a96-94d8-16fe850523bc", "metadata": {"aucs": [0.24360015878550179, 0.24360015878550179, 0.24360015878550179], "final_y": [0.16504203019740082, 0.16504203019740082, 0.16504203019740082]}, "mutation_prompt": null}
{"id": "62cddf60-1490-4f84-8a7a-b25cac19a5e3", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                F_adapt = self.F * (fitness[i] / np.min(fitness))  # Adapt F based on fitness\n                mutant = np.clip(a + F_adapt * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a fitness-based mutation factor adaptation to improve convergence in Adaptive Differential Evolution.", "configspace": "", "generation": 30, "fitness": 0.22806800902465174, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.228 with standard deviation 0.000. And the mean value of best solutions found was 0.218 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "55185ddb-e0df-4a96-94d8-16fe850523bc", "metadata": {"aucs": [0.22806800902465174, 0.22806800902465174, 0.22806800902465174], "final_y": [0.21811414182722566, 0.21811414182722566, 0.21811414182722566]}, "mutation_prompt": null}
{"id": "1a1220b1-e38d-4926-bb78-b6e1ea560261", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Modified mutation noise scaling\n                noise_scale = 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.normal(0, noise_scale, self.dim), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate  # Slight change from mean to max\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance mutation noise adaptability with fitness variance using Gaussian distribution for better exploration in Adaptive Differential Evolution.", "configspace": "", "generation": 31, "fitness": 0.24360015878550179, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "55185ddb-e0df-4a96-94d8-16fe850523bc", "metadata": {"aucs": [0.24360015878550179, 0.24360015878550179, 0.24360015878550179], "final_y": [0.16504203019740082, 0.16504203019740082, 0.16504203019740082]}, "mutation_prompt": null}
{"id": "afb6c3e3-676c-48c1-9704-403ce3876c60", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Modified mutation noise scaling\n                noise_scale = 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Adjustments for F and CR\n            self.F = 0.5 + (np.var(fitness) / np.mean(abs(fitness - np.mean(fitness)))) * self.adaptation_rate  # Changed mean to abs(mean difference)\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            # Adaptive crossover rate based on success of trials\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce environment-based scaling of mutation factor to enhance adaptation and convergence in Adaptive Differential Evolution.", "configspace": "", "generation": 32, "fitness": 0.2419104693628329, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "55185ddb-e0df-4a96-94d8-16fe850523bc", "metadata": {"aucs": [0.2419104693628329, 0.2419104693628329, 0.2419104693628329], "final_y": [0.16528164937509904, 0.16528164937509904, 0.16528164937509904]}, "mutation_prompt": null}
{"id": "a695628b-833f-4114-87d6-ac1232895ce5", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic inertia factor to balance exploration and exploitation in Adaptive Differential Evolution.", "configspace": "", "generation": 33, "fitness": 0.24360522629931292, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "55185ddb-e0df-4a96-94d8-16fe850523bc", "metadata": {"aucs": [0.24360522629931292, 0.24360522629931292, 0.24360522629931292], "final_y": [0.16505129035407706, 0.16505129035407706, 0.16505129035407706]}, "mutation_prompt": null}
{"id": "a61eeda2-f828-4d0a-afc4-86d43647daed", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                mutant = np.clip(a + self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Modified the adaptation strategy for F\n            self.F = 0.5 + (np.std(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.2, 1.0)\n            \n            # Modified the adaptation strategy for CR\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.var(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Adjust the adaptation strategy by refining mutation factor F and crossover rate CR for improved performance in Adaptive Differential Evolution.", "configspace": "", "generation": 34, "fitness": 0.24150847069960446, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.000. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a695628b-833f-4114-87d6-ac1232895ce5", "metadata": {"aucs": [0.24150847069960446, 0.24150847069960446, 0.24150847069960446], "final_y": [0.1685247320910367, 0.1685247320910367, 0.1685247320910367]}, "mutation_prompt": null}
{"id": "fe642da9-201d-4289-ae70-33fb8930c5b6", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Changed line: Introduced adaptive mutation scale\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation scale to enhance search space exploration in Adaptive Differential Evolution.", "configspace": "", "generation": 35, "fitness": 0.24575726728965952, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a695628b-833f-4114-87d6-ac1232895ce5", "metadata": {"aucs": [0.24575726728965952, 0.24575726728965952, 0.24575726728965952], "final_y": [0.1648773644700895, 0.1648773644700895, 0.1648773644700895]}, "mutation_prompt": null}
{"id": "8b43ac1a-12fc-4679-8ff4-ceb088b2ccbb", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Changed line: Enhanced mutation scale with diversity\n                mutant = np.clip(a + np.random.uniform(0.5, 1.5) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance solution exploration by modifying the mutation factor formula to account for population diversity.", "configspace": "", "generation": 36, "fitness": 0.24406112808557368, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fe642da9-201d-4289-ae70-33fb8930c5b6", "metadata": {"aucs": [0.24406112808557368, 0.24406112808557368, 0.24406112808557368], "final_y": [0.16540674754039142, 0.16540674754039142, 0.16540674754039142]}, "mutation_prompt": null}
{"id": "4f1866eb-059a-4a85-90c9-68ee29ab2a4c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Changed line: Introduced adaptive mutation scale\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale * 0.9, lb, ub)  # Adjusted mutation scale\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Fine-tune adaptive mutation scale to enhance local search efficiency in Adaptive Differential Evolution.", "configspace": "", "generation": 37, "fitness": 0.2457554764166585, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fe642da9-201d-4289-ae70-33fb8930c5b6", "metadata": {"aucs": [0.2457554764166585, 0.2457554764166585, 0.2457554764166585], "final_y": [0.16489032386724545, 0.16489032386724545, 0.16489032386724545]}, "mutation_prompt": null}
{"id": "2f9d28ec-0402-49ff-962e-9d8c36e80564", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Changed line: Introduced adaptive mutation scale\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.normal(0, noise_scale, self.dim), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - self.CR)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce Gaussian mutation with adaptive scaling for improved exploration in Adaptive Differential Evolution.", "configspace": "", "generation": 38, "fitness": 0.24575726728965952, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fe642da9-201d-4289-ae70-33fb8930c5b6", "metadata": {"aucs": [0.24575726728965952, 0.24575726728965952, 0.24575726728965952], "final_y": [0.1648773644700895, 0.1648773644700895, 0.1648773644700895]}, "mutation_prompt": null}
{"id": "b03f41ae-e0d9-492e-9242-35d6230b1b2b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Changed line: Introduced adaptive mutation scale\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials))  # Changed line: Adapt CR based on variance\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic crossover probability adaptation based on fitness improvement variance to enhance diversity in Adaptive Differential Evolution.", "configspace": "", "generation": 39, "fitness": 0.24583432010727202, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fe642da9-201d-4289-ae70-33fb8930c5b6", "metadata": {"aucs": [0.24583432010727202, 0.24583432010727202, 0.24583432010727202], "final_y": [0.16523682428153585, 0.16523682428153585, 0.16523682428153585]}, "mutation_prompt": null}
{"id": "0f4a9888-2ba8-4fbc-89a0-0cd066042891", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Changed line: Introduced adaptive mutation scale\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            # Changed line: Incorporate fitness-centric CR adaptation\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness))\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce fitness-centric crossover probability adaptation to fine-tune exploration and exploitation balance in Adaptive Differential Evolution.", "configspace": "", "generation": 40, "fitness": 0.24583630720610794, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b03f41ae-e0d9-492e-9242-35d6230b1b2b", "metadata": {"aucs": [0.24583630720610794, 0.24583630720610794, 0.24583630720610794], "final_y": [0.16517129049118573, 0.16517129049118573, 0.16517129049118573]}, "mutation_prompt": null}
{"id": "00323252-4911-45ee-ba31-dc3daddc41d4", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        successful_trials_history = []  # New: Track successful trials history\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Changed line: Introduced adaptive mutation scale\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n                    successful_trials_history.append(1)  # New: Record successful trial\n                else:\n                    successful_trials_history.append(0)  # New: Record unsuccessful trial\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            # Changed line: Incorporate fitness-centric CR adaptation\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness))\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance Adaptive Differential Evolution's convergence by incorporating dynamic mutation scaling based on success history.", "configspace": "", "generation": 41, "fitness": 0.24583630720610794, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0f4a9888-2ba8-4fbc-89a0-0cd066042891", "metadata": {"aucs": [0.24583630720610794, 0.24583630720610794, 0.24583630720610794], "final_y": [0.16517129049118573, 0.16517129049118573, 0.16517129049118573]}, "mutation_prompt": null}
{"id": "2cc6047c-fbbf-4a79-a888-277bfa6cad82", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            # Change 1: Adjust population size dynamically\n            self.population_size = max(4, self.population_size - evaluations // 100)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Change 2: Introduce fitness-based mutation factor scaling\n                fitness_scale = (fitness[i] - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-8)\n                mutant = np.clip(a + (0.7 + 0.3 * fitness_scale) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness))\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce fitness-based mutation factor scaling and dynamic population resizing for enhanced convergence in Adaptive Differential Evolution.", "configspace": "", "generation": 42, "fitness": 0.2364920230769778, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.236 with standard deviation 0.000. And the mean value of best solutions found was 0.208 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0f4a9888-2ba8-4fbc-89a0-0cd066042891", "metadata": {"aucs": [0.2364920230769778, 0.2364920230769778, 0.2364920230769778], "final_y": [0.20793543770078038, 0.20793543770078038, 0.20793543770078038]}, "mutation_prompt": null}
{"id": "efd157b8-250d-4e35-9539-325d222e335c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            # Changed line: dynamic CR adjustment based on population diversity\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.std(population) * 0.1)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic crossover rate adjustment based on population diversity to improve exploration and exploitation balance in Adaptive Differential Evolution.", "configspace": "", "generation": 43, "fitness": 0.24305651004385276, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.000. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0f4a9888-2ba8-4fbc-89a0-0cd066042891", "metadata": {"aucs": [0.24305651004385276, 0.24305651004385276, 0.24305651004385276], "final_y": [0.17038404155320708, 0.17038404155320708, 0.17038404155320708]}, "mutation_prompt": null}
{"id": "f3133795-74cc-49ae-a655-e1e66ea6b9da", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Changed line: Introduced adaptive mutation scale\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Line change: Non-linear mutation scaling\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            # Changed line: Smoothed fitness-centric CR adaptation\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Integrate non-linear scaling of mutation factor and adaptive strategy for crossover to enhance convergence in Adaptive Differential Evolution.", "configspace": "", "generation": 44, "fitness": 0.24594898470132276, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0f4a9888-2ba8-4fbc-89a0-0cd066042891", "metadata": {"aucs": [0.24594898470132276, 0.24594898470132276, 0.24594898470132276], "final_y": [0.16533658344801794, 0.16533658344801794, 0.16533658344801794]}, "mutation_prompt": null}
{"id": "0f994b54-424b-4fff-8fc9-b5a6a57a20d9", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Changed line: Introduced adaptive mutation scale\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Line change: Non-linear mutation scaling\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            # Changed line: Smoothed fitness-centric CR adaptation\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            # New: Variable reduction in population size\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce variable population size reduction strategy to improve convergence in Adaptive Differential Evolution.", "configspace": "", "generation": 45, "fitness": 0.24623258773896073, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f3133795-74cc-49ae-a655-e1e66ea6b9da", "metadata": {"aucs": [0.24623258773896073, 0.24623258773896073, 0.24623258773896073], "final_y": [0.16501109229650557, 0.16501109229650557, 0.16501109229650557]}, "mutation_prompt": null}
{"id": "754d87f1-c856-410a-936f-d43424edd090", "solution": "import numpy as np\n\nclass ChaoticDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.chaos_coefficient = 0.7\n\n    def chaotic_sequence(self, size):\n        x = np.random.rand()\n        sequence = []\n        for _ in range(size):\n            x = self.chaos_coefficient * x * (1 - x)\n            sequence.append(x)\n        return np.array(sequence)\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            chaotic_factor = self.chaotic_sequence(1)[0]  # Update chaotic factor\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + chaotic_factor * self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.F = 0.5 + np.var(fitness) / np.mean(fitness)\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = self.CR + 0.1 * (np.mean(successful_trials) - 0.5)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "ChaoticDifferentialEvolution", "description": "Incorporate a chaotic search mechanism to enhance exploration and convergence in a Chaotic Differential Evolution algorithm.", "configspace": "", "generation": 46, "fitness": 0.24161701080260134, "feedback": "The algorithm ChaoticDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.000. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0f994b54-424b-4fff-8fc9-b5a6a57a20d9", "metadata": {"aucs": [0.24161701080260134, 0.24161701080260134, 0.24161701080260134], "final_y": [0.17110952122441692, 0.17110952122441692, 0.17110952122441692]}, "mutation_prompt": null}
{"id": "c538be74-1829-49ff-bbc5-59acab290b9b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                best_idx = np.argmin(fitness)  # New: Record the best solution\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance mutation strategy by introducing elitism to retain the best solution.", "configspace": "", "generation": 47, "fitness": 0.24623258773896073, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0f994b54-424b-4fff-8fc9-b5a6a57a20d9", "metadata": {"aucs": [0.24623258773896073, 0.24623258773896073, 0.24623258773896073], "final_y": [0.16501109229650557, 0.16501109229650557, 0.16501109229650557]}, "mutation_prompt": null}
{"id": "20043260-21b6-4bb7-b7db-b38617666054", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Changed line: Introduced adaptive mutation scale\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Line change: Non-linear mutation scaling\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * np.random.uniform(0.9, 1.1), 0.1, 1.0)  # Updated line: random scaling factor\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            # Changed line: Smoothed fitness-centric CR adaptation\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            # New: Variable reduction in population size\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance mutation strategy by incorporating a random scaling factor for improved diversity in exploration.", "configspace": "", "generation": 48, "fitness": 0.24621814343097836, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0f994b54-424b-4fff-8fc9-b5a6a57a20d9", "metadata": {"aucs": [0.24621814343097836, 0.24621814343097836, 0.24621814343097836], "final_y": [0.16487920813247825, 0.16487920813247825, 0.16487920813247825]}, "mutation_prompt": null}
{"id": "8517daa4-b94c-4072-9d53-9ecfd931b629", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # New: Dynamic inertia factor based on evaluations\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                # Changed line: Introduced adaptive mutation scale\n                decay_factor = (1 - (evaluations / self.budget)) ** 2  # Changed: dynamic decay factor\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale * decay_factor, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Line change: Non-linear mutation scaling\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F, 0.1, 1.0)\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            # Changed line: Smoothed fitness-centric CR adaptation\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            # New: Variable reduction in population size\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Refined noise scaling using a dynamic decay factor to enhance solution stability in Adaptive Differential Evolution.", "configspace": "", "generation": 49, "fitness": 0.24623212849972032, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0f994b54-424b-4fff-8fc9-b5a6a57a20d9", "metadata": {"aucs": [0.24623212849972032, 0.24623212849972032, 0.24623212849972032], "final_y": [0.16501580691010953, 0.16501580691010953, 0.16501580691010953]}, "mutation_prompt": null}
{"id": "901c7c66-759e-4033-8a9b-492f7a77b68b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)  # Modified line: Integrate inertia into F\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Refine convergence by integrating an adaptive inertia factor into mutation scale computation.", "configspace": "", "generation": 50, "fitness": 0.24634619291584325, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0f994b54-424b-4fff-8fc9-b5a6a57a20d9", "metadata": {"aucs": [0.24634619291584325, 0.24634619291584325, 0.24634619291584325], "final_y": [0.16521313900436452, 0.16521313900436452, 0.16521313900436452]}, "mutation_prompt": null}
{"id": "468666ba-8610-436d-842a-627256d7a003", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness)) * np.std(fitness)  # Modified: Adjust noise scale with std of fitness\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)  # Modified line: Integrate inertia into F\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance mutation by dynamically adjusting noise scale based on fitness diversity.", "configspace": "", "generation": 51, "fitness": 0.2460432852681549, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "901c7c66-759e-4033-8a9b-492f7a77b68b", "metadata": {"aucs": [0.2460432852681549, 0.2460432852681549, 0.2460432852681549], "final_y": [0.16608346763031956, 0.16608346763031956, 0.16608346763031956]}, "mutation_prompt": null}
{"id": "83916960-a1f8-48f5-b04a-6c85b8e53031", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial += np.random.randn(self.dim) * (np.var(fitness) / np.mean(fitness))  # Modified line: Perturb trial using Gaussian noise\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)  # Modified line: Integrate inertia into F\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce diversity by perturbing trial solutions using adaptive Gaussian noise scaled to the fitness variance.", "configspace": "", "generation": 52, "fitness": 0.24602004488239404, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "901c7c66-759e-4033-8a9b-492f7a77b68b", "metadata": {"aucs": [0.24602004488239404, 0.24602004488239404, 0.24602004488239404], "final_y": [0.16559396045181185, 0.16559396045181185, 0.16559396045181185]}, "mutation_prompt": null}
{"id": "df595c2c-84e8-41f4-97b2-e0dc8c58faa9", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)  # Modified line: Integrate inertia into F\n            \n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance mutation diversity by adding dimension-wise adaptive scaling to the differential evolution strategy.", "configspace": "", "generation": 53, "fitness": 0.2465877794415522, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "901c7c66-759e-4033-8a9b-492f7a77b68b", "metadata": {"aucs": [0.2465877794415522, 0.2465877794415522, 0.2465877794415522], "final_y": [0.16531407257140096, 0.16531407257140096, 0.16531407257140096]}, "mutation_prompt": null}
{"id": "9a317de3-db68-4db9-9a4b-063d410f823b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce dynamic population resizing and adaptive scaling of crossover rate based on fitness variance to improve exploration.", "configspace": "", "generation": 54, "fitness": 0.2466077133671548, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "df595c2c-84e8-41f4-97b2-e0dc8c58faa9", "metadata": {"aucs": [0.2466077133671548, 0.2466077133671548, 0.2466077133671548], "final_y": [0.16514114507369815, 0.16514114507369815, 0.16514114507369815]}, "mutation_prompt": null}
{"id": "768a1d84-57df-4174-8554-343e149043f0", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n            \n            self.F *= np.mean(successful_trials)  # New: adjust mutation factor based on success rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce an adaptive mutation strategy by adjusting the mutation factor F based on the success rate of trials.", "configspace": "", "generation": 55, "fitness": 0.24616376545118346, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.24616376545118346, 0.24616376545118346, 0.24616376545118346], "final_y": [0.16879720635754014, 0.16879720635754014, 0.16879720635754014]}, "mutation_prompt": null}
{"id": "e6ffe5a9-f391-4bce-a539-f2a05f1fb119", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                mutant = np.clip(a + dimension_scale * (self.F + 0.1 * (1 - fitness[i] / np.max(fitness))) * (b - c) + np.random.randn(self.dim) * noise_scale, lb, ub)  # Modified: fitness-based adaptive mutation\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce fitness-based adaptive mutation factor and enhance trial vector selection for convergence and diversity balance.", "configspace": "", "generation": 56, "fitness": 0.24398894736352972, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.24398894736352972, 0.24398894736352972, 0.24398894736352972], "final_y": [0.16565740031001586, 0.16565740031001586, 0.16565740031001586]}, "mutation_prompt": null}
{"id": "ccae9e26-9152-478d-9269-05497eee5672", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                novelty_factor = 0.1 * np.random.randn()  # New: novelty-based mutation factor\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + novelty_factor + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                if np.random.rand() < 0.1:  # New: stochastic restart mechanism\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    fitness = np.array([func(ind) for ind in population])\n                else:\n                    population = population[np.argsort(fitness)[:self.population_size]]\n                    fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration by incorporating a novelty-based mutation factor and stochastic restart mechanism for escaping local optima.", "configspace": "", "generation": 57, "fitness": 0.24629016140074889, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.24629016140074889, 0.24629016140074889, 0.24629016140074889], "final_y": [0.16583594708743887, 0.16583594708743887, 0.16583594708743887]}, "mutation_prompt": null}
{"id": "679da7db-d2b2-4037-a4c2-dc339db53462", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                # Change: Modify how dimension_scale is used in the mutation step for adaptive effect\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce dimension-wise adaptive scaling and inertia factor in mutation for enhanced exploration and exploitation balance.", "configspace": "", "generation": 58, "fitness": 0.2466077133671548, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.2466077133671548, 0.2466077133671548, 0.2466077133671548], "final_y": [0.16514114507369815, 0.16514114507369815, 0.16514114507369815]}, "mutation_prompt": null}
{"id": "9d8df8bc-28fa-433a-a5e5-68f30ffb9460", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            best_idx = np.argmin(fitness)\n            best_ind = population[best_idx]  # New: track the best individual\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (best_ind - a) + np.random.randn(self.dim) * noise_scale, lb, ub)  # Change: mutated based on best_ind\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration by introducing a mutation strategy based on the current best individual.", "configspace": "", "generation": 59, "fitness": 0.24591080601521031, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.24591080601521031, 0.24591080601521031, 0.24591080601521031], "final_y": [0.17102827560679446, 0.17102827560679446, 0.17102827560679446]}, "mutation_prompt": null}
{"id": "ae9f6f2e-99ef-4840-bfe4-14c3aac9adf3", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim) * np.mean(population)  # Change: variable scaling factor\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a variable scaling factor in dimension-wise adaptive scaling to enhance search diversity and convergence in DE.", "configspace": "", "generation": 60, "fitness": 0.20414815361272454, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.204 with standard deviation 0.000. And the mean value of best solutions found was 0.439 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.20414815361272454, 0.20414815361272454, 0.20414815361272454], "final_y": [0.4387515239665405, 0.4387515239665405, 0.4387515239665405]}, "mutation_prompt": null}
{"id": "941d9d26-a795-4389-a826-4d5e4969a241", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.mean(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                elite_idx = np.argsort(fitness)[:int(0.1 * self.population_size)]  # Added: stochastic elitism selection\n                population = population[elite_idx]\n                fitness = fitness[elite_idx]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce stochastic elitism in population selection and enhanced mutation scaling based on survivor fitness.", "configspace": "", "generation": 61, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 67 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 67 is out of bounds for axis 0 with size 9')", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {}, "mutation_prompt": null}
{"id": "64302dd9-5319-4404-ba64-2ab4c44d92ec", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.uniform(0.5, 1.5, self.dim)  # Changed: range for dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration-exploitation balance by modifying dimension-wise scaling for better mutation diversity.", "configspace": "", "generation": 62, "fitness": 0.24447080652870923, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.24447080652870923, 0.24447080652870923, 0.24447080652870923], "final_y": [0.16514573786624787, 0.16514573786624787, 0.16514573786624787]}, "mutation_prompt": null}
{"id": "6d92a7af-12a1-4c1a-8134-4a9f63fa3671", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = np.sqrt(1 - (evaluations - initial_eval) / (self.budget - initial_eval))  # Modified: improve scaling\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale * 0.5, lb, ub)  # Modified: refine perturbation\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Refine exploration with adaptive Gaussian perturbation and improved inertia factor scaling for enhanced convergence.", "configspace": "", "generation": 63, "fitness": 0.24660011806311588, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.24660011806311588, 0.24660011806311588, 0.24660011806311588], "final_y": [0.1651774890518447, 0.1651774890518447, 0.1651774890518447]}, "mutation_prompt": null}
{"id": "65dd6412-b589-4aef-a03f-2761d063af2e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                # Here `self.F` is modified, constituting the 1 line change\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) * (1 - np.min(fitness) / np.mean(fitness)) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Utilize adaptive mutation scaling based on the minimum fitness to enhance convergence.", "configspace": "", "generation": 64, "fitness": 0.24655257862563296, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.24655257862563296, 0.24655257862563296, 0.24655257862563296], "final_y": [0.16491102474411956, 0.16491102474411956, 0.16491102474411956]}, "mutation_prompt": null}
{"id": "8cd98297-a66a-4905-b789-f49371551979", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + ((np.var(fitness) + np.linalg.norm(population.std(axis=0))) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration by dynamically adjusting the scaling factor based on a balance of fitness variance and population diversity.", "configspace": "", "generation": 65, "fitness": 0.23343452304460766, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.000. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.23343452304460766, 0.23343452304460766, 0.23343452304460766], "final_y": [0.1673377160410342, 0.1673377160410342, 0.1673377160410342]}, "mutation_prompt": null}
{"id": "de1b217f-63a8-4243-ae6b-6ebbdc564ce4", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = (1 - (evaluations - initial_eval) / (self.budget - initial_eval)) ** 1.01  # Changed: adaptive inertia factor scaling\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive inertia factor scaling to improve the balance between exploration and exploitation.", "configspace": "", "generation": 66, "fitness": 0.24650730641537122, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.24650730641537122, 0.24650730641537122, 0.24650730641537122], "final_y": [0.1654793948885701, 0.1654793948885701, 0.1654793948885701]}, "mutation_prompt": null}
{"id": "372cba19-5d79-4609-8d0b-86816019398c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + np.random.randn(self.dim) * noise_scale, lb, ub)  # Changed: Removed redundant term\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation strategies based on fitness variance and inertia to balance exploration and exploitation.", "configspace": "", "generation": 67, "fitness": 0.2386089316474389, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.239 with standard deviation 0.000. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.2386089316474389, 0.2386089316474389, 0.2386089316474389], "final_y": [0.18174567341753722, 0.18174567341753722, 0.18174567341753722]}, "mutation_prompt": null}
{"id": "b9042d65-a9d0-4ae5-bb2d-23b893df970b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Change 1: Adaptive scaling of F based on fitness improvement\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate * (1 - np.mean(fitness)/np.min(fitness))\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                # Change 2: Elitism by always retaining the best individuals\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:self.population_size]]\n                fitness = fitness[sorted_indices[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Implement adaptive mutation scaling and introduce elitism to improve convergence speed and solution quality.", "configspace": "", "generation": 68, "fitness": 0.24639031473639872, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.24639031473639872, 0.24639031473639872, 0.24639031473639872], "final_y": [0.16653472159665006, 0.16653472159665006, 0.16653472159665006]}, "mutation_prompt": null}
{"id": "13cccf81-fc6e-4e46-b454-b8f0727cd1cd", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n            if evaluations % (self.budget // 20) == 0:  # Local search around best\n                best_idx = np.argmin(fitness)\n                local_trial = population[best_idx] + np.random.randn(self.dim) * 0.01\n                local_trial = np.clip(local_trial, lb, ub)\n                local_trial_fit = func(local_trial)\n                evaluations += 1\n                if local_trial_fit < fitness[best_idx]:\n                    population[best_idx] = local_trial\n                    fitness[best_idx] = local_trial_fit\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce local search around the best solution found so far to enhance convergence speed.", "configspace": "", "generation": 69, "fitness": 0.2465122572876125, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.2465122572876125, 0.2465122572876125, 0.2465122572876125], "final_y": [0.1654701489446968, 0.1654701489446968, 0.1654701489446968]}, "mutation_prompt": null}
{"id": "34ae3027-ae64-49ae-a890-d368095ee211", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Refined adaptation mechanism using fitness variance to improve convergence stability.", "configspace": "", "generation": 70, "fitness": 0.2466077133671548, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.2466077133671548, 0.2466077133671548, 0.2466077133671548], "final_y": [0.16514114507369815, 0.16514114507369815, 0.16514114507369815]}, "mutation_prompt": null}
{"id": "3cef00d7-cbdd-4853-ad48-06774dee23be", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                mutant = np.clip(a + dimension_scale * self.F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Change the adaptation of F\n            self.F = 0.5 + 0.4 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration by introducing oscillating mutation factor F based on a sine function.", "configspace": "", "generation": 71, "fitness": 0.24508426100354064, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.245 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.24508426100354064, 0.24508426100354064, 0.24508426100354064], "final_y": [0.16535349977072356, 0.16535349977072356, 0.16535349977072356]}, "mutation_prompt": null}
{"id": "7e57e2e6-764d-46ce-bd79-00c110fc93c2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance mutation strategy by introducing stochastic scaling factors to improve global exploration and convergence speed.", "configspace": "", "generation": 72, "fitness": 0.2467947949634367, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9a317de3-db68-4db9-9a4b-063d410f823b", "metadata": {"aucs": [0.2467947949634367, 0.2467947949634367, 0.2467947949634367], "final_y": [0.16623444578355073, 0.16623444578355073, 0.16623444578355073]}, "mutation_prompt": null}
{"id": "af3a2d58-5ce6-4a0e-a09c-cc4ef1fc7e62", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            successful_mutations = 0  # New: track successful mutations\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim)) \n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n                    successful_mutations += 1  # New: increment for successful mutation\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n            # New: adapt F based on success rate\n            if successful_mutations > 0:\n                self.F *= 1 + (successful_mutations / self.population_size)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0) \n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation rate based on the success rate of trial vectors to further improve convergence.", "configspace": "", "generation": 73, "fitness": 0.245554919197287, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e57e2e6-764d-46ce-bd79-00c110fc93c2", "metadata": {"aucs": [0.245554919197287, 0.245554919197287, 0.245554919197287], "final_y": [0.16562633932873927, 0.16562633932873927, 0.16562633932873927]}, "mutation_prompt": null}
{"id": "2596d48b-2051-463c-8f37-11ca87a49cca", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive inertia and crossover rate to balance exploration and exploitation in differential evolution.", "configspace": "", "generation": 74, "fitness": 0.246856100786914, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e57e2e6-764d-46ce-bd79-00c110fc93c2", "metadata": {"aucs": [0.246856100786914, 0.246856100786914, 0.246856100786914], "final_y": [0.16562657039986384, 0.16562657039986384, 0.16562657039986384]}, "mutation_prompt": null}
{"id": "dd600ac1-07a5-44df-933b-95c58f5c8c71", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                fitness_diversity = np.linalg.norm(fitness - np.mean(fitness)) / np.linalg.norm(fitness)  # Added: fitness diversity metric\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim)) * fitness_diversity  # Changed: adaptive mutation scaling\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation scaling based on fitness diversity for improved exploration-exploitation balance in differential evolution.", "configspace": "", "generation": 75, "fitness": 0.24676527541050686, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24676527541050686, 0.24676527541050686, 0.24676527541050686], "final_y": [0.16703886303230708, 0.16703886303230708, 0.16703886303230708]}, "mutation_prompt": null}
{"id": "a80264ef-f036-4ea6-bda7-6a04338900ba", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                # Changed: dynamic adjustment based on convergence rate\n                convergence_rate = np.abs(np.var(fitness) / np.mean(fitness))\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * convergence_rate * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic population size adjustment based on convergence rate to improve exploration.", "configspace": "", "generation": 76, "fitness": 0.2466690779732318, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.2466690779732318, 0.2466690779732318, 0.2466690779732318], "final_y": [0.1659686505961253, 0.1659686505961253, 0.1659686505961253]}, "mutation_prompt": null}
{"id": "08affba1-39b5-4d5a-9ed5-b44117cb4225", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n        self.dynamic_resize_threshold = 0.05  # New: dynamic resizing threshold\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n\n            # New: Adjust population size adaptively\n            if np.std(fitness) < self.dynamic_resize_threshold:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce dynamic population resizing and selective pressure to enhance convergence rate and solution quality in differential evolution.", "configspace": "", "generation": 77, "fitness": 0.24664490219673796, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24664490219673796, 0.24664490219673796, 0.24664490219673796], "final_y": [0.16631478733460758, 0.16631478733460758, 0.16631478733460758]}, "mutation_prompt": null}
{"id": "7bab7412-251e-47d9-8520-c1927834364e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * np.mean(successful_trials) * (1.0 - np.min(fitness) / np.max(fitness))  # Change: dynamic CR adjustment\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic crossover probability adjustment based on the relative improvement in fitness.", "configspace": "", "generation": 78, "fitness": 0.24677052627950047, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24677052627950047, 0.24677052627950047, 0.24677052627950047], "final_y": [0.1655745493577897, 0.1655745493577897, 0.1655745493577897]}, "mutation_prompt": null}
{"id": "51604d3f-15d4-450b-b0e8-f36bed97bbac", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Incorporate dimension-wise adaptive mutation scaling to enhance exploration in Adaptive Differential Evolution.", "configspace": "", "generation": 79, "fitness": 0.2430546079739795, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.000. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.2430546079739795, 0.2430546079739795, 0.2430546079739795], "final_y": [0.17033719562979088, 0.17033719562979088, 0.17033719562979088]}, "mutation_prompt": null}
{"id": "36b72212-0045-465a-bcdb-a1a67c08a7e2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                diversity = np.std(population, axis=0).mean()  # New: calculate diversity\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size * (1 - diversity)))  # Update: population size scaling based on diversity\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Improve exploration by introducing adaptive population size scaling based on diversity.", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 273 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 273 is out of bounds for axis 0 with size 100')", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {}, "mutation_prompt": null}
{"id": "237dd67a-a46a-4886-a7e9-e417b5e19288", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            best_fitness_improvement = np.min(fitness) / (np.min(fitness) + 1e-8)  # New: dynamic inertia adjustment\n            inertia_factor *= 1 + best_fitness_improvement\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic inertia adjustment based on the best fitness improvement to enhance convergence rate.", "configspace": "", "generation": 81, "fitness": 0.24022953779539669, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24022953779539669, 0.24022953779539669, 0.24022953779539669], "final_y": [0.1658102151994929, 0.1658102151994929, 0.1658102151994929]}, "mutation_prompt": null}
{"id": "bf4f935d-b0a9-4081-bb30-7c9549dbb34e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor * (1 + 0.1 * np.random.randn()), 0.1, 1.0)  # Modified: stochastic component added to F\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a stochastic component to adaptively update the mutation factor for enhanced diversity.", "configspace": "", "generation": 82, "fitness": 0.24655909934052922, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24655909934052922, 0.24655909934052922, 0.24655909934052922], "final_y": [0.16681470160920042, 0.16681470160920042, 0.16681470160920042]}, "mutation_prompt": null}
{"id": "028efa3e-67ea-4ccb-a684-fa449bc25919", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce dynamic adjustment for mutation factor and crossover rate based on past iterations' performance to enhance convergence.", "configspace": "", "generation": 83, "fitness": 0.246856100786914, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.246856100786914, 0.246856100786914, 0.246856100786914], "final_y": [0.16562657039986384, 0.16562657039986384, 0.16562657039986384]}, "mutation_prompt": null}
{"id": "b73f5fb3-f8ef-4271-9056-e4c0eba3776c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n                # New: Incorporate adaptive scaling of the population size for enhanced convergence\n                self.population_size = min(max(5 * self.dim, int(self.population_size * (1 + 0.05 * np.random.randn()))), 10 * self.dim)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance differential evolution with adaptive population size scaling to improve convergence.", "configspace": "", "generation": 84, "fitness": 0.24657660651663638, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24657660651663638, 0.24657660651663638, 0.24657660651663638], "final_y": [0.1665793263164711, 0.1665793263164711, 0.1665793263164711]}, "mutation_prompt": null}
{"id": "f928bf85-209e-4608-908d-531a59b8d120", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(4 * self.dim, self.population_size - int(0.1 * self.population_size))  # Changed: reduce population size\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce dynamic scaling of the mutation factor with success-based adaptation and adaptive population size reduction.", "configspace": "", "generation": 85, "fitness": 0.246856100786914, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.246856100786914, 0.246856100786914, 0.246856100786914], "final_y": [0.16562657039986384, 0.16562657039986384, 0.16562657039986384]}, "mutation_prompt": null}
{"id": "92324374-2b09-440f-8d34-9a71da14dca8", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness) + 0.05 * np.random.randn()), 0.1, 1.0)  # Modified: add noise to adapt CR\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce noise to the crossover rate to enhance diversity in the Adaptive Differential Evolution algorithm.", "configspace": "", "generation": 86, "fitness": 0.2467463926702771, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.2467463926702771, 0.2467463926702771, 0.2467463926702771], "final_y": [0.16609268546060996, 0.16609268546060996, 0.16609268546060996]}, "mutation_prompt": null}
{"id": "c6b3ca5d-7427-437b-8ceb-e77ffe969b06", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance adaptive differential evolution by integrating a dynamic learning rate adjustment mechanism.", "configspace": "", "generation": 87, "fitness": 0.246856100786914, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.246856100786914, 0.246856100786914, 0.246856100786914], "final_y": [0.16562657039986384, 0.16562657039986384, 0.16562657039986384]}, "mutation_prompt": null}
{"id": "bd6f53f9-f5bc-46f1-9f7d-dda8149c3c3b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.05 * (1 + np.var(fitness) / np.mean(fitness))  # Changed: dynamic noise scaling\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR / (1 + np.var(fitness))  # Changed: adaptive mutation probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration by introducing dynamic noise scaling and adaptive mutation probability within differential evolution.", "configspace": "", "generation": 88, "fitness": 0.2460070807766258, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.2460070807766258, 0.2460070807766258, 0.2460070807766258], "final_y": [0.16775771100911407, 0.16775771100911407, 0.16775771100911407]}, "mutation_prompt": null}
{"id": "76cce56e-8f67-4a17-9638-65985c479a87", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n                \n            # Introduce adaptive mutation scaling based on best fitness\n            best_fit = np.min(fitness)\n            self.F = self.F * (1 + np.log(1 + best_fit))\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation scaling based on current best fitness to improve convergence speed in adaptive differential evolution.", "configspace": "", "generation": 89, "fitness": 0.24592003464420698, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24592003464420698, 0.24592003464420698, 0.24592003464420698], "final_y": [0.16556829794391137, 0.16556829794391137, 0.16556829794391137]}, "mutation_prompt": null}
{"id": "6fab138f-7af6-4ae2-abdf-6c6f3bf7659f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))\n                # Change: Apply dimension-wise Gaussian mutation for diversity\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance population diversity by integrating a dimension-wise Gaussian mutation for robust exploration.", "configspace": "", "generation": 90, "fitness": 0.246856100786914, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.246856100786914, 0.246856100786914, 0.246856100786914], "final_y": [0.16562657039986384, 0.16562657039986384, 0.16562657039986384]}, "mutation_prompt": null}
{"id": "cb9b4f61-fc69-4d0f-9ff4-faaa1198075e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * np.mean(fitness) * self.adaptation_rate  # Enhanced: adaptive F scaling\n\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive inertia and crossover rate to balance exploration and exploitation in differential evolution with enhanced adaptive F scaling.", "configspace": "", "generation": 91, "fitness": 0.246809079201168, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.246809079201168, 0.246809079201168, 0.246809079201168], "final_y": [0.1661740690383533, 0.1661740690383533, 0.1661740690383533]}, "mutation_prompt": null}
{"id": "bccd9b94-ee57-4975-8f84-0d773b26bc3b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic adaptation and diversity restoration\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n                # Restore diversity by reinitializing some individuals\n                num_restore = int(0.1 * self.population_size)\n                restore_indices = np.random.choice(self.population_size, num_restore, replace=False)\n                population[restore_indices] = np.random.uniform(lb, ub, (num_restore, self.dim))\n                fitness[restore_indices] = [func(ind) for ind in population[restore_indices]]\n                evaluations += num_restore\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance the differential evolution by introducing diversity restoration and dynamic adaptation of control parameters to improve optimization efficiency.", "configspace": "", "generation": 92, "fitness": 0.24634508393239274, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24634508393239274, 0.24634508393239274, 0.24634508393239274], "final_y": [0.16750699760940058, 0.16750699760940058, 0.16750699760940058]}, "mutation_prompt": null}
{"id": "2006a7f0-75da-4a5b-8453-331e5be05959", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                dynamic_factor = 0.5 + 0.5 * np.sin(0.1 * evaluations)  # New: dynamic factor based on evaluations\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) +\n                                 dynamic_factor * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance adaptive scaling by incorporating a dynamic parameter adjustment inspired by swarm intelligence.", "configspace": "", "generation": 93, "fitness": 0.2460418753408844, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.2460418753408844, 0.2460418753408844, 0.2460418753408844], "final_y": [0.16490885792643306, 0.16490885792643306, 0.16490885792643306]}, "mutation_prompt": null}
{"id": "a739614d-98ca-4333-a717-787fb14e0fab", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim) + 0.01 * (np.min(fitness) / fitness[i]))  # Changed\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation scaling based on the best individual's fitness to enhance exploration.", "configspace": "", "generation": 94, "fitness": 0.24678125910113036, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24678125910113036, 0.24678125910113036, 0.24678125910113036], "final_y": [0.16582376122032338, 0.16582376122032338, 0.16582376122032338]}, "mutation_prompt": null}
{"id": "8be30e74-8842-431c-be48-421ce5a8f263", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            # Updated line\n            self.CR = 0.9 * (1 - np.std(fitness) / np.mean(fitness)) + self.adaptation_rate * (np.mean(fitness))\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic crossover rate that adjusts based on the diversity of the population to enhance exploration.", "configspace": "", "generation": 95, "fitness": 0.24621226029649823, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24621226029649823, 0.24621226029649823, 0.24621226029649823], "final_y": [0.16489690556324121, 0.16489690556324121, 0.16489690556324121]}, "mutation_prompt": null}
{"id": "ca2f991a-523f-4337-a9d3-dc3a03bd1c17", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations  # New: track initial evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)  # New: dimension-wise adaptive scaling\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))  # Changed: stochastic scaling in mutation\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR * dimension_scale  # Modified: dimension-weighted crossover\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)  # Modified: adapt CR based on fitness variance\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Enhance diversity by introducing dimension-weighted crossover and fitness-sorted dimension adjustments.", "configspace": "", "generation": 96, "fitness": 0.24446047419095795, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24446047419095795, 0.24446047419095795, 0.24446047419095795], "final_y": [0.164869341600007, 0.164869341600007, 0.164869341600007]}, "mutation_prompt": null}
{"id": "77fae7de-2f64-402e-b672-d71a0fafb335", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                stochastic_F = self.F * (1 + 0.1 * np.random.randn(self.dim))\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.1 * self.population_size))\n                top_indices = np.argsort(fitness)[:self.population_size]  # Changed: Improved selection of top individuals\n                population = population[top_indices]\n                fitness = fitness[top_indices]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic population size adjustment and improved trial vector selection based on fitness ranking.", "configspace": "", "generation": 97, "fitness": 0.246856100786914, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.246856100786914, 0.246856100786914, 0.246856100786914], "final_y": [0.16562657039986384, 0.16562657039986384, 0.16562657039986384]}, "mutation_prompt": null}
{"id": "d7c3a17f-65a2-4221-9cdc-9052df9e4034", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                stochastic_F = self.F * (1 + 0.05 * np.random.randn(self.dim))  # Adjusted: reduced mutation noise\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + self.F * (population[i] - a) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.1, 1.0)\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.1, 1.0)\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.15 * self.population_size))  # Increased reduction rate\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Implement adaptive population size reduction and enhance mutation strategy by introducing a dynamic blending of exploration and exploitation to improve convergence.", "configspace": "", "generation": 98, "fitness": 0.24674086810689433, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.24674086810689433, 0.24674086810689433, 0.24674086810689433], "final_y": [0.16545281723284566, 0.16545281723284566, 0.16545281723284566]}, "mutation_prompt": null}
{"id": "b5d2305d-75ee-4e70-8e93-6c996d4641fc", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        initial_eval = evaluations\n\n        while evaluations < self.budget:\n            inertia_factor = 1 - (evaluations - initial_eval) / (self.budget - initial_eval)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_scale = inertia_factor * 0.01 * (1 + np.var(fitness) / np.mean(fitness))\n                dimension_scale = np.random.rand(self.dim)\n                stochastic_F = self.F * (1 + 0.2 * np.random.randn(self.dim))  # Changed: increased stochastic scaling\n                mutant = np.clip(a + dimension_scale * stochastic_F * (b - c) + np.random.randn(self.dim) * noise_scale, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fit = func(trial)\n                evaluations += 1\n\n                if trial_fit < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fit\n\n                if evaluations >= self.budget:\n                    break\n\n            self.F = 0.5 + (np.var(fitness) / np.max(fitness)) ** 0.5 * self.adaptation_rate\n            self.F = np.clip(self.F * inertia_factor, 0.2, 1.0)  # Changed: adjusted F lower bound\n\n            successful_trials = fitness < np.roll(fitness, 1)\n            self.CR = self.CR + self.adaptation_rate * (np.mean(successful_trials) - np.var(successful_trials) * np.mean(fitness) * 0.5)\n            self.CR = np.clip(self.CR * (1 + np.var(fitness)), 0.2, 1.0)  # Changed: adjusted CR lower bound\n            \n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5 * self.dim, self.population_size - int(0.15 * self.population_size))  # Changed: increased reduction rate\n                population = population[np.argsort(fitness)[:self.population_size]]\n                fitness = fitness[np.argsort(fitness)[:self.population_size]]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Introduce dynamic population resizing and a variance-based mutation strategy to enhance exploration and convergence in adaptive differential evolution.", "configspace": "", "generation": 99, "fitness": 0.2435016589186335, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2596d48b-2051-463c-8f37-11ca87a49cca", "metadata": {"aucs": [0.2435016589186335, 0.2435016589186335, 0.2435016589186335], "final_y": [0.16645523531567497, 0.16645523531567497, 0.16645523531567497]}, "mutation_prompt": null}
