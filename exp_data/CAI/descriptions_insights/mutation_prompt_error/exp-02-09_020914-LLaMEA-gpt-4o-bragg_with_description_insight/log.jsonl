{"id": "52d96f08-d4bc-435b-9138-a2f0f6086459", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridOptimizationAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        opp_population = lb + ub - population\n        return np.vstack((population, opp_population))\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=bounds, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.quasi_oppositional_initialization(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.differential_evolution(population, bounds, func)\n            evaluations += len(population)\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n        best_idx = np.argmin([func(ind) for ind in population])\n        return population[best_idx]", "name": "HybridOptimizationAlgorithm", "description": "The algorithm combines global exploration using Quasi-Oppositional Differential Evolution with local exploitation using BFGS to optimize periodicity in multilayer photonic structures.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 280, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 128, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 46, in __call__\n  File \"<string>\", line 33, in local_optimization\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 670, in minimize\n    bounds = standardize_bounds(bounds, x0, 'new')\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 1058, in standardize_bounds\n    lb, ub = old_bound_to_new(bounds)\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_constraints.py\", line 433, in old_bound_to_new\n    lb, ub = zip(*bounds)\nTypeError: zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds\n.", "error": "TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds')Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 280, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 128, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 46, in __call__\n  File \"<string>\", line 33, in local_optimization\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 670, in minimize\n    bounds = standardize_bounds(bounds, x0, 'new')\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 1058, in standardize_bounds\n    lb, ub = old_bound_to_new(bounds)\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_constraints.py\", line 433, in old_bound_to_new\n    lb, ub = zip(*bounds)\nTypeError: zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "17f7008d-ad2d-4477-86ac-c65e82166e7c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "A Coevolutionary Niching Algorithm (CNA) that simultaneously evolves multiple subpopulations to cover diverse regions of the search space, encouraging solution diversity and periodicity through niche creation.", "configspace": "", "generation": 1, "fitness": 0.24676938248825167, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "52d96f08-d4bc-435b-9138-a2f0f6086459", "metadata": {"aucs": [0.24698616418130404, 0.24667663080591018, 0.24664535247754082], "final_y": [0.164856413269457, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "89986060-a96a-4d43-ba44-486c806f2c07", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius / (evaluations / self.budget)  # Adjusted niche radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Improved niche handling by adjusting niche radius dynamically to balance exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.24676938248825167, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "17f7008d-ad2d-4477-86ac-c65e82166e7c", "metadata": {"aucs": [0.24698616418130404, 0.24667663080591018, 0.24664535247754082], "final_y": [0.164856413269457, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "214d6a8b-56e3-495b-b007-5f642b01708f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n        self.decay_factor = 0.99  # Added decay factor for mutation step size\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c) * self.decay_factor, bounds.lb, bounds.ub)  # Modified line with decay factor\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "This updated Coevolutionary Niching Algorithm introduces a decay factor in mutation to enhance exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.2467550374847596, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "17f7008d-ad2d-4477-86ac-c65e82166e7c", "metadata": {"aucs": [0.24695706875541013, 0.2465860419674485, 0.24672200173142023], "final_y": [0.164856413269457, 0.16485592331782406, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "a724d8c1-19d8-4a5c-bfab-03cefce6ee1d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            # Adaptive niche radius adjustment\n            self.niche_radius *= 1.05\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "An updated Coevolutionary Niching Algorithm with adaptive niche radius to enhance exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.24676938248825167, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "17f7008d-ad2d-4477-86ac-c65e82166e7c", "metadata": {"aucs": [0.24698616418130404, 0.24667663080591018, 0.24664535247754082], "final_y": [0.164856413269457, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "9f4ba1e6-1e4d-4a53-849d-a4768afda8b8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior using stochastic ranking\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argpartition(niche_fitness, 1)[0]  # Stochastic ranking\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "An enhanced Coevolutionary Niching Algorithm (CNA) incorporating stochastic ranking to balance exploration and exploitation, improving solution quality for complex multimodal landscapes.", "configspace": "", "generation": 5, "fitness": 0.24676938248825167, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "17f7008d-ad2d-4477-86ac-c65e82166e7c", "metadata": {"aucs": [0.24698616418130404, 0.24667663080591018, 0.24664535247754082], "final_y": [0.164856413269457, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "8a413ba7-b5be-4128-bec6-43b996296ae7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='TNC')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhanced local optimization by using the 'TNC' method instead of 'L-BFGS-B' for improved convergence in the local refinement phase.", "configspace": "", "generation": 6, "fitness": 0.23740295126133826, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.004. And the mean value of best solutions found was 0.189 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "17f7008d-ad2d-4477-86ac-c65e82166e7c", "metadata": {"aucs": [0.23533477226784183, 0.24258493925314495, 0.234289142263028], "final_y": [0.18653157872275483, 0.16606478488030751, 0.21413760858002662]}, "mutation_prompt": null}
{"id": "9ec3bd83-95bd-4517-b54c-908dd43a9016", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self.evaluated_func(trial, func) < self.evaluated_func(population[i], func):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def evaluated_func(self, x, func):\n        # Penalty for deviations from periodicity\n        penalty = np.var([np.mean(x[i::2]) for i in range(2)])\n        return func(x) + penalty\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhanced fitness evaluation by incorporating a penalty for deviations from periodicity to improve convergence towards optimal solutions.", "configspace": "", "generation": 7, "fitness": 0.24603125382195212, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "17f7008d-ad2d-4477-86ac-c65e82166e7c", "metadata": {"aucs": [0.24649953490353171, 0.2451007769549619, 0.24649344960736275], "final_y": [0.16485713213353825, 0.16485602284234313, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "e136f37e-4820-4db7-b889-ee119dab8a1d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhanced differential evolution by adjusting crossover probability dynamically based on iteration progress for improved exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.24679779547917155, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "17f7008d-ad2d-4477-86ac-c65e82166e7c", "metadata": {"aucs": [0.24698640617344692, 0.2466766208380301, 0.2467303594260376], "final_y": [0.16485630681285635, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "55339d31-4957-4bf3-a36a-377f1300581c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        elite = population[np.argmin([func(ind) for ind in population])]\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return np.vstack((new_population, elite))\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduced elite preservation in the differential evolution stage for improved convergence.", "configspace": "", "generation": 9, "fitness": 0.24659178846606608, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e136f37e-4820-4db7-b889-ee119dab8a1d", "metadata": {"aucs": [0.2467592485538479, 0.246501319121601, 0.2465147977227493], "final_y": [0.16485630681285635, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "46d66b1b-c469-4b5f-8d01-12dedfcd457f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1  # Changed to dynamic adjustment based on evaluations\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius * (1.0 + evaluations / self.budget)  # Dynamic niche radius adjustment\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhanced niche diversity by adjusting niche radius dynamically to improve exploration in optimization.", "configspace": "", "generation": 10, "fitness": 0.24679779547917155, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e136f37e-4820-4db7-b889-ee119dab8a1d", "metadata": {"aucs": [0.24698640617344692, 0.2466766208380301, 0.2467303594260376], "final_y": [0.16485630681285635, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "3ae71282-b121-4cf3-8217-1fcf00eb6b06", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Changed to dynamic adjustment in differential_evolution method\n        self.CR = 0.9\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_dynamic = self.F * (1.0 - i / len(population))  # Dynamic adjustment of F\n            mutant = np.clip(a + F_dynamic * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhanced differential evolution with dynamic adjustment of both crossover probability and scaling factor for better exploration-exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.24678939696559887, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e136f37e-4820-4db7-b889-ee119dab8a1d", "metadata": {"aucs": [0.24694750294746015, 0.24669011058351276, 0.2467305773658237], "final_y": [0.16485632498843794, 0.1648559513783271, 0.16485633910363173]}, "mutation_prompt": null}
{"id": "430ef6dd-37c4-42e2-8a2f-1cf1c07ad513", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.15  # Increased niche radius to promote diversity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhanced differential evolution by promoting diversity through niche radius adjustment.", "configspace": "", "generation": 12, "fitness": 0.24679779547917155, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e136f37e-4820-4db7-b889-ee119dab8a1d", "metadata": {"aucs": [0.24698640617344692, 0.2466766208380301, 0.2467303594260376], "final_y": [0.16485630681285635, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "678a2e9f-f694-41f8-b25c-40c71a2b3f98", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Changed to dynamic adjustment\n        self.CR = 0.9\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_dynamic = self.F * (1.0 - i / len(population))  # Dynamic adjustment of F\n            mutant = np.clip(a + F_dynamic * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Improved exploration-exploitation balance by adjusting the mutation factor dynamically based on iteration progress.", "configspace": "", "generation": 13, "fitness": 0.24678939696559887, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e136f37e-4820-4db7-b889-ee119dab8a1d", "metadata": {"aucs": [0.24694750294746015, 0.24669011058351276, 0.2467305773658237], "final_y": [0.16485632498843794, 0.1648559513783271, 0.16485633910363173]}, "mutation_prompt": null}
{"id": "114b4c4e-9353-42ef-ba9e-e98e9f75a642", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.mutation_scale = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def simulated_annealing(self, x, func, bounds):\n        current_temp = self.initial_temp\n        current_solution = np.copy(x)\n        current_obj = func(current_solution)\n        \n        while current_temp > 1 and self.evaluations < self.budget:\n            # Adaptive mutation to promote exploration\n            mutation = self.mutation_scale * np.random.randn(self.dim)\n            new_solution = np.clip(current_solution + mutation, bounds.lb, bounds.ub)\n            new_obj = func(new_solution)\n            self.evaluations += 1\n            \n            # Acceptance probability\n            if new_obj < current_obj or np.exp((current_obj - new_obj) / current_temp) > np.random.rand():\n                current_solution = new_solution\n                current_obj = new_obj\n            \n            # Cool down\n            current_temp *= self.cooling_rate\n\n        return current_solution\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        self.evaluations = 0\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations < self.budget:\n                    # Simulated Annealing\n                    population[i] = self.simulated_annealing(population[i], func, bounds)\n                    \n                    if self.evaluations < self.budget:\n                        # Local optimization\n                        population[i] = self.local_optimization(population[i], func, bounds)\n                        self.evaluations += 1\n\n        # Return the best solution found\n        best_idx = np.argmin([func(ind) for ind in population])\n        return population[best_idx]", "name": "HybridSimulatedAnnealing", "description": "Hybridized Simulated Annealing with Adaptive Mutation for enhanced exploration and local refinement in complex optimization landscapes.", "configspace": "", "generation": 14, "fitness": 0.24616952062613506, "feedback": "The algorithm HybridSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e136f37e-4820-4db7-b889-ee119dab8a1d", "metadata": {"aucs": [0.24643407043898724, 0.24518773224097345, 0.2468867591984445], "final_y": [0.16485764496468414, 0.16485715229046594, 0.16485627722187357]}, "mutation_prompt": null}
{"id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Adaptive mutation factor adjustment based on population diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.24690684591164316, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e136f37e-4820-4db7-b889-ee119dab8a1d", "metadata": {"aucs": [0.2465897574294339, 0.24663001626319525, 0.24750076404230037], "final_y": [0.16485785008543985, 0.16485620555962366, 0.1648563448188196]}, "mutation_prompt": null}
{"id": "462db67f-8f26-4d6e-92ab-bab04777191f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 6  # Changed from 5 to 6 to increase diversity\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Improved exploration by increasing the number of niches to enhance diversity.", "configspace": "", "generation": 16, "fitness": 0.24635873334432987, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.246612936112788, 0.24649272789932664, 0.24597053602087493], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "78dd04fd-8f16-4134-bb09-0f1d4928447b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            self.niche_radius = np.mean(distances)  # Dynamic niche radius adjustment\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduced dynamic niche radius adjustment to enhance solution diversity and convergence speed.", "configspace": "", "generation": 17, "fitness": 0.24690684591164316, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.2465897574294339, 0.24663001626319525, 0.24750076404230037], "final_y": [0.16485785008543985, 0.16485620555962366, 0.1648563448188196]}, "mutation_prompt": null}
{"id": "466a2820-8689-417c-8d32-4d11a9d2f9c6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.6 + 0.4 * diversity)  # Enhanced adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhanced adaptive mutation factor calculation to improve exploration-exploitation trade-off.", "configspace": "", "generation": 18, "fitness": 0.2469067982605084, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.2465897574294339, 0.24663001463155187, 0.2475006227205394], "final_y": [0.16485785008543985, 0.16485620555962366, 0.16485668047782742]}, "mutation_prompt": null}
{"id": "39698508-37ae-416d-b238-a9c1a2239703", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            niche_fitness += np.random.uniform(-0.01, 0.01, niche_fitness.shape)  # Slight random noise added\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Minor enhancement in niche selection to boost local optima escape capabilities.", "configspace": "", "generation": 19, "fitness": 0.24690684591164316, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.2465897574294339, 0.24663001626319525, 0.24750076404230037], "final_y": [0.16485785008543985, 0.16485620555962366, 0.1648563448188196]}, "mutation_prompt": null}
{"id": "03009057-3777-4561-bff1-b05437ea4cf1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            sinusoidal_perturbation = np.sin(np.arange(self.dim) * 2 * np.pi / self.dim)  # New line\n            mutant = np.clip(a + F_adaptive * (b - c) + sinusoidal_perturbation, bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduce diversity by adding a sinusoidal perturbation to the mutation process within the Differential Evolution, enhancing exploration of the search space.", "configspace": "", "generation": 20, "fitness": 0.24690684293087603, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.2465897574294339, 0.24663001626319525, 0.24750075509999891], "final_y": [0.16485785008543985, 0.16485620555962366, 0.1648563448188196]}, "mutation_prompt": null}
{"id": "d4cadeb0-0758-47b6-801e-702db31cd327", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.2  # Increased niche radius for improved exploration\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhanced niche diversity by modifying niche radius for improved exploration.", "configspace": "", "generation": 21, "fitness": 0.24690684591164316, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.2465897574294339, 0.24663001626319525, 0.24750076404230037], "final_y": [0.16485785008543985, 0.16485620555962366, 0.1648563448188196]}, "mutation_prompt": null}
{"id": "c6df42c5-52fc-4d06-aada-91b442594ba1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius * np.std(all_individuals, axis=0).mean()  # Adaptive niche radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduce adaptive niche radius adjustment based on population diversity to enhance exploration in different regions of the search space.", "configspace": "", "generation": 22, "fitness": 0.24690684591164316, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.2465897574294339, 0.24663001626319525, 0.24750076404230037], "final_y": [0.16485785008543985, 0.16485620555962366, 0.1648563448188196]}, "mutation_prompt": null}
{"id": "439fd19d-185c-438b-9c14-135dc7c0552b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage unique niche population selection behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Improved niche behavior by ensuring unique niche population selection to enhance diversity.", "configspace": "", "generation": 23, "fitness": 0.24690684591164316, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.2465897574294339, 0.24663001626319525, 0.24750076404230037], "final_y": [0.16485785008543985, 0.16485620555962366, 0.1648563448188196]}, "mutation_prompt": null}
{"id": "b9c378c9-2af9-4d93-a7a7-321b3a93e41b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            # Introduce niche-adaptive differential weight\n            self.F *= 1 + 0.1 * (1 - niche_fitness.std())\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduce a niche-adaptive differential weight to enhance diversity handling based on niche fitness.", "configspace": "", "generation": 24, "fitness": 0.24690684591164316, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.2465897574294339, 0.24663001626319525, 0.24750076404230037], "final_y": [0.16485785008543985, 0.16485620555962366, 0.1648563448188196]}, "mutation_prompt": null}
{"id": "027125dc-dbbb-4ded-ae8e-053b9f35c807", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            self.niche_radius = 0.1 * (1 + np.std(all_individuals))  # Adaptive niche radius based on diversity\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduced adaptive niche radius scaling based on diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 25, "fitness": 0.24690684591164316, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.2465897574294339, 0.24663001626319525, 0.24750076404230037], "final_y": [0.16485785008543985, 0.16485620555962366, 0.1648563448188196]}, "mutation_prompt": null}
{"id": "ee7a5fab-9196-451f-8693-91c72302c329", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < CR_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius * (1 + np.std(all_individuals))  # Adjusted niche radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduce an adaptive niche radius to improve exploration within diverse fitness landscapes.", "configspace": "", "generation": 26, "fitness": 0.24690684591164316, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.2465897574294339, 0.24663001626319525, 0.24750076404230037], "final_y": [0.16485785008543985, 0.16485620555962366, 0.1648563448188196]}, "mutation_prompt": null}
{"id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduced a probability-based crossover scheme to improve exploration in the differential evolution phase.", "configspace": "", "generation": 27, "fitness": 0.24706887570345237, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "487d8a72-b62e-49f4-9b2e-85c8c8fd96ed", "metadata": {"aucs": [0.24698558897726397, 0.2467541369498173, 0.24746690118327586], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "0705ec20-6927-4019-a88a-b4cbe1ab39d5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedCoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n        all_individuals = np.vstack(subpopulations)\n        \n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n            if evaluations >= self.budget:\n                break\n\n            # Adaptive niche management\n            cluster_centers = np.mean(all_individuals.reshape(self.niches, -1, self.dim), axis=1)\n            cluster_distances = np.linalg.norm(cluster_centers[:, np.newaxis, :] - cluster_centers[np.newaxis, :, :], axis=2)\n            min_distances = np.min(cluster_distances + np.eye(self.niches) * np.max(cluster_distances), axis=1)\n            adaptive_radius = np.mean(min_distances) * 0.7\n            self.niche_radius = max(adaptive_radius, 0.1)  # Prevents collapse to zero\n\n        return all_individuals[best_niche_idx]", "name": "EnhancedCoevolutionaryNichingAlgorithm", "description": "Enhanced exploration-exploitation through adaptive niche dynamics and multi-modal search integration.", "configspace": "", "generation": 28, "fitness": 0.24706887570345237, "feedback": "The algorithm EnhancedCoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "metadata": {"aucs": [0.24698558897726397, 0.2467541369498173, 0.24746690118327586], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "e72cb43c-b566-4d12-97db-08088c47e122", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < (self.niche_radius * (1 + np.std(all_individuals)))  # Self-adaptive niche radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhanced exploration by introducing a self-adaptive niche radius to improve diversity.", "configspace": "", "generation": 29, "fitness": 0.24706887570345237, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "metadata": {"aucs": [0.24698558897726397, 0.2467541369498173, 0.24746690118327586], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "d636c27b-e006-4836-bc1e-c24f7b24af6b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.15  # Increased niche radius\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Improved the niching strategy by slightly increasing the niche radius to better encourage diverse exploration across niches.", "configspace": "", "generation": 30, "fitness": 0.24706887570345237, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "metadata": {"aucs": [0.24698558897726397, 0.2467541369498173, 0.24746690118327586], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "3e848460-43e1-4ff0-a675-718415a3c02f", "solution": "# Description: Enhanced the local optimization step by including a periodic solution initialization to exploit known solution traits.\n# Code:\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        periodic_solution = np.tile(np.array([1.4, 1.8]), self.dim // 2)[:self.dim]\n        x0 = 0.5 * (x0 + periodic_solution)  # Blend initialization with periodic solution\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhanced the local optimization step by including a periodic solution initialization to exploit known solution traits.", "configspace": "", "generation": 31, "fitness": 0.23515646194345916, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.235 with standard deviation 0.009. And the mean value of best solutions found was 0.196 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "metadata": {"aucs": [0.24735496050800643, 0.2243704759279067, 0.2337439493944643], "final_y": [0.16485637983903223, 0.2578101557173571, 0.16485601899522662]}, "mutation_prompt": null}
{"id": "7285370c-7ed6-43b1-a57e-8a9de511877a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            self.niche_radius = 0.05 + 0.05 * np.std(all_individuals)  # Dynamically adjust niche radius\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Improved exploration by dynamically adjusting niche radius based on diversity.", "configspace": "", "generation": 32, "fitness": 0.24706887570345237, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "metadata": {"aucs": [0.24698558897726397, 0.2467541369498173, 0.24746690118327586], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "529a9088-5922-43ea-974b-e0e3d79a315a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduced niche-based elitism to retain top individuals from each niche, enhancing convergence speed.", "configspace": "", "generation": 33, "fitness": 0.24706887570345237, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "metadata": {"aucs": [0.24698558897726397, 0.2467541369498173, 0.24746690118327586], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "7d7cc0c4-8a1b-449d-b494-4f7ba65215e6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            self.niche_radius = 0.1 + 0.1 * np.std(distances)  # Adaptive niche radius based on diversity\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Implemented adaptive niche radius to dynamically adjust exploration focus based on population diversity.", "configspace": "", "generation": 34, "fitness": 0.24706887570345237, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "metadata": {"aucs": [0.24698558897726397, 0.2467541369498173, 0.24746690118327586], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "aae87de6-86da-4bfe-b548-22851a9469cd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior with local fitness sharing\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduced a local fitness sharing mechanism to promote diverse solutions within niches.", "configspace": "", "generation": 35, "fitness": 0.24706887570345237, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "metadata": {"aucs": [0.24698558897726397, 0.2467541369498173, 0.24746690118327586], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "ca03beed-b730-4fbf-8772-c0fd22718e02", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.niche_radius = 0.1 + 0.9 * evaluations / self.budget  # Dynamic niche radius adjustment\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduced a dynamic niche radius adjustment for improved exploration-exploitation balance.", "configspace": "", "generation": 36, "fitness": 0.24706887570345237, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "metadata": {"aucs": [0.24698558897726397, 0.2467541369498173, 0.24746690118327586], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "2f6ed826-3614-4003-9497-512e10bf3e0a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.05  # Adjusted niche radius for better exploration\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhanced niche behavior by adjusting niche radius to improve solution diversity.", "configspace": "", "generation": 37, "fitness": 0.24706887570345237, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "metadata": {"aucs": [0.24698558897726397, 0.2467541369498173, 0.24746690118327586], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "c2ac5fc0-6747-4601-b285-fa45bbcb4c02", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c) + self.F * np.random.rand(*a.shape) * (np.mean(population, axis=0) - a), bounds.lb, bounds.ub)  # Diversity-promoting mutation\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhance diversity in the differential evolution step by introducing a diversity-promoting mutation strategy.", "configspace": "", "generation": 38, "fitness": 0.2470997827723913, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "14278acc-f3ff-48e7-96ad-34caeca8b33e", "metadata": {"aucs": [0.2469274624553517, 0.2469047840912154, 0.24746710177060682], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "f9537425-827d-4617-b8de-395e7f7a0afd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        best_individual = population[np.argmin([func(ind) for ind in population])]  # Elitism: Keep the best individual\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c) + self.F * np.random.rand(*a.shape) * (np.mean(population, axis=0) - a), bounds.lb, bounds.ub)  # Diversity-promoting mutation\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        new_population[0] = best_individual  # Elitism: Retain the best individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduce elitism to retain the best individual in each niche during the differential evolution step.", "configspace": "", "generation": 39, "fitness": 0.2471328221310413, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c2ac5fc0-6747-4601-b285-fa45bbcb4c02", "metadata": {"aucs": [0.2462577177102634, 0.24753197929514992, 0.2476087693877106], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "3141ff74-1b07-4471-af28-38e1341bab7e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        best_individual = population[np.argmin([func(ind) for ind in population])]  # Elitism: Keep the best individual\n        top_5_percent_mean = np.mean(sorted(population, key=func)[:max(1, len(population)//20)], axis=0)  # Calculate mean of top 5%\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c) + self.F * np.random.rand(*a.shape) * (top_5_percent_mean - a), bounds.lb, bounds.ub)  # Use mean of top 5%\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        new_population[0] = best_individual  # Elitism: Retain the best individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhance niche exploitation by incorporating the mean of the top 5% of individuals to guide mutation.", "configspace": "", "generation": 40, "fitness": 0.2469068178446826, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9537425-827d-4617-b8de-395e7f7a0afd", "metadata": {"aucs": [0.2459973977925679, 0.24732385713967064, 0.24739919860180926], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "eaaea8ef-42cb-45db-8612-4b71b5262816", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        best_individual = population[np.argmin([func(ind) for ind in population])]  # Elitism: Keep the best individual\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c) + self.F * np.random.rand(*a.shape) * (np.mean(population, axis=0) - a), bounds.lb, bounds.ub)  # Diversity-promoting mutation\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        new_population[0] = best_individual  # Elitism: Retain the best individual\n        return np.array(new_population)  # Ensure new_population is a numpy array\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Refine mutation strategy by incorporating adaptive crossover probability, enhancing diversity and convergence.", "configspace": "", "generation": 41, "fitness": 0.2471328221310413, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9537425-827d-4617-b8de-395e7f7a0afd", "metadata": {"aucs": [0.2462577177102634, 0.24753197929514992, 0.2476087693877106], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "ff0d8aeb-c9f0-42bb-80df-23c619f28b12", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        best_individual = population[np.argmin([func(ind) for ind in population])]  # Elitism: Keep the best individual\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c) + self.F * np.random.rand(*a.shape) * (np.mean(population, axis=0) - a), bounds.lb, bounds.ub)  # Diversity-promoting mutation\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        new_population[0] = best_individual  # Elitism: Retain the best individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < (self.niche_radius * np.std(all_individuals))  # Dynamic niche radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Improve convergence by adjusting niche radius dynamically based on population diversity.", "configspace": "", "generation": 42, "fitness": 0.2471328221310413, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9537425-827d-4617-b8de-395e7f7a0afd", "metadata": {"aucs": [0.2462577177102634, 0.24753197929514992, 0.2476087693877106], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "8174efe9-9c00-477c-9066-5fb673ca870c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        best_individual = population[np.argmin([func(ind) for ind in population])]  # Elitism: Keep the best individual\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c) + self.F * np.random.rand(*a.shape) * (np.mean(population, axis=0) - a), bounds.lb, bounds.ub)  # Diversity-promoting mutation\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        new_population[0] = best_individual  # Elitism: Retain the best individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            # Redistribute underperforming individuals\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduce niche rebalance by redistributing underperforming individuals to better-performing niches to enhance global exploration.", "configspace": "", "generation": 43, "fitness": 0.2471328221310413, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9537425-827d-4617-b8de-395e7f7a0afd", "metadata": {"aucs": [0.2462577177102634, 0.24753197929514992, 0.2476087693877106], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "4a2d0db3-0670-450a-9628-4e786f2a4a64", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        best_individual = population[np.argmin([func(ind) for ind in population])]  # Elitism: Keep the best individual\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c) + self.F * np.random.rand(*a.shape) * (np.mean(population, axis=0) - a), bounds.lb, bounds.ub)  # Diversity-promoting mutation\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        new_population[0] = best_individual  # Elitism: Retain the best individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        x0 += np.random.normal(0, 0.1, x0.shape)  # Random perturbation to escape local optima\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhance exploration by introducing random perturbations in local optimization to escape local optima.", "configspace": "", "generation": 44, "fitness": 0.2471256922452996, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9537425-827d-4617-b8de-395e7f7a0afd", "metadata": {"aucs": [0.24626813545159343, 0.24750043201083827, 0.24760850927346711], "final_y": [0.164856233380695, 0.16485587485001896, 0.16485767230603143]}, "mutation_prompt": null}
{"id": "c17faa59-6965-45eb-b94c-2ea5162192b9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Reduced to enhance broader exploration\n        self.CR = 0.9\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.6 + 0.4 * diversity)  # Adjusted F formula for dynamic exploration\n        best_individual = population[np.argmin([func(ind) for ind in population])]\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            CR_dynamic = self.CR * (1.0 - i / len(population))\n            cross_points = np.random.rand(self.dim) < (0.4 + CR_dynamic / 2)  # Adjusted crossover probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        new_population[0] = best_individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Enhance adaptive features and modularity in CoevolutionaryNichingAlgorithm to improve exploration and exploitation balance.", "configspace": "", "generation": 45, "fitness": 0.2470353808410706, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9537425-827d-4617-b8de-395e7f7a0afd", "metadata": {"aucs": [0.24596546861376034, 0.2475319045217409, 0.2476087693877106], "final_y": [0.16485728269453037, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "0ff05926-b22e-46b2-bc6c-512dbb7724d9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        best_individual = population[np.argmin([func(ind) for ind in population])]  # Elitism: Keep the best individual\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c) + self.F * np.random.rand(*a.shape) * (np.mean(population, axis=0) - a), bounds.lb, bounds.ub)  # Diversity-promoting mutation\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        new_population[0] = best_individual  # Elitism: Retain the best individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < (self.niche_radius * (1 + np.std(all_individuals)))  # Adaptive niche radius adjustment\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduce adaptive niche radius adjustment to dynamically manage niche size based on population diversity.", "configspace": "", "generation": 46, "fitness": 0.2471328221310413, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9537425-827d-4617-b8de-395e7f7a0afd", "metadata": {"aucs": [0.2462577177102634, 0.24753197929514992, 0.2476087693877106], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "d4f98739-f8b0-4b55-9b57-8124c23f3cb2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        best_individual = population[np.argmin([func(ind) for ind in population])]  # Elitism: Keep the best individual\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c) + self.F * np.random.rand(*a.shape) * (np.mean(population, axis=0) - a), bounds.lb, bounds.ub)  # Diversity-promoting mutation\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        new_population[0] = best_individual  # Elitism: Retain the best individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            self.niche_radius = np.std(all_individuals) * 0.1  # Adaptive niche radius calculation\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduce adaptive niche radius to enhance exploration and convergence dynamics.", "configspace": "", "generation": 47, "fitness": 0.2471328221310413, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9537425-827d-4617-b8de-395e7f7a0afd", "metadata": {"aucs": [0.2462577177102634, 0.24753197929514992, 0.2476087693877106], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "0a4e9c04-3132-495e-8da2-6d21e98e5105", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        best_individual = population[np.argmin([func(ind) for ind in population])]  # Elitism: Keep the best individual\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c) + self.F * np.random.rand(*a.shape) * (np.mean(population, axis=0) - a), bounds.lb, bounds.ub)  # Diversity-promoting mutation\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        new_population[0] = best_individual  # Elitism: Retain the best individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduce periodicity enforcement by modifying the crossover step in the differential evolution to favor periodic solutions.", "configspace": "", "generation": 48, "fitness": 0.2471328221310413, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9537425-827d-4617-b8de-395e7f7a0afd", "metadata": {"aucs": [0.2462577177102634, 0.24753197929514992, 0.2476087693877106], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "d544bb91-a575-4cf0-a6b6-c6a780db2010", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5  # Adaptive adjustment in differential_evolution method\n        self.CR = 0.9  # Changed to dynamic adjustment in differential_evolution method\n        self.niche_radius = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)  # Adaptive adjustment of F\n        best_individual = population[np.argmin([func(ind) for ind in population])]  # Elitism: Keep the best individual\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F_adaptive * (b - c) + self.F * np.random.rand(*a.shape) * (np.mean(population, axis=0) - a) * (i % 3 + 1), bounds.lb, bounds.ub)  # Niche-specific mutation\n            CR_dynamic = self.CR * (1.0 - i / len(population))  # Dynamic adjustment of CR\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)  # Probability-based crossover scheme\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n        new_population[0] = best_individual  # Elitism: Retain the best individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "CoevolutionaryNichingAlgorithm", "description": "Introduce niche-specific mutation strategies to enhance diversity within each niche.", "configspace": "", "generation": 49, "fitness": 0.24714023792635975, "feedback": "The algorithm CoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9537425-827d-4617-b8de-395e7f7a0afd", "metadata": {"aucs": [0.24627996500335958, 0.24753197938800908, 0.2476087693877106], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "57d88e3a-27aa-44e6-aa12-0fb90f7a14cb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedCoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n        self.niche_radius_decay = 0.99  # Adaptive niche radius decay\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity)\n        best_individual = population[np.argmin([func(ind) for ind in population])]\n\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            # Multi-strategy mutation\n            if np.random.rand() < 0.5:\n                mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            else:\n                mutant = np.clip(a + F_adaptive * (a - b + c - np.mean(population, axis=0)), bounds.lb, bounds.ub)\n\n            CR_dynamic = self.CR * (1.0 - i / len(population))\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        new_population[0] = best_individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior with adaptive niche radius\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            self.niche_radius *= self.niche_radius_decay  # Decay the niche radius for balancing exploration vs exploitation\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "EnhancedCoevolutionaryNichingAlgorithm", "description": "Implement adaptive niche radii and multi-strategy mutation operators to enhance exploration and exploitation balance.", "configspace": "", "generation": 50, "fitness": 0.2471901909374836, "feedback": "The algorithm EnhancedCoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d544bb91-a575-4cf0-a6b6-c6a780db2010", "metadata": {"aucs": [0.246413447327693, 0.24753198926302988, 0.24762513622172788], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "a6952072-72af-4dc0-91a2-9c6295044b57", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedCoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n        self.niche_radius_decay = 0.99  # Adaptive niche radius decay\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity / self.niche_radius)  # Adjust F based on niche radius\n        best_individual = population[np.argmin([func(ind) for ind in population])]\n\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            # Multi-strategy mutation\n            if np.random.rand() < 0.5:\n                mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            else:\n                mutant = np.clip(a + F_adaptive * (a - b + c - np.mean(population, axis=0)), bounds.lb, bounds.ub)\n\n            CR_dynamic = self.CR * (1.0 - i / len(population))\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        new_population[0] = best_individual\n        return new_population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            # Encourage niche behavior with adaptive niche radius\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            self.niche_radius *= self.niche_radius_decay  # Decay the niche radius for balancing exploration vs exploitation\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "EnhancedCoevolutionaryNichingAlgorithm", "description": "Introduce a diversity-enhancing strategy by adjusting mutation scale factor (`self.F`) based on niche radius to improve exploration.", "configspace": "", "generation": 51, "fitness": 0.24719019096843664, "feedback": "The algorithm EnhancedCoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "57d88e3a-27aa-44e6-aa12-0fb90f7a14cb", "metadata": {"aucs": [0.246413447327693, 0.24753198935588905, 0.24762513622172788], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "da1f746a-14fe-47ef-bfd1-0ba301bc730c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedCoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n        self.niche_radius_decay = 0.97  # More gradual decay\n        self.periodicity_enforcement = 0.1  # New parameter for periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity / self.niche_radius)\n        best_individual = population[np.argmin([func(ind) for ind in population])]\n\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            if np.random.rand() < 0.5:\n                mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            else:\n                mutant = np.clip(a + F_adaptive * (a - b + c - np.mean(population, axis=0)), bounds.lb, bounds.ub)\n\n            CR_dynamic = self.CR * (1.0 - i / len(population))\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)  # Apply periodicity enforcement\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            self.niche_radius *= self.niche_radius_decay\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "EnhancedCoevolutionaryNichingAlgorithm", "description": "Integrates adaptive periodicity enforcement and multi-niche reinforcement to improve solution quality and diversity.", "configspace": "", "generation": 52, "fitness": 0.24719026035930006, "feedback": "The algorithm EnhancedCoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a6952072-72af-4dc0-91a2-9c6295044b57", "metadata": {"aucs": [0.2464134505547415, 0.24753198883993854, 0.24762534168322015], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "d0bccad4-4d12-46bb-ac33-c269a2f41111", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedCoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n        self.niche_radius_decay = 0.97  # More gradual decay\n        self.periodicity_enforcement = 0.2  # Updated parameter for periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity / self.niche_radius)\n        best_individual = population[np.argmin([func(ind) for ind in population])]\n\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            if np.random.rand() < 0.5:\n                mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            else:\n                mutant = np.clip(a + F_adaptive * (a - b + c - np.mean(population, axis=0)), bounds.lb, bounds.ub)\n\n            CR_dynamic = self.CR * (1.0 - i / len(population))\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)  # Apply periodicity enforcement\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            self.niche_radius *= self.niche_radius_decay\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "EnhancedCoevolutionaryNichingAlgorithm", "description": "Optimize reflective structures using enhanced periodicity enforcement and niche adaptation.", "configspace": "", "generation": 53, "fitness": 0.24719032862067924, "feedback": "The algorithm EnhancedCoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "da1f746a-14fe-47ef-bfd1-0ba301bc730c", "metadata": {"aucs": [0.24641345019618055, 0.24753198944874832, 0.24762554621710886], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "f1c75149-50a9-49ca-81c4-e51f447a7306", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedCoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n        self.niche_radius_decay = 0.97  # More gradual decay\n        self.periodicity_enforcement = 0.2  # Updated parameter for periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.5 + 0.5 * diversity / self.niche_radius)\n        best_individual = population[np.argmin([func(ind) for ind in population])]\n\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            if np.random.rand() < 0.5:\n                mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            else:\n                mutant = np.clip(a + F_adaptive * (a - b + c - np.mean(population, axis=0)), bounds.lb, bounds.ub)\n\n            CR_dynamic = self.CR * (1.0 - i / len(population))\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)  # Apply periodicity enforcement\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'disp': True})\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            self.niche_radius *= self.niche_radius_decay\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "EnhancedCoevolutionaryNichingAlgorithm", "description": "Enhance local exploitation by incorporating adaptive momentum in local optimization step.", "configspace": "", "generation": 54, "fitness": 0.24719032862067924, "feedback": "The algorithm EnhancedCoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d0bccad4-4d12-46bb-ac33-c269a2f41111", "metadata": {"aucs": [0.24641345019618055, 0.24753198944874832, 0.24762554621710886], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "883fc29d-d189-49ab-bc7a-4c2061ba1a03", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedCoevolutionaryNichingAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.niches = 5\n        self.F = 0.5\n        self.CR = 0.9\n        self.niche_radius = 0.1\n        self.niche_radius_decay = 0.95  # More gradual decay\n        self.periodicity_enforcement = 0.3  # Updated parameter for periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return [lb + (ub - lb) * np.random.rand(self.population_size, self.dim) for _ in range(self.niches)]\n\n    def differential_evolution(self, population, bounds, func):\n        new_population = np.copy(population)\n        diversity = np.std(population, axis=0).mean()\n        F_adaptive = self.F * (0.3 + 0.7 * diversity / self.niche_radius)\n        best_individual = population[np.argmin([func(ind) for ind in population])]\n\n        for i in range(len(population)):\n            idxs = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            if np.random.rand() < 0.5:\n                mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            else:\n                mutant = np.clip(a + F_adaptive * (a - b + c - np.mean(population, axis=0)), bounds.lb, bounds.ub)\n\n            CR_dynamic = self.CR * (1.0 - i / len(population))\n            cross_points = np.random.rand(self.dim) < (0.5 + CR_dynamic / 2)\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)  # Apply periodicity enforcement\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        subpopulations = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.niches):\n                subpopulations[i] = self.differential_evolution(subpopulations[i], bounds, func)\n                evaluations += len(subpopulations[i])\n\n                if evaluations < self.budget:\n                    for j in range(len(subpopulations[i])):\n                        subpopulations[i][j] = self.local_optimization(subpopulations[i][j], func, bounds)\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n            all_individuals = np.vstack(subpopulations)\n            distances = np.linalg.norm(all_individuals[:, np.newaxis, :] - all_individuals[np.newaxis, :, :], axis=2)\n            niche_mask = distances < self.niche_radius\n            niche_fitness = np.array([np.mean([func(ind) for ind in all_individuals[niche_mask[i]]]) for i in range(len(all_individuals))])\n            best_niche_idx = np.argmin(niche_fitness)\n\n            self.niche_radius *= self.niche_radius_decay\n\n            if evaluations >= self.budget:\n                break\n\n        return all_individuals[best_niche_idx]", "name": "EnhancedCoevolutionaryNichingAlgorithm", "description": "Improved periodicity enforcement and adaptive niche management for enhanced Bragg mirror optimization.", "configspace": "", "generation": 55, "fitness": 0.24719039637897866, "feedback": "The algorithm EnhancedCoevolutionaryNichingAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d0bccad4-4d12-46bb-ac33-c269a2f41111", "metadata": {"aucs": [0.24641345019618055, 0.24753198911851626, 0.24762574982223917], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "4b42f8c4-317e-4dd6-a7a3-ca055669f4a2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.6\n        self.CR = 0.7\n        self.periodicity_enforcement = 0.4\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Hybrid Symbiotic Algorithm integrating cooperative coevolution and adaptive periodic enforcement for enhanced global exploration and solution refinement.", "configspace": "", "generation": 56, "fitness": 0.24738407509105684, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "883fc29d-d189-49ab-bc7a-4c2061ba1a03", "metadata": {"aucs": [0.24706313854179995, 0.24761798405533475, 0.24747110267603578], "final_y": [0.1648565931434084, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "5c343e16-454b-4235-9d36-b88b284c5b03", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.6\n        self.CR = 0.7\n        self.periodicity_enforcement = 0.5  # Increased from 0.4 to 0.5 for enhanced periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced global exploration through increased periodicity enforcement factor for improved optimization performance.", "configspace": "", "generation": 57, "fitness": 0.24738450069550832, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4b42f8c4-317e-4dd6-a7a3-ca055669f4a2", "metadata": {"aucs": [0.24705333595068657, 0.24762901382734037, 0.24747115230849803], "final_y": [0.1648565157910472, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "0dd3e57a-1f70-40d1-8dd6-967edcaa6b20", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.6\n        self.CR = 0.75  # Increased from 0.7 to 0.75 for improved exploration\n        self.periodicity_enforcement = 0.5  # Increased from 0.4 to 0.5 for enhanced periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced exploration by slightly increasing the crossover rate to improve optimization performance.", "configspace": "", "generation": 58, "fitness": 0.24642384179293284, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5c343e16-454b-4235-9d36-b88b284c5b03", "metadata": {"aucs": [0.24416223392041725, 0.2476290903687567, 0.24748020108962454], "final_y": [0.1648565157910472, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "689bbfcf-ea19-46d0-a618-ad8ddcc75377", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.6\n        self.CR = 0.8  # Changed from 0.7 to 0.8 for enhanced local exploitation\n        self.periodicity_enforcement = 0.5\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced local exploitation by increasing crossover rate for improved convergence performance in optimization.", "configspace": "", "generation": 59, "fitness": 0.24622452514574714, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5c343e16-454b-4235-9d36-b88b284c5b03", "metadata": {"aucs": [0.24721095808494353, 0.24766420250709464, 0.24379841484520326], "final_y": [0.1648565157910472, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "b5b39d56-dcd6-4fda-a3ea-739f565e085b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.6\n        self.CR = 0.7\n        self.periodicity_enforcement = 0.5  # Increased from 0.4 to 0.5 for enhanced periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = (2 * np.pi / (bounds.ub - bounds.lb)) * (1 + np.random.uniform(-0.05, 0.05))  # Adaptive frequency adjustment\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced periodicity enforcement through adaptive frequency adjustment for improved optimization performance.", "configspace": "", "generation": 60, "fitness": 0.24693579950862346, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5c343e16-454b-4235-9d36-b88b284c5b03", "metadata": {"aucs": [0.24697130886785912, 0.24738749728302423, 0.24644859237498706], "final_y": [0.16485596301364658, 0.1648559756560113, 0.1648561098476906]}, "mutation_prompt": null}
{"id": "2e7973c1-950a-424a-a351-0afe0ac169de", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.6\n        self.CR = 0.7\n        self.periodicity_enforcement = 0.55  # Increased from 0.5 to 0.55 for enhanced periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Refine periodicity enforcement by increasing the periodicity enforcement factor slightly for better optimization performance.", "configspace": "", "generation": 61, "fitness": 0.24738302627188777, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5c343e16-454b-4235-9d36-b88b284c5b03", "metadata": {"aucs": [0.24705831662398325, 0.2476195852594587, 0.24747117693222132], "final_y": [0.16485728269453037, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "9a764e44-517e-4e10-a5f0-aefe76e39ace", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.6\n        self.CR = 0.7\n        self.periodicity_enforcement = 0.5\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb).mean()  # Changed line\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced periodicity enforcement by adjusting frequency calculation to improve convergence in multilayered photonic structure optimization.", "configspace": "", "generation": 62, "fitness": 0.24738450069550832, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5c343e16-454b-4235-9d36-b88b284c5b03", "metadata": {"aucs": [0.24705333595068657, 0.24762901382734037, 0.24747115230849803], "final_y": [0.1648565157910472, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "f1f1653c-43bc-45d7-84c1-48e5304c28c8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted from 0.6 to 0.8 for improved exploration\n        self.CR = 0.7\n        self.periodicity_enforcement = 0.5  # Increased from 0.4 to 0.5 for enhanced periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Improved exploration by adjusting mutation factor F for better convergence.", "configspace": "", "generation": 63, "fitness": 0.24751903481795948, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5c343e16-454b-4235-9d36-b88b284c5b03", "metadata": {"aucs": [0.24746279894441015, 0.24762859785920166, 0.24746570765026665], "final_y": [0.16485699275897603, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "a2cf58d7-4331-4cc7-9dbd-74a3a7a18512", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted from 0.6 to 0.8 for improved exploration\n        self.CR = 0.75  # Fine-tuned crossover rate from 0.7 to 0.75\n        self.periodicity_enforcement = 0.5  # Increased from 0.4 to 0.5 for enhanced periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhance algorithm performance by fine-tuning crossover rate for better exploration-exploitation balance.", "configspace": "", "generation": 64, "fitness": 0.24755522597917887, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f1f1653c-43bc-45d7-84c1-48e5304c28c8", "metadata": {"aucs": [0.24746219973868278, 0.24775158211285253, 0.24745189608600127], "final_y": [0.16485699275897603, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "1f0e9308-8c82-410a-809b-6bd90d1a231b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = max(1, dim // 3)  # Changed from dim // 2 to dim // 3\n        self.F = 0.5 + 0.3 * np.random.rand()  # Adjusted to be adaptive with random factor\n        self.CR = 0.75\n        self.periodicity_enforcement = 0.5\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Incorporate adaptive mutation factor and dynamic subgroup size to enhance exploration and convergence efficiency.", "configspace": "", "generation": 65, "fitness": 0.24690504892971746, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a2cf58d7-4331-4cc7-9dbd-74a3a7a18512", "metadata": {"aucs": [0.2472603484902688, 0.2471062112798883, 0.2463485870189953], "final_y": [0.16485617047007506, 0.1648562824806621, 0.16485612278534267]}, "mutation_prompt": null}
{"id": "e8a1b605-e4ec-4892-ac1d-7fcd8c241f1d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 3  # Adjusted from dim // 2 to dim // 3 for improved exploration-exploitation balance\n        self.F = 0.8\n        self.CR = 0.75\n        self.periodicity_enforcement = 0.5\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Refine the symbiotic optimization by adjusting subgroup size for enhanced exploration and exploitation balance.", "configspace": "", "generation": 66, "fitness": 0.2472953024963929, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a2cf58d7-4331-4cc7-9dbd-74a3a7a18512", "metadata": {"aucs": [0.24689791262459937, 0.2475396840658891, 0.24744831079869023], "final_y": [0.16485632498843794, 0.16485620555962366, 0.1648561169260795]}, "mutation_prompt": null}
{"id": "3b63aad8-9c1e-43a2-8ced-cb03d672acfd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted from 0.6 to 0.8 for improved exploration\n        self.CR = 0.75  # Fine-tuned crossover rate from 0.7 to 0.75\n        self.periodicity_enforcement = 0.5  # Increased from 0.4 to 0.5 for enhanced periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='TNC')  # Changed from L-BFGS-B to TNC for improved convergence\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Refine local optimization strategy for enhanced convergence on difficult optimization landscapes.", "configspace": "", "generation": 67, "fitness": 0.24125972572355361, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.241 with standard deviation 0.004. And the mean value of best solutions found was 0.188 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "a2cf58d7-4331-4cc7-9dbd-74a3a7a18512", "metadata": {"aucs": [0.2427269602066362, 0.24560053119636782, 0.23545168576765685], "final_y": [0.18239889716010127, 0.16606478488030751, 0.21413760858002662]}, "mutation_prompt": null}
{"id": "20674f8a-f250-4a9b-bd85-ddab9bde7aa3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted from 0.6 to 0.8 for improved exploration\n        self.CR = 0.75  # Fine-tuned crossover rate from 0.7 to 0.75\n        self.periodicity_enforcement = 0.6  # Changed from 0.5 to 0.6 for adaptive periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Leverage adaptive periodicity enforcement for enhanced convergence in hybrid symbiotic optimization.", "configspace": "", "generation": 68, "fitness": 0.24755601556914517, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a2cf58d7-4331-4cc7-9dbd-74a3a7a18512", "metadata": {"aucs": [0.2474626679480314, 0.24775341299961728, 0.24745196575978678], "final_y": [0.16485728269453037, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "530e4963-aea0-4cd4-badb-f4efa6dc12e8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted from 0.6 to 0.8 for improved exploration\n        self.CR = 0.78  # Changed from 0.75 to 0.78 for enhanced diversity\n        self.periodicity_enforcement = 0.65  # Modified from 0.6 to 0.65 for better periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Slightly adjust periodicity enforcement and crossover rate for improved search effectiveness.", "configspace": "", "generation": 69, "fitness": 0.24737183617713224, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "20674f8a-f250-4a9b-bd85-ddab9bde7aa3", "metadata": {"aucs": [0.2469092529746384, 0.24775425510082705, 0.2474520004559313], "final_y": [0.16485728269453037, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "340c6b0e-33b3-4be8-9bf7-1e859723bfa1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted from 0.6 to 0.8 for improved exploration\n        self.CR = 0.75  # Fine-tuned crossover rate from 0.7 to 0.75\n        self.periodicity_enforcement = 0.6  # Changed from 0.5 to 0.6 for adaptive periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < np.random.uniform(0.7, 0.9)  # Adaptive crossover rate\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Introduce adaptive crossover rates for enhanced exploration and exploitation balance.", "configspace": "", "generation": 70, "fitness": 0.24726112263577163, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "20674f8a-f250-4a9b-bd85-ddab9bde7aa3", "metadata": {"aucs": [0.24694422881433298, 0.24737363520361877, 0.24746550388936317], "final_y": [0.16485751310148167, 0.16485620555962366, 0.1648560329628227]}, "mutation_prompt": null}
{"id": "7f976dbb-9878-4cf3-ab6c-7610f63fa3fa", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 65  # Adjusted from 60 to 65 for improved exploration\n        self.subgroup_size = dim // 2\n        self.F = 0.8\n        self.CR = 0.75\n        self.periodicity_enforcement = 0.6\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhance exploration by increasing population size for diversity in HybridSymbioticAlgorithm.", "configspace": "", "generation": 71, "fitness": 0.24693319196963512, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "20674f8a-f250-4a9b-bd85-ddab9bde7aa3", "metadata": {"aucs": [0.24608471136554932, 0.24732616089834747, 0.24738870364500853], "final_y": [0.16485628427303378, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "72421e8d-9c8f-429c-b286-f1714304a7c3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 3  # Adjusted from dim // 2 to dim // 3 for better diversity\n        self.F = 0.8\n        self.CR = 0.75\n        self.periodicity_enforcement = 0.7  # Changed from 0.6 to 0.7 for enhanced periodicity handling\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhance convergence by adjusting periodicity enforcement and subgroup size to better exploit problem structure.", "configspace": "", "generation": 72, "fitness": 0.24729702005987694, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "20674f8a-f250-4a9b-bd85-ddab9bde7aa3", "metadata": {"aucs": [0.24690659910161072, 0.24753607977053171, 0.24744838130748836], "final_y": [0.16485632498843794, 0.16485613144574218, 0.1648561094397244]}, "mutation_prompt": null}
{"id": "4b0cb372-ec1d-4493-8aa3-4ad1305cb6c3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.9  # Adjust factor for improved exploration\n        self.CR = 0.8  # Increase crossover rate for diversity\n        self.periodicity_enforcement = 0.65  # Enhanced adaptive periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        elite_indices = np.argsort([func(ind) for ind in new_population])[:5]  # Elite preservation\n        for idx in elite_indices:\n            new_population[idx] = self.local_optimization(new_population[idx], func, bounds)\n\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhance symbiotic optimization with adaptive periodicity and elite preservation strategies for improved convergence.", "configspace": "", "generation": 73, "fitness": 0.2474510703004216, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "20674f8a-f250-4a9b-bd85-ddab9bde7aa3", "metadata": {"aucs": [0.2471996358105174, 0.2477046379041441, 0.24744893718660332], "final_y": [0.16485607898810528, 0.1648565145972959, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "8d90f075-f5b3-4f0b-805d-e0a4f5a3953a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.85  # Adjusted from 0.8 to 0.85 for improved exploration\n        self.CR = 0.75  # Fine-tuned crossover rate from 0.7 to 0.75\n        self.periodicity_enforcement = 0.65  # Changed from 0.6 to 0.65 for adaptive periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced exploration and convergence by refining DE parameters and periodicity enforcement.", "configspace": "", "generation": 74, "fitness": 0.2475651512264222, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "20674f8a-f250-4a9b-bd85-ddab9bde7aa3", "metadata": {"aucs": [0.2475094001374617, 0.2477354737235642, 0.2474505798182407], "final_y": [0.16485728269453037, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "a18938dc-6242-4063-8990-4c4512d8642b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 65  # Increased from 60 to 65 for better exploration\n        self.subgroup_size = dim // 2\n        self.F = 0.85  # Adjusted from 0.8 to 0.85 for improved exploration\n        self.CR = 0.75  # Fine-tuned crossover rate from 0.7 to 0.75\n        self.periodicity_enforcement = 0.65  # Changed from 0.6 to 0.65 for adaptive periodicity\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Refine the HybridSymbioticAlgorithm by increasing the population size for better exploration.", "configspace": "", "generation": 75, "fitness": 0.24677095996301027, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d90f075-f5b3-4f0b-805d-e0a4f5a3953a", "metadata": {"aucs": [0.24597097129033096, 0.24695281423094206, 0.2473890943677578], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "a0e1c547-689a-4aab-a6fb-b9de085a2c9a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.85\n        self.CR = 0.75\n        self.periodicity_enforcement = 0.65\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def adaptive_mutation_factor(self, generation):\n        return 0.5 + (self.F - 0.5) * (1 - generation / self.budget)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            F_adaptive = self.adaptive_mutation_factor(i)\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + F_adaptive * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def strategic_re_evaluation(self, population, func, num_re_evals=5):\n        idx = np.random.choice(len(population), num_re_evals, replace=False)\n        for i in idx:\n            population[i] = self.local_optimization(population[i], func, func.bounds)\n        return population\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                population = self.strategic_re_evaluation(population, func)\n                evaluations += min(len(population), self.budget - evaluations)\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced convergence and diversity by introducing adaptive learning and strategic re-evaluation.", "configspace": "", "generation": 76, "fitness": 0.2458274591109039, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d90f075-f5b3-4f0b-805d-e0a4f5a3953a", "metadata": {"aucs": [0.2452667315822834, 0.2458350435448471, 0.24638060220558122], "final_y": [0.1648559218161031, 0.16485935692744125, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "714dd147-e273-45fd-ba9b-3c3a9070abfb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.9  # Adjusted from 0.85 to 0.9 for improved exploration\n        self.CR = 0.8  # Fine-tuned crossover rate from 0.75 to 0.8\n        self.periodicity_enforcement = 0.7  # Changed from 0.65 to 0.7 for adaptive periodicity\n        self.adaptive_threshold = 0.5  # New parameter for diversity adaptation\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Introduce symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + mirrored) / 2\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Integrate adaptive differential evolution and symmetry-driven local search to enhance convergence and solution periodicity.", "configspace": "", "generation": 77, "fitness": 0.24768159998518188, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d90f075-f5b3-4f0b-805d-e0a4f5a3953a", "metadata": {"aucs": [0.2478855083845103, 0.24802950756581876, 0.24712978400521657], "final_y": [0.16485594409215476, 0.1648559714148895, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "f981fd77-ab44-4135-937f-9ccfdd5ebce8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom sklearn.cluster import KMeans\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.95  # Adjusted for aggressive exploration\n        self.CR = 0.85  # Increased crossover rate for diversity\n        self.periodicity_enforcement = 0.7\n        self.adaptive_threshold = 0.5\n        self.clustering_k = 5  # New parameter for niche exploration\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        kmeans = KMeans(n_clusters=self.clustering_k)\n        cluster_labels = kmeans.fit_predict(population)\n       \n        for i in range(len(population)):\n            same_cluster = population[cluster_labels == cluster_labels[i]]\n            indices = np.random.choice(len(same_cluster), 3, replace=False)\n            a, b, c = same_cluster[indices]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhance the adaptive differential evolution with periodicity and niche exploration via clustering for improved subspace convergence.", "configspace": "", "generation": 78, "fitness": 0.24700441144465743, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "714dd147-e273-45fd-ba9b-3c3a9070abfb", "metadata": {"aucs": [0.24618090852538532, 0.24737468300112853, 0.2474576428074584], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "ae5bcfd7-ca53-41de-93ab-0b4e02a09228", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.92  # Adjusted from 0.9 to 0.92 for enhanced exploration\n        self.CR = 0.82  # Fine-tuned crossover rate from 0.8 to 0.82 for better diversity\n        self.periodicity_enforcement = 0.7  # Changed from 0.65 to 0.7 for adaptive periodicity\n        self.adaptive_threshold = 0.5  # New parameter for diversity adaptation\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Introduce symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + mirrored) / 2\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Minor adjustments in parameters to improve exploration and intensification balance.", "configspace": "", "generation": 79, "fitness": 0.24768741164314143, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "714dd147-e273-45fd-ba9b-3c3a9070abfb", "metadata": {"aucs": [0.24788045633596922, 0.24805797473555846, 0.24712380385789656], "final_y": [0.16485594724189212, 0.16485594750625976, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "437b6bd2-6937-48f6-a41d-e221efeba58f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.92\n        self.CR = 0.82\n        self.periodicity_enforcement = 0.7\n        self.adaptive_threshold = 0.5\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Introduce symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.99 * mirrored) / 2  # Adjusted factor for a smoother search\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced balance between exploration and exploitation by refining symmetry-driven local search.", "configspace": "", "generation": 80, "fitness": 0.24771180267747403, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ae5bcfd7-ca53-41de-93ab-0b4e02a09228", "metadata": {"aucs": [0.24786934160124596, 0.24807725770960953, 0.24718880872156657], "final_y": [0.16485632498843794, 0.1648558905998624, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "75e5d60b-4848-49be-894f-4e777c973d16", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.92\n        self.CR = 0.85  # Increased crossover rate for enhanced diversity\n        self.periodicity_enforcement = 0.7\n        self.adaptive_threshold = 0.5\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Introduce symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.99 * mirrored) / 2  # Adjusted factor for a smoother search\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Introduce a slight increase in the crossover rate to improve diversity in the search process.", "configspace": "", "generation": 81, "fitness": 0.24776073748627203, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "437b6bd2-6937-48f6-a41d-e221efeba58f", "metadata": {"aucs": [0.2480161374595441, 0.2480772555944175, 0.2471888194048545], "final_y": [0.1648560190914654, 0.16485589615097485, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "80aacd1a-3740-4b7e-8c52-5dc207f52bef", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted for better exploration\n        self.CR = 0.9  # Increased crossover rate for enhanced adaptability\n        self.periodicity_enforcement = 0.5  # Reduced to refine periodicity\n        self.adaptive_threshold = 0.7  # Increased to allow dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Introduce symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.95 * mirrored) / 2  # Adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhance the diversity and adaptability by dynamically adjusting parameters based on population convergence.", "configspace": "", "generation": 82, "fitness": 0.2478970053573134, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "75e5d60b-4848-49be-894f-4e777c973d16", "metadata": {"aucs": [0.24794692732949164, 0.24810373890154147, 0.2476403498409071], "final_y": [0.1648558617469662, 0.16485592602741206, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "2d16871e-750a-4e69-b1e3-f77da0703079", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted for better exploration\n        self.CR = 0.9  # Increased crossover rate for enhanced adaptability\n        self.periodicity_enforcement = 0.5  # Reduced to refine periodicity\n        self.adaptive_threshold = 0.7  # Increased to allow dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            self.F = np.random.uniform(0.5, 1.0)  # Adaptive mutation factor\n            self.CR = np.random.uniform(0.7, 1.0)  # Adaptive crossover rate\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Introduce symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.95 * mirrored) / 2  # Adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced convergence by applying adaptive mutation factor and crossover rate adjustments based on iteration progress.", "configspace": "", "generation": 83, "fitness": 0.24777538244961753, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "80aacd1a-3740-4b7e-8c52-5dc207f52bef", "metadata": {"aucs": [0.24770033215559784, 0.24760381430975853, 0.24802200088349624], "final_y": [0.16485592535881355, 0.16485589253663535, 0.16485592327116128]}, "mutation_prompt": null}
{"id": "4452687c-5d06-4505-8e0d-0c3a98b0035c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted for better exploration\n        self.CR = 0.9  # Increased crossover rate for enhanced adaptability\n        self.periodicity_enforcement = 0.3  # Reduced to refine periodicity further\n        self.adaptive_threshold = 0.7  # Increased to allow dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Introduce symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.95 * mirrored) / 2  # Adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhance periodicity and diversity by adjusting the periodicity enforcement factor for better convergence.", "configspace": "", "generation": 84, "fitness": 0.24789858850216637, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "80aacd1a-3740-4b7e-8c52-5dc207f52bef", "metadata": {"aucs": [0.2479465065144829, 0.2481031316854896, 0.24764612730652658], "final_y": [0.16485593047778735, 0.1648559328081699, 0.16485613307394797]}, "mutation_prompt": null}
{"id": "e3c40fbd-d46d-4351-a6d9-20e5b430bdd7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted for better exploration\n        self.CR = 0.9  # Increased crossover rate for enhanced adaptability\n        self.periodicity_enforcement = 0.3  # Reduced to refine periodicity further\n        self.adaptive_threshold = 0.7  # Increased to allow dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Introduce symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + (self.periodicity_enforcement * (0.5 + 0.5 * np.sin(frequency * individual)))  # Modified line\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.95 * mirrored) / 2  # Adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Introduce dynamic periodicity adjustment for enhanced solution convergence.", "configspace": "", "generation": 85, "fitness": 0.24789175576853376, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4452687c-5d06-4505-8e0d-0c3a98b0035c", "metadata": {"aucs": [0.24794507475213234, 0.2481032443246498, 0.24762694822881914], "final_y": [0.1648560314305043, 0.16485600864595795, 0.16485594975697992]}, "mutation_prompt": null}
{"id": "f7c59833-dfd7-428c-8b94-a8634c683767", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.9  # Adjusted for increased diversity\n        self.CR = 0.85  # Slightly decreased for periodicity awareness\n        self.periodicity_enforcement = 0.35  # Slightly increased for better periodicity\n        self.adaptive_threshold = 0.7\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.dynamic_crossover(i)\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def dynamic_crossover(self, index):\n        # Dynamic crossover rate based on index and periodicity\n        return self.CR + 0.05 * np.sin(2 * np.pi * index / self.population_size)\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        mirrored = individual[::-1]\n        return (individual + 0.95 * mirrored) / 2\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Improve convergence by integrating a periodicity-aware dynamic crossover strategy.", "configspace": "", "generation": 86, "fitness": 0.24773326925519215, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4452687c-5d06-4505-8e0d-0c3a98b0035c", "metadata": {"aucs": [0.24783444443204306, 0.24807324511809303, 0.2472921182154404], "final_y": [0.1648558756842018, 0.16485610406631745, 0.1648559510474331]}, "mutation_prompt": null}
{"id": "9e26fb2b-cf8d-4bda-9da5-2600e6942f22", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted for better exploration\n        self.CR = 0.9  # Increased crossover rate for enhanced adaptability\n        self.periodicity_enforcement = 0.3  # Reduced to refine periodicity further\n        self.adaptive_threshold = 0.7  # Increased to allow dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Introduce symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.9 * mirrored) / 2  # Adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Minor adjustments in population initialization and symmetry-driven local search parameters to refine convergence.", "configspace": "", "generation": 87, "fitness": 0.247993863917677, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4452687c-5d06-4505-8e0d-0c3a98b0035c", "metadata": {"aucs": [0.2478521110151597, 0.24808245514919836, 0.24804702558867298], "final_y": [0.1648559367940261, 0.16485595944872478, 0.1648560712802385]}, "mutation_prompt": null}
{"id": "415bcc10-6648-4cd3-86a6-e951839ffcd9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted for better exploration\n        self.CR = 0.9  # Increased crossover rate for enhanced adaptability\n        self.periodicity_enforcement = 0.3  # Reduced to refine periodicity further\n        self.adaptive_threshold = 0.7  # Increased to allow dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Introduce symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual * np.random.uniform(0.8, 1.2))  # Adaptive enforcement\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.9 * mirrored) / 2  # Adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Introduced adaptive periodicity enforcement to improve convergence towards periodic solutions.", "configspace": "", "generation": 88, "fitness": 0.24792647283318495, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9e26fb2b-cf8d-4bda-9da5-2600e6942f22", "metadata": {"aucs": [0.24768656162168956, 0.2480714606771629, 0.2480213962007024], "final_y": [0.1648560219896421, 0.1648558728000148, 0.1648558660203998]}, "mutation_prompt": null}
{"id": "7f2a99d2-adc0-44d0-b409-def541920abd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.8  # Adjusted for better exploration\n        self.CR = 0.9  # Increased crossover rate for enhanced adaptability\n        self.periodicity_enforcement = 0.3  # Reduced to refine periodicity further\n        self.adaptive_threshold = 0.75  # Increased to allow dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Introduce symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * individual)\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.9 * mirrored) / 2  # Adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Refine periodicity enforcement by enhancing adaptive threshold for better convergence.", "configspace": "", "generation": 89, "fitness": 0.247993863917677, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9e26fb2b-cf8d-4bda-9da5-2600e6942f22", "metadata": {"aucs": [0.2478521110151597, 0.24808245514919836, 0.24804702558867298], "final_y": [0.1648559367940261, 0.16485595944872478, 0.1648560712802385]}, "mutation_prompt": null}
{"id": "cbbcf470-3ef5-4584-94b3-2caa2c2d34bd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.85  # Slightly increased for more aggressive exploration\n        self.CR = 0.95  # Further increased crossover rate for adaptability\n        self.periodicity_enforcement = 0.35  # Increased to enhance periodicity\n        self.adaptive_threshold = 0.75  # Further increased for more dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Adjusted symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * (individual - np.mean(individual)))  # Centered adjustment for better periodicity\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.85 * mirrored) / 2  # Further adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced periodicity enforcement and adaptive symbiotic mechanisms to improve convergence.", "configspace": "", "generation": 90, "fitness": 0.24806500499740633, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9e26fb2b-cf8d-4bda-9da5-2600e6942f22", "metadata": {"aucs": [0.24790483735607793, 0.24820562465283436, 0.24808455298330667], "final_y": [0.16485607624986398, 0.1648559627009445, 0.16485587903532495]}, "mutation_prompt": null}
{"id": "fa2d7975-c29d-4b1c-aba8-36fdf12acd88", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 3  # Reduced subgroup size for diversity\n        self.F = 0.9  # More exploration\n        self.CR = 0.9  # Increased adaptability\n        self.periodicity_enforcement = 0.4  # Enhanced periodicity\n        self.adaptive_threshold = 0.8  # More dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b = population[np.random.choice(indices, 2, replace=False)]\n            c = np.mean(population, axis=0)  # Use mean for opposition-based learning\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Refined symmetry-driven local search\n            trial = self.refined_symmetry_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * (individual - np.mean(individual)))\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def refined_symmetry_search(self, individual, bounds):  # Renamed and adjusted for better clarity\n        mirrored = individual[::-1]\n        return (individual + mirrored) / 2  # Simplified for better periodicity\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced symbiotic periodicity with adaptive opposition-based learning and refined local search for better convergence.", "configspace": "", "generation": 91, "fitness": 0.24804344915399237, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cbbcf470-3ef5-4584-94b3-2caa2c2d34bd", "metadata": {"aucs": [0.24792204374529925, 0.24796531719259507, 0.24824298652408283], "final_y": [0.16485598222679088, 0.1648558391783912, 0.16485602558319046]}, "mutation_prompt": null}
{"id": "77236484-6045-47ec-9ef3-1cc08f4b0e32", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.9  # Slightly increased for more aggressive exploration\n        self.CR = 0.92  # Slightly reduced crossover rate to refine adaptability\n        self.periodicity_enforcement = 0.35  # Increased to enhance periodicity\n        self.adaptive_threshold = 0.75  # Further increased for more dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Adjusted symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * (individual - np.mean(individual)))  # Centered adjustment for better periodicity\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.85 * mirrored) / 2  # Further adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Slightly adjust exploration parameters to balance between exploration and exploitation more effectively.", "configspace": "", "generation": 92, "fitness": 0.24798658691427358, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cbbcf470-3ef5-4584-94b3-2caa2c2d34bd", "metadata": {"aucs": [0.2476577565721757, 0.24821941673779857, 0.2480825874328465], "final_y": [0.16485588904743775, 0.16485587211476038, 0.1648559682920815]}, "mutation_prompt": null}
{"id": "c3ec9586-2979-45df-a0ba-3607683deb4f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.85  # Slightly increased for more aggressive exploration\n        self.CR = 0.95  # Further increased crossover rate for adaptability\n        self.periodicity_enforcement = 0.35  # Increased to enhance periodicity\n        self.adaptive_threshold = 0.75  # Further increased for more dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.adaptive_periodicity(trial, bounds, func(population[i]))\n\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def adaptive_periodicity(self, individual, bounds, current_value):\n        adjustment_factor = self.periodicity_enforcement * (1 - current_value)\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + adjustment_factor * np.sin(frequency * (individual - np.mean(individual)))\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        mirrored = individual[::-1]\n        return (individual + 0.85 * mirrored) / 2\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Incorporating adaptive periodicity enforcement and dynamic subgroup selection into a hybrid symbiotic algorithm to improve convergence on complex optimization landscapes.", "configspace": "", "generation": 93, "fitness": 0.24792096116822562, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cbbcf470-3ef5-4584-94b3-2caa2c2d34bd", "metadata": {"aucs": [0.24769366617560296, 0.24810207457024058, 0.24796714275883336], "final_y": [0.16485612426041363, 0.16485585527848712, 0.1648558794910826]}, "mutation_prompt": null}
{"id": "58156b76-e758-422a-ad62-d81b9e13ca69", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.85  # Slightly increased for more aggressive exploration\n        self.CR = 0.95  # Further increased crossover rate for adaptability\n        self.periodicity_enforcement = 0.35  # Increased to enhance periodicity\n        self.adaptive_threshold = 0.75  # Further increased for more dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Adjusted symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * (individual - np.mean(individual)))  # Centered adjustment for better periodicity\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.86 * mirrored) / 2  # Further adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced modular symmetry and periodicity adjustments for improved convergence.", "configspace": "", "generation": 94, "fitness": 0.2480587242410719, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cbbcf470-3ef5-4584-94b3-2caa2c2d34bd", "metadata": {"aucs": [0.2478849048820343, 0.24819558566751365, 0.24809568217366773], "final_y": [0.1648559281072417, 0.1648559352655552, 0.16485597801497587]}, "mutation_prompt": null}
{"id": "c10b916a-8095-451c-95cf-f0aff10b56ad", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.85  # Slightly increased for more aggressive exploration\n        self.CR = 0.95  # Further increased crossover rate for adaptability\n        self.periodicity_enforcement = 0.35  # Increased to enhance periodicity\n        self.adaptive_threshold = 0.75  # Further increased for more dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Refined symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * (individual - np.mean(individual)))  # Centered adjustment for better periodicity\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply enhanced symmetry constraints for more effective local search\n        mirrored = individual[::-1]\n        return (individual + 0.9 * mirrored) / 2  # Slightly increased adjustment factor for improved modularity\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Refined symmetry-driven local search and increased modularity to enhance convergence and solution quality.", "configspace": "", "generation": 95, "fitness": 0.2479922759169827, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cbbcf470-3ef5-4584-94b3-2caa2c2d34bd", "metadata": {"aucs": [0.24777145989674465, 0.24813131308706238, 0.24807405476714106], "final_y": [0.1648559731783097, 0.16485598368510768, 0.1648560169466763]}, "mutation_prompt": null}
{"id": "2ac8fac1-1de8-471d-adaa-3134ebab4858", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.85  # Slightly increased for more aggressive exploration\n        self.CR = 0.95  # Further increased crossover rate for adaptability\n        self.periodicity_enforcement = 0.35  # Increased to enhance periodicity\n        self.adaptive_threshold = 0.75  # Further increased for more dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]) + 0.1 * (population[i][subgroup_indices] - b[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])  # Changed line\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Adjusted symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * (individual - np.mean(individual)))  # Centered adjustment for better periodicity\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.85 * mirrored) / 2  # Further adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Enhanced mutation strategy for better convergence by increasing diversity in symbiotic optimization.", "configspace": "", "generation": 96, "fitness": 0.24806136414606275, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cbbcf470-3ef5-4584-94b3-2caa2c2d34bd", "metadata": {"aucs": [0.24789043215301143, 0.2481663174046922, 0.24812734288048466], "final_y": [0.16485598861261574, 0.16485600624623298, 0.1648560234801557]}, "mutation_prompt": null}
{"id": "f73b59c4-f3ce-4cd5-ab97-faa267a98e44", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 70  # Adjusted population size for better exploration\n        self.subgroup_size = dim // 2\n        self.F = 0.9  # Slightly increased for more aggressive exploration\n        self.CR = 0.9  # Adjusted crossover rate for adaptability\n        self.periodicity_enforcement = 0.4  # Increased to enhance periodicity\n        self.adaptive_threshold = 0.8  # Further increased for more dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Adjusted symmetry-driven local search with dynamic factor\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * (individual - np.mean(individual)))  # Centered adjustment for better periodicity\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply dynamic symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        dynamic_factor = 0.9  # Introduced dynamic factor for smoother exploration\n        return (individual + dynamic_factor * mirrored) / 2\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Hybrid Symbiotic Algorithm with enhanced periodicity and dynamic symmetry adjustment to improve convergence.", "configspace": "", "generation": 97, "fitness": 0.24751269797517206, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cbbcf470-3ef5-4584-94b3-2caa2c2d34bd", "metadata": {"aucs": [0.2468630644152865, 0.24759757607808197, 0.2480774534321477], "final_y": [0.1648560159847775, 0.16485588153192265, 0.16485589055375371]}, "mutation_prompt": null}
{"id": "0995a49d-7d03-4d9a-9dab-1f27699e7fea", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.85  # Slightly increased for more aggressive exploration\n        self.CR = 0.95  # Further increased crossover rate for adaptability\n        self.periodicity_enforcement = 0.4  # Adjusted to enhance periodicity\n        self.adaptive_threshold = 0.75  # Further increased for more dynamic changes\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n\n            # Adjusted symmetry-driven local search\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * (individual - np.mean(individual)))  # Centered adjustment for better periodicity\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        # Apply symmetry constraints to enhance local search\n        mirrored = individual[::-1]\n        return (individual + 0.9 * mirrored) / 2  # Further adjusted for smoother exploration\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Small improvements in periodicity enforcement and symmetry local search for better convergence.", "configspace": "", "generation": 98, "fitness": 0.24799108015993673, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cbbcf470-3ef5-4584-94b3-2caa2c2d34bd", "metadata": {"aucs": [0.24777176649408716, 0.24812907839610876, 0.24807239558961425], "final_y": [0.16485593674749555, 0.16485599536259143, 0.1648559945645689]}, "mutation_prompt": null}
{"id": "07887794-efc3-486d-a7b8-b491c4cda890", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridSymbioticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.subgroup_size = dim // 2\n        self.F = 0.85\n        self.CR = 0.95\n        self.periodicity_enforcement = 0.35\n        self.adaptive_threshold = 0.75\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * 0.95\n\n    def symbiotic_optimization(self, population, bounds, func):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            subgroup_indices = np.random.choice(self.dim, self.subgroup_size, replace=False)\n            mutant = a.copy()\n            mutant[subgroup_indices] = np.clip(a[subgroup_indices] + self.F * (b[subgroup_indices] - c[subgroup_indices]), bounds.lb[subgroup_indices], bounds.ub[subgroup_indices])\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial = self.enforce_periodicity(trial, bounds)\n            trial = self.symmetry_local_search(trial, bounds)\n\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n\n        best_individual = new_population[np.argmin([func(ind) for ind in new_population])]\n        new_population[0] = best_individual\n        return new_population\n\n    def enforce_periodicity(self, individual, bounds):\n        frequency = 2 * np.pi / (bounds.ub - bounds.lb)\n        adjusted = individual + self.periodicity_enforcement * np.sin(frequency * (individual - np.mean(individual)))\n        adjusted = adjusted + 0.05 * np.cos(frequency * adjusted)  # New cosine adjustment\n        return np.clip(adjusted, bounds.lb, bounds.ub)\n\n    def symmetry_local_search(self, individual, bounds):\n        mirrored = individual[::-1]\n        avg_symmetry = (individual + mirrored) / 2\n        bias = 0.9 if np.mean(avg_symmetry) > np.mean(individual) else 0.7  # Dynamic biasing\n        return (individual + bias * mirrored) / 2\n\n    def local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            population = self.symbiotic_optimization(population, bounds, func)\n            evaluations += len(population)\n\n            if evaluations < self.budget:\n                for i in range(len(population)):\n                    population[i] = self.local_optimization(population[i], func, bounds)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations >= self.budget:\n                break\n\n        best_solution = population[np.argmin([func(ind) for ind in population])]\n        return best_solution", "name": "HybridSymbioticAlgorithm", "description": "Improved dynamic symbiotic interactions and periodicity adjustments for better convergence and solution quality.", "configspace": "", "generation": 99, "fitness": 0.2478702446332353, "feedback": "The algorithm HybridSymbioticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "cbbcf470-3ef5-4584-94b3-2caa2c2d34bd", "metadata": {"aucs": [0.24772649675195768, 0.24791854966104143, 0.24796568748670678], "final_y": [0.16485593669025578, 0.16485597273319474, 0.16485610967890185]}, "mutation_prompt": null}
