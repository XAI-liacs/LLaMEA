{"id": "db88fd43-2c32-4e47-b3aa-28c8cbb92934", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.3\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Local search\n                if np.random.rand() < self.local_search_prob and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01  # A small step size relative to bounds\n        for _ in range(5):  # Perform up to 5 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "A hybrid Differential Evolution with Local Search, enhancing global exploration with refined local exploitation for robust optimization in complex landscapes.", "configspace": "", "generation": 0, "fitness": 0.2142038588415701, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.214 with standard deviation 0.002. And the mean value of best solutions found was 0.331 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": null, "metadata": {"aucs": [0.21660396953621242, 0.21164158050105342, 0.2143660264874444], "final_y": [0.3292361817426205, 0.3509529230236531, 0.3132167275080422]}, "mutation_prompt": null}
{"id": "a3c88ef9-a612-4423-b246-b8d32d288bc2", "solution": "import numpy as np\n\nclass AdaptiveMemeticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 5 * dim\n        self.min_population_size = 2 * dim\n        self.max_population_size = 10 * dim\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.2\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(population_size):\n                # Mutation\n                indices = [idx for idx in range(population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Local search\n                if np.random.rand() < self.local_search_prob and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n            \n            # Dynamic Population Sizing\n            if self.evaluations < self.budget / 2:\n                population_size = min(self.max_population_size, population_size + dim)\n            else:\n                population_size = max(self.min_population_size, population_size - dim)\n            if self.evaluations < self.budget:\n                additional_population = np.random.uniform(lb, ub, (population_size - len(population), self.dim))\n                population = np.vstack((population, additional_population))\n                fitness = np.append(fitness, [func(ind) for ind in additional_population])\n                self.evaluations += len(additional_population)\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01\n        current_fitness = func(solution)\n        for _ in range(5):\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < current_fitness:\n                solution = candidate\n                current_fitness = candidate_fitness\n                improved = True\n        return improved, current_fitness", "name": "AdaptiveMemeticAlgorithm", "description": "Adaptive Memetic Algorithm with Dynamic Population Sizing that balances exploration and exploitation by adapting population size and combining global and local search strategies.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'dim' is not defined\").", "error": "NameError(\"name 'dim' is not defined\")", "parent_id": "db88fd43-2c32-4e47-b3aa-28c8cbb92934", "metadata": {}, "mutation_prompt": null}
{"id": "6cfdc146-70ec-431c-a42d-16178adb669a", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.3\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Dynamic mutation factor\n                dyn_mutation_factor = self.mutation_factor * (self.budget - self.evaluations) / self.budget\n                mutant = np.clip(a + dyn_mutation_factor * (b - c), lb, ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Local search\n                if np.random.rand() < self.local_search_prob and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01  # A small step size relative to bounds\n        for _ in range(5):  # Perform up to 5 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "An enhanced Hybrid Differential Evolution utilizing a dynamic mutation factor for adaptive optimization in complex landscapes.", "configspace": "", "generation": 2, "fitness": 0.2141433576097802, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.214 with standard deviation 0.002. And the mean value of best solutions found was 0.325 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "db88fd43-2c32-4e47-b3aa-28c8cbb92934", "metadata": {"aucs": [0.2149891320647046, 0.21155089516826409, 0.21589004559637193], "final_y": [0.3418804040668607, 0.3570946632887124, 0.27619431980207587]}, "mutation_prompt": null}
{"id": "e1d801e6-cf08-4950-aa0d-86972b7d3834", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.3\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.5 + (ub + lb) * 0.5  # Adjusted initialization for diversity\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Local search\n                if np.random.rand() < self.local_search_prob and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01  # A small step size relative to bounds\n        for _ in range(5):  # Perform up to 5 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "A refined Hybrid Differential Evolution with Local Search, where the initial population is scaled for better diversity and exploration capability in complex landscapes.", "configspace": "", "generation": 3, "fitness": 0.21407577357647908, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.214 with standard deviation 0.004. And the mean value of best solutions found was 0.345 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "db88fd43-2c32-4e47-b3aa-28c8cbb92934", "metadata": {"aucs": [0.21410416384368514, 0.2190431203570532, 0.2090800365286989], "final_y": [0.3392947853494288, 0.3111802628922846, 0.38387707052857456]}, "mutation_prompt": null}
{"id": "9882e41a-0952-4fb1-a68d-c38780493894", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.alpha = 0.5  # Initial quantum state probability amplitude\n        self.beta = np.sqrt(1 - self.alpha**2)\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population in quantum representation\n        quantum_population = np.random.rand(self.population_size, self.dim)\n        population = self.quantum_measurement(quantum_population, lb, ub)\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            # Quantum rotation gate\n            self.alpha, self.beta = self.quantum_rotation(self.alpha, self.beta)\n\n            for i in range(self.population_size):\n                # Create trial quantum individual\n                trial_quantum = self.alpha * quantum_population[i] + self.beta * np.random.randn(self.dim)\n                trial_quantum = np.clip(trial_quantum, 0, 1)\n                trial = self.quantum_measurement(np.array([trial_quantum]), lb, ub)[0]\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    quantum_population[i] = trial_quantum\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n        return best_solution\n\n    def quantum_measurement(self, quantum_population, lb, ub):\n        # Collapse quantum states to real numbers within the search space\n        return lb + (ub - lb) * quantum_population\n\n    def quantum_rotation(self, alpha, beta):\n        # Adjust quantum state probabilities for exploration-exploitation balance\n        theta = np.pi / 100  # Small rotation angle\n        new_alpha = alpha * np.cos(theta) - beta * np.sin(theta)\n        new_beta = alpha * np.sin(theta) + beta * np.cos(theta)\n        return new_alpha, new_beta", "name": "QuantumInspiredEA", "description": "Quantum-Inspired Evolutionary Algorithm (QIEA) utilizing quantum superposition principles for enhanced exploration and dynamic adjustment of search space to tackle complex optimization landscapes.", "configspace": "", "generation": 4, "fitness": 0.20858314647171441, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.209 with standard deviation 0.002. And the mean value of best solutions found was 0.397 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "db88fd43-2c32-4e47-b3aa-28c8cbb92934", "metadata": {"aucs": [0.2112019745842979, 0.20680373557977605, 0.20774372925106932], "final_y": [0.37349563392499185, 0.41379549904142665, 0.4051421831226424]}, "mutation_prompt": null}
{"id": "781c75b2-e96c-433d-be82-10c75956ddfa", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.3\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.mutation_factor = np.random.uniform(0.5, 1.0)  # Dynamic adjustment of mutation factor\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Local search\n                if np.random.rand() < self.local_search_prob and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01  # A small step size relative to bounds\n        for _ in range(5):  # Perform up to 5 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "An Adaptive Mutation Differential Evolution that adjusts the mutation factor dynamically for optimizing multilayered structures.", "configspace": "", "generation": 5, "fitness": 0.2112898174649809, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.211 with standard deviation 0.001. And the mean value of best solutions found was 0.351 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "db88fd43-2c32-4e47-b3aa-28c8cbb92934", "metadata": {"aucs": [0.20928906730965358, 0.21252253044679448, 0.2120578546384947], "final_y": [0.35781810341997244, 0.3409522482777889, 0.35282500908801906]}, "mutation_prompt": null}
{"id": "3152acb2-68e1-4726-91c5-0c760d0ccd89", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.3\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive mutation factor based on fitness improvement\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Local search\n                if np.random.rand() < self.local_search_prob and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01  # A small step size relative to bounds\n        for _ in range(5):  # Perform up to 5 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "A hybrid Differential Evolution with Local Search and adaptive mutation factor, enhancing global exploration with refined local exploitation for robust optimization in complex landscapes.", "configspace": "", "generation": 6, "fitness": 0.21446831850846862, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.214 with standard deviation 0.002. And the mean value of best solutions found was 0.315 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "db88fd43-2c32-4e47-b3aa-28c8cbb92934", "metadata": {"aucs": [0.21596401476076987, 0.21155089516826409, 0.21589004559637193], "final_y": [0.310754687914228, 0.3570946632887124, 0.27619431980207587]}, "mutation_prompt": null}
{"id": "c7141a6d-332a-474d-9d38-d6686cff0c91", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.3\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive mutation factor based on fitness improvement\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n\n                # Dynamic crossover rate\n                current_crossover_rate = self.crossover_rate * (1 - (self.evaluations / self.budget))\n                cross_points = np.random.rand(self.dim) < current_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Local search\n                if np.random.rand() < self.local_search_prob and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01  # A small step size relative to bounds\n        for _ in range(5):  # Perform up to 5 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "Introduce a dynamic crossover rate that decreases linearly as evaluations progress, enhancing exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.21706467120113748, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.217 with standard deviation 0.000. And the mean value of best solutions found was 0.279 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "3152acb2-68e1-4726-91c5-0c760d0ccd89", "metadata": {"aucs": [0.21657066658426516, 0.2174017759780319, 0.2172215710411154], "final_y": [0.3098684428439641, 0.27767734341259254, 0.24843747381556902]}, "mutation_prompt": null}
{"id": "88818abb-821d-40d7-a596-3b4cb7f92b7e", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.3\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive mutation factor based on fitness improvement\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n\n                # Dynamic crossover rate\n                current_crossover_rate = self.crossover_rate * (1 - (self.evaluations / self.budget))\n                cross_points = np.random.rand(self.dim) < current_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Local search\n                dynamic_local_search_prob = self.local_search_prob + 0.5 * (self.evaluations / self.budget)\n                if np.random.rand() < dynamic_local_search_prob and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01  # A small step size relative to bounds\n        for _ in range(5):  # Perform up to 5 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "Introduce a dynamic local search probability that increases linearly as evaluations progress, enhancing exploitation towards the end.", "configspace": "", "generation": 8, "fitness": 0.2142970986969491, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.214 with standard deviation 0.005. And the mean value of best solutions found was 0.333 (0. is the best) with standard deviation 0.053.", "error": "", "parent_id": "c7141a6d-332a-474d-9d38-d6686cff0c91", "metadata": {"aucs": [0.21289542302910902, 0.20904404044383618, 0.22095183261790208], "final_y": [0.3582413876494107, 0.3826326164672018, 0.2589448046138878]}, "mutation_prompt": null}
{"id": "6e4e6335-9f11-4fdd-8055-64cf9970ed33", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.5  # increased local search probability\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive mutation factor based on fitness improvement\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n\n                # Dynamic crossover rate\n                current_crossover_rate = self.crossover_rate * (1 - (self.evaluations / self.budget))\n                cross_points = np.random.rand(self.dim) < current_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Local search\n                if np.random.rand() < self.local_search_prob and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.005  # Reduced step size for finer local search\n        for _ in range(7):  # Perform up to 7 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "Adaptive mutation and crossover strategies with enhanced local search probabilistic threshold for improved convergence in diverse landscapes.", "configspace": "", "generation": 9, "fitness": 0.21215286107267214, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.212 with standard deviation 0.003. And the mean value of best solutions found was 0.332 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c7141a6d-332a-474d-9d38-d6686cff0c91", "metadata": {"aucs": [0.20837387101621385, 0.21431673893703052, 0.21376797326477204], "final_y": [0.33818105095358064, 0.33440820843490215, 0.32287602361442935]}, "mutation_prompt": null}
{"id": "598ff6ee-e372-4ec0-b642-ba361f3618ae", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.3\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive mutation factor based on fitness improvement\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n\n                # Dynamic crossover rate\n                current_crossover_rate = self.crossover_rate * (1 - (self.evaluations / self.budget))\n                cross_points = np.random.rand(self.dim) < current_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Local search\n                if np.random.rand() < self.local_search_prob * (1 - trial_fitness / max(fitness)) and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01  # A small step size relative to bounds\n        for _ in range(5):  # Perform up to 5 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "Incorporate fitness-based selection pressure by adjusting probability of local search activation.", "configspace": "", "generation": 10, "fitness": 0.22997182910269062, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.230 with standard deviation 0.001. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c7141a6d-332a-474d-9d38-d6686cff0c91", "metadata": {"aucs": [0.22839902195721917, 0.23090179698324964, 0.23061466836760303], "final_y": [0.19930880282291175, 0.17761567762330754, 0.18156611702921555]}, "mutation_prompt": null}
{"id": "4d3a9dc8-437c-43bd-b365-2794874dcf40", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.3\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Fitness-proportional mutation factor\n                mutation_factor_adaptive = (self.mutation_factor * (fitness[i] / max(fitness)))\n                mutant = np.clip(a + mutation_factor_adaptive * (b - c), lb, ub)\n\n                # Dynamic crossover rate\n                current_crossover_rate = self.crossover_rate * (1 - (self.evaluations / self.budget))\n                cross_points = np.random.rand(self.dim) < current_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Adaptive local search probability\n                local_search_prob_adaptive = self.local_search_prob * (1 - (trial_fitness / best_fitness))\n                if np.random.rand() < local_search_prob_adaptive and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01  # A small step size relative to bounds\n        for _ in range(5):  # Perform up to 5 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "Introduce fitness-proportional mutation factor and adaptive local search probability to enhance exploration and exploitation balance in HybridDE.", "configspace": "", "generation": 11, "fitness": 0.2329495309994446, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.001. And the mean value of best solutions found was 0.180 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "598ff6ee-e372-4ec0-b642-ba361f3618ae", "metadata": {"aucs": [0.23322131039190142, 0.23200984096716926, 0.23361744163926312], "final_y": [0.18577436766058275, 0.17542120129964778, 0.17860143994347177]}, "mutation_prompt": null}
{"id": "a1a65d8b-aee9-43cf-9ecf-4d8ccbbb110c", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.3\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Fitness-proportional mutation factor\n                mutation_factor_adaptive = (self.mutation_factor * (fitness[i] / max(fitness)))\n                mutant = np.clip(a + mutation_factor_adaptive * (b - c), lb, ub)\n\n                # Dynamic crossover rate\n                current_crossover_rate = self.crossover_rate * (1 - (self.evaluations / self.budget))\n                cross_points = np.random.rand(self.dim) < current_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Adaptive local search probability\n                local_search_prob_adaptive = self.local_search_prob * (1 - (trial_fitness / best_fitness))\n                if np.random.rand() < local_search_prob_adaptive and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n                # Introduce diversity mechanism\n                if np.random.rand() < 0.05:  # 5% chance to introduce diversity\n                    population[i] = np.random.uniform(lb, ub, self.dim)\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01  # A small step size relative to bounds\n        for _ in range(5):  # Perform up to 5 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim) * 0.5  # Adaptive step size\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "Introduce adaptive step size in local search and incorporate a diversity mechanism to improve global exploration in HybridDE.", "configspace": "", "generation": 12, "fitness": 0.22407605501641167, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.002. And the mean value of best solutions found was 0.225 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "4d3a9dc8-437c-43bd-b365-2794874dcf40", "metadata": {"aucs": [0.22513055081378974, 0.22525093193822665, 0.2218466822972186], "final_y": [0.22532592299091647, 0.2091838140400163, 0.23999861990718097]}, "mutation_prompt": null}
{"id": "c1153b8f-699a-46b1-a443-270f9d4ce6b9", "solution": "import numpy as np\n\nclass AdaptiveLevyDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        # Levy distribution parameters\n        beta = 1.5\n        alpha = 0.01\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation using Levy flight\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                levy_step = alpha * self.levy_flight(beta, self.dim, lb, ub)\n                mutant = np.clip(a + levy_step * (b - c), lb, ub)\n\n                # Fitness-guided crossover\n                fitness_ratio = fitness[i] / max(fitness)\n                current_crossover_rate = self.crossover_rate * (1 - fitness_ratio)\n                cross_points = np.random.rand(self.dim) < current_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n        return best_solution\n\n    def levy_flight(self, beta, dim, lb, ub):\n        # Generate Levy flight step\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step", "name": "AdaptiveLevyDE", "description": "Introduce an adaptive levy flight mutation strategy along with a fitness-guided crossover to enhance exploration in the early stages and exploitation in the later stages.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "4d3a9dc8-437c-43bd-b365-2794874dcf40", "metadata": {}, "mutation_prompt": null}
{"id": "4a9b2ada-38b5-4eeb-99e5-7929459af9c0", "solution": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # generally a good population size for DE\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.local_search_prob = 0.3\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Fitness-proportional mutation factor\n                mutation_factor_adaptive = (self.mutation_factor * (fitness[i] / max(fitness)))\n                mutant = np.clip(a + mutation_factor_adaptive * (b - c), lb, ub)\n\n                # Dynamic crossover rate\n                current_crossover_rate = self.crossover_rate * (1 - (self.evaluations / self.budget))\n                cross_points = np.random.rand(self.dim) < current_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update best solution\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Adaptive local search probability\n                local_search_prob_adaptive = self.local_search_prob * (1 - (trial_fitness / best_fitness))\n                if np.random.rand() < local_search_prob_adaptive and self.evaluations < self.budget:\n                    improved, trial_fitness = self.local_search(trial, func, lb, ub)\n                    if improved:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n        return best_solution\n\n    def local_search(self, solution, func, lb, ub):\n        improved = False\n        step_size = (ub - lb) * 0.01 * (1 - func(solution) / (np.max(ub) - np.min(lb)))  # Dynamic step size\n        for _ in range(5):  # Perform up to 5 local search steps\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n            if candidate_fitness < func(solution):\n                solution = candidate\n                improved = True\n        return improved, candidate_fitness", "name": "HybridDE", "description": "Enhance local search with dynamic step size based on function's fitness landscape.", "configspace": "", "generation": 14, "fitness": 0.2329495309994446, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.001. And the mean value of best solutions found was 0.180 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "4d3a9dc8-437c-43bd-b365-2794874dcf40", "metadata": {"aucs": [0.23322131039190142, 0.23200984096716926, 0.23361744163926312], "final_y": [0.18577436766058275, 0.17542120129964778, 0.17860143994347177]}, "mutation_prompt": null}
