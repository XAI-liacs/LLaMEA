{"id": "8bb1792d-d122-4cba-b6e3-bdb3e82885a2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDEBFGS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, bounds):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.mutation_factor * (population[b] - population[c])\n        mutant = np.clip(mutant, bounds[0], bounds[1])\n        return mutant\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_prob\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            mutant = self._mutate(i, population, bounds)\n            trial = self._crossover(population[i], mutant)\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = self.dim // 2\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='L-BFGS-B', bounds=bounds, options={'maxfun': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.init_budget:\n            population = self._de_step(population, func, bounds)\n            evaluations += self.population_size\n\n        best_idx = np.argmin([func(ind) for ind in population])\n        best_solution = population[best_idx]\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridDEBFGS", "description": "A hybrid metaheuristic algorithm combining Differential Evolution with periodicity encouragement and local refinement using BFGS for optimizing multilayer photonic structures.", "configspace": "", "generation": 0, "fitness": 0.651257445172778, "feedback": "The algorithm HybridDEBFGS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.651 with standard deviation 0.071. And the mean value of best solutions found was 0.248 (0. is the best) with standard deviation 0.040.", "error": "", "parent_id": null, "metadata": {"aucs": [0.5503365291142057, 0.7040178364998845, 0.6994179699042434], "final_y": [0.3051447300196537, 0.22251074787539582, 0.21778727180997604]}, "mutation_prompt": null}
{"id": "07df8214-b6b5-4f41-8714-7f950dd3ae33", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDEBFGS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        quasi_opposite_population = lb + ub - population  # Quasi-oppositional initialization\n        return np.concatenate((population, quasi_opposite_population))\n\n    def _mutate(self, target_idx, population, bounds):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.mutation_factor * (population[b] - population[c])\n        mutant = np.clip(mutant, bounds[0], bounds[1])\n        return mutant\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_prob\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            mutant = self._mutate(i, population, bounds)\n            trial = self._crossover(population[i], mutant)\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = self.dim // 2\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='L-BFGS-B', bounds=bounds, options={'maxfun': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.init_budget:\n            population = self._de_step(population, func, bounds)\n            evaluations += self.population_size\n\n        best_idx = np.argmin([func(ind) for ind in population])\n        best_solution = population[best_idx]\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridDEBFGS", "description": "Enhanced HybridDEBFGS by increasing population diversity via quasi-oppositional initialization to improve exploration capabilities.", "configspace": "", "generation": 1, "fitness": 0.651257445172778, "feedback": "The algorithm HybridDEBFGS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.651 with standard deviation 0.071. And the mean value of best solutions found was 0.248 (0. is the best) with standard deviation 0.040.", "error": "", "parent_id": "8bb1792d-d122-4cba-b6e3-bdb3e82885a2", "metadata": {"aucs": [0.5503365291142057, 0.7040178364998845, 0.6994179699042434], "final_y": [0.3051447300196537, 0.22251074787539582, 0.21778727180997604]}, "mutation_prompt": null}
{"id": "b9898741-e420-4a49-ae94-f889f76bd3ca", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDEBFGS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, bounds):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.mutation_factor * (population[b] - population[c])\n        mutant = np.clip(mutant, bounds[0], bounds[1])\n        return mutant\n\n    def _crossover(self, target, mutant):\n        period = self.dim // 2\n        cross_points = np.random.rand(period) < self.crossover_prob\n        trial = np.where(np.tile(cross_points, self.dim // period + 1)[:self.dim], mutant, target)\n        return trial\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            mutant = self._mutate(i, population, bounds)\n            trial = self._crossover(population[i], mutant)\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = self.dim // 2\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='L-BFGS-B', bounds=bounds, options={'maxfun': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.init_budget:\n            population = self._de_step(population, func, bounds)\n            evaluations += self.population_size\n\n        best_idx = np.argmin([func(ind) for ind in population])\n        best_solution = population[best_idx]\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridDEBFGS", "description": "Improved hybrid algorithm by modifying the crossover strategy to preserve periodicity more effectively.", "configspace": "", "generation": 2, "fitness": 0.646539072424763, "feedback": "The algorithm HybridDEBFGS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.647 with standard deviation 0.050. And the mean value of best solutions found was 0.230 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "8bb1792d-d122-4cba-b6e3-bdb3e82885a2", "metadata": {"aucs": [0.5896663060464673, 0.7113056776290129, 0.6386452335988089], "final_y": [0.2548985840200856, 0.19843242278590423, 0.23574938346483398]}, "mutation_prompt": null}
{"id": "1eba3261-8486-439d-8779-6b2602f78405", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDEBFGS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.9  # Increased mutation factor for broader exploration\n        self.crossover_prob = 0.7\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, bounds):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.mutation_factor * (population[b] - population[c])\n        mutant = np.clip(mutant, bounds[0], bounds[1])\n        return mutant\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_prob\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            mutant = self._mutate(i, population, bounds)\n            trial = self._crossover(population[i], mutant)\n            if func(trial) < func(population[i]):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = self.dim // 2\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='L-BFGS-B', bounds=bounds, options={'maxfun': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.init_budget:\n            population = self._de_step(population, func, bounds)\n            evaluations += self.population_size\n\n        best_idx = np.argmin([func(ind) for ind in population])\n        best_solution = population[best_idx]\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridDEBFGS", "description": "Enhanced algorithm by modifying the mutation strategy in Differential Evolution for better exploration.", "configspace": "", "generation": 3, "fitness": 0.619410440875175, "feedback": "The algorithm HybridDEBFGS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.619 with standard deviation 0.052. And the mean value of best solutions found was 0.259 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "8bb1792d-d122-4cba-b6e3-bdb3e82885a2", "metadata": {"aucs": [0.6305259020695935, 0.5506905108594584, 0.6770149096964733], "final_y": [0.2396074012681082, 0.2760679740075217, 0.25994304791604506]}, "mutation_prompt": null}
{"id": "2c190e23-4af6-4b6d-8d39-b5c6e854fa21", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = self.dim // 2\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "An adaptive hybrid evolutionary algorithm combining Particle Swarm Optimization (PSO) with periodic solution encouragement and local refinement using Nelder-Mead for optimizing multilayer photonic structures.", "configspace": "", "generation": 4, "fitness": 0.9739377435767779, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8bb1792d-d122-4cba-b6e3-bdb3e82885a2", "metadata": {"aucs": [0.9571453308380719, 0.9821384849328095, 0.9825294149594522], "final_y": [0.16485577190485023, 0.16485577190480538, 0.16485577190492706]}, "mutation_prompt": null}
{"id": "c200f3d8-550d-4b94-8b18-bfc1ad2a4970", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.0 + np.random.rand()  # Changed line\n        self.social_coef = 2.0 - self.cognitive_coef  # Changed line\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = self.dim // 2\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "HybridPSONM improved by modifying the cognitive and social coefficients dynamically to enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.9665377730524765, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2c190e23-4af6-4b6d-8d39-b5c6e854fa21", "metadata": {"aucs": [0.9656787913751326, 0.9638971633007074, 0.9700373644815893], "final_y": [0.16485577190478262, 0.1648557719047753, 0.1648557719047865]}, "mutation_prompt": null}
{"id": "34f40bed-5f4a-4f80-8818-57f22f2d0d52", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opp_pop = lb + ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = self.dim // 2\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Powell', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "EnhancedHybridPSO", "description": "An enhanced adaptive hybrid algorithm that integrates PSO with periodicity encouragement, leverages Quasi-Oppositional initialization, and combines with local optimization using Powell's method to finely tune photonic structures.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (30,10) (60,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (30,10) (60,10) ')", "parent_id": "2c190e23-4af6-4b6d-8d39-b5c6e854fa21", "metadata": {}, "mutation_prompt": null}
{"id": "02923c2b-8104-4bcb-84ef-ec291fe87b34", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.9  # Changed from 0.5 to 0.9 for adaptive inertia weighting\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = self.dim // 2\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhanced HybridPSONM with adaptive inertia weighting for better convergence in optimization of multilayer photonic structures.", "configspace": "", "generation": 7, "fitness": 0.9041699844443539, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.045. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2c190e23-4af6-4b6d-8d39-b5c6e854fa21", "metadata": {"aucs": [0.841983128706609, 0.9495203917252427, 0.9210064329012101], "final_y": [0.164855771904851, 0.16485577190502798, 0.1648557719047291]}, "mutation_prompt": null}
{"id": "ce0ce5fa-e9f6-41ec-b50b-61ce91ec4e69", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7  # Change: Increased social coefficient to enhance global exploration\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = self.dim // 2\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "An adaptive hybrid evolutionary algorithm combining Particle Swarm Optimization (PSO) with periodic solution encouragement and local refinement using Nelder-Mead, enhanced by increasing social influence for optimizing multilayer photonic structures.", "configspace": "", "generation": 8, "fitness": 0.9387781953293457, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.055. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "2c190e23-4af6-4b6d-8d39-b5c6e854fa21", "metadata": {"aucs": [0.8617264853699371, 0.9713105867602829, 0.983297513857817], "final_y": [0.20044491299736777, 0.16485577190480938, 0.16485577190508072]}, "mutation_prompt": null}
{"id": "273a26bc-e86d-4cce-ae69-957ae22d7958", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.inertia = 0.9 - (0.9 - 0.4) * (self.budget - self.local_budget) / self.budget  # Dynamic inertia update\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = self.dim // 2\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "The improved algorithm refines the velocity update mechanism by adjusting inertia dynamically to enhance convergence speed and exploration balance.", "configspace": "", "generation": 9, "fitness": 0.9639525783719419, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2c190e23-4af6-4b6d-8d39-b5c6e854fa21", "metadata": {"aucs": [0.952532190716581, 0.9840012247112513, 0.9553243196879933], "final_y": [0.16485577190554035, 0.16485577190539702, 0.16485577190481393]}, "mutation_prompt": null}
{"id": "27e1ff69-4b6d-4754-b852-a3ce00ceb2df", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8  # Change line: Adjust initialization\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 3)  # Change line: Modify periodic encouragement step\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "A refined hybrid PSO algorithm that enhances periodicity and exploration of multilayer photonic structures using a modified initialization and periodic encouragement step.", "configspace": "", "generation": 10, "fitness": 0.9820861612061732, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2c190e23-4af6-4b6d-8d39-b5c6e854fa21", "metadata": {"aucs": [0.9889564814923388, 0.9830733991473203, 0.9742286029788607], "final_y": [0.16485577190491374, 0.16485577190486667, 0.1648557719047532]}, "mutation_prompt": null}
{"id": "60020b80-f2ad-4544-8595-918489d82b5e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.inertia = 0.5 + 0.5 * (1 - iteration / max_iterations)  # Change line: Dynamic inertia scaling based on iteration\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 3)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhanced velocity update rule in HybridPSONM to improve convergence by scaling inertia dynamically based on iteration count.", "configspace": "", "generation": 11, "fitness": 0.9479416440086053, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27e1ff69-4b6d-4754-b852-a3ce00ceb2df", "metadata": {"aucs": [0.9737572741145144, 0.9342381556096087, 0.9358295023016926], "final_y": [0.16485577190543987, 0.16485577190476808, 0.1648557719048549]}, "mutation_prompt": null}
{"id": "dd156d98-aca5-41eb-8e52-7f9a47636f82", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.6  # Change line: Slightly increased cognitive coefficient\n        self.social_coef = 1.6     # Change line: Slightly increased social coefficient\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 3)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "A refined hybrid PSO algorithm enhancing exploration by slightly increasing cognitive and social learning components.", "configspace": "", "generation": 12, "fitness": 0.9422306565376269, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.059. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27e1ff69-4b6d-4754-b852-a3ce00ceb2df", "metadata": {"aucs": [0.985944218519628, 0.8582973305975952, 0.9824504204956579], "final_y": [0.16485577190490586, 0.16485577190482525, 0.16485577190480472]}, "mutation_prompt": null}
{"id": "a6b9d6f6-1523-46bf-a7dd-86300650ca95", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.9  # Change line: Adjusted initialization scale\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)  # Change line: Modified periodic encouragement step\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "A refined hybrid PSO algorithm that enhances periodicity and exploration of multilayer photonic structures by tweaking initialization and periodic encouragement steps for improved optimization performance.", "configspace": "", "generation": 13, "fitness": 0.9782393043047962, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.978 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27e1ff69-4b6d-4754-b852-a3ce00ceb2df", "metadata": {"aucs": [0.984998687871506, 0.9633560666268091, 0.9863631584160732], "final_y": [0.1648557719048902, 0.16485577190495537, 0.16485577190484557]}, "mutation_prompt": null}
{"id": "0adbd58f-948d-461b-af1b-dabd4639a9eb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8  # Change line: Adjust initialization\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (\n            (0.9 - self.inertia) * (self.budget - self.local_budget) / self.budget + 0.4 + self.inertia * self.velocities +  # Dynamic inertia adjustment\n            self.cognitive_coef * r1 * (personal_best - population) +\n            self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 3)  # Change line: Modify periodic encouragement step\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce a dynamic adjustment of the inertia weight to balance exploration and exploitation in the PSO phase.", "configspace": "", "generation": 14, "fitness": 0.936447427061477, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.936 with standard deviation 0.060. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27e1ff69-4b6d-4754-b852-a3ce00ceb2df", "metadata": {"aucs": [0.9873192356497794, 0.8529441436584404, 0.9690789018762112], "final_y": [0.16485577190497014, 0.16485577190481282, 0.164855771904877]}, "mutation_prompt": null}
{"id": "8331de5b-38ec-4a00-b65c-91cd559ceb9d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8  # Change line: Adjust initialization\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)  # Change line: Modify periodic encouragement step for finer granularity\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhanced the periodic encouragement step in HybridPSONM by adjusting the periodicity granularity to explore finer structures.", "configspace": "", "generation": 15, "fitness": 0.9821400476916707, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27e1ff69-4b6d-4754-b852-a3ce00ceb2df", "metadata": {"aucs": [0.9889585684383448, 0.9830824920681953, 0.9743790825684719], "final_y": [0.16485577190478728, 0.16485577190483258, 0.16485577190480538]}, "mutation_prompt": null}
{"id": "df7bdaa6-d855-4da7-a860-1484389e7c1c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Change line: Increased the population size for broader exploration\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 3)  # Change line: Refined the period for periodicity encouragement\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Fine-tuned the periodicity encouragement period and increased the population size for broader exploration.", "configspace": "", "generation": 16, "fitness": 0.9436120386711627, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.058. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8331de5b-38ec-4a00-b65c-91cd559ceb9d", "metadata": {"aucs": [0.9829281608830347, 0.8622319703013849, 0.9856759848290688], "final_y": [0.1648557719047763, 0.16485577190513634, 0.1648557719048983]}, "mutation_prompt": null}
{"id": "e61dd07a-a25c-4a76-8cfc-71b47200d471", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8  # Change line: Adjust initialization\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 6)  # Change line: Modify periodic encouragement step for finer granularity\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='BFGS', options={'maxiter': self.local_budget})  # Change line: Use BFGS for local refinement\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Improved local refinement by using BFGS for faster convergence, optimizing the periodic encouragement with granular refinement.", "configspace": "", "generation": 17, "fitness": 0.9820846363992534, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8331de5b-38ec-4a00-b65c-91cd559ceb9d", "metadata": {"aucs": [0.9889586422536725, 0.9830818385028428, 0.9742134284412448], "final_y": [0.16485582126377507, 0.1648562464581257, 0.16486279069999965]}, "mutation_prompt": null}
{"id": "bfb9929d-89f8-4a9e-979f-24746c44a8bb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8  # Change line: Adjust initialization\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        modularity_factor = np.cos(np.linspace(0, np.pi, self.dim))  # Change line: Adding modularity factor\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population)) * modularity_factor\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)  # Change line: Modify periodic encouragement step for finer granularity\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Improved the velocity update mechanism by adding a factor to preserve modularity in solutions, enhancing exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.7910778623438285, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.042. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8331de5b-38ec-4a00-b65c-91cd559ceb9d", "metadata": {"aucs": [0.8375489077760417, 0.736104228937575, 0.799580450317869], "final_y": [0.1648557719049566, 0.1648557719049687, 0.16485577190480272]}, "mutation_prompt": null}
{"id": "8c2c724b-1a9b-4809-b98e-ad632e585d96", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.5\n        self.cognitive_coef = 1.2  # Change line: Adjust cognitive coefficient\n        self.social_coef = 1.2  # Change line: Adjust social coefficient\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Adjusted cognitive and social coefficients to improve convergence speed in HybridPSONM.", "configspace": "", "generation": 19, "fitness": 0.9835348302505711, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.984 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8331de5b-38ec-4a00-b65c-91cd559ceb9d", "metadata": {"aucs": [0.9894545906594381, 0.9744634399272109, 0.9866864601650647], "final_y": [0.1648557719049214, 0.16485577190474332, 0.1648557719047422]}, "mutation_prompt": null}
{"id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhance performance by slightly increasing the inertia weight to improve balance between exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.9856912186658094, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8c2c724b-1a9b-4809-b98e-ad632e585d96", "metadata": {"aucs": [0.990242676254333, 0.9779763263476656, 0.9888546533954296], "final_y": [0.16485577190540723, 0.16485577190479628, 0.16485577190483214]}, "mutation_prompt": null}
{"id": "0be55ac2-c819-448c-bd51-cd6a37761b25", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6\n        self.cognitive_coef = 1.4  # Change line: Slightly increase cognitive coefficient for enhanced personal exploration\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Slightly increase the cognitive coefficient to boost personal learning and exploration capabilities.", "configspace": "", "generation": 21, "fitness": 0.985336539619149, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9904286292390939, 0.976480522797189, 0.989100466821164], "final_y": [0.16485577190480027, 0.16485577190502998, 0.16485577190503198]}, "mutation_prompt": null}
{"id": "393cfe8c-d438-4329-99ce-057620c64dda", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6  # Original inertia\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        decay_factor = 0.99  # New line: Introduce inertia decay factor\n        self.inertia *= decay_factor  # New line: Apply decay factor to inertia\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce a decay factor in the inertia weight to adaptively adjust the exploration-exploitation balance over iterations.", "configspace": "", "generation": 22, "fitness": 0.9826715697281548, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.983 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9899312250177815, 0.9673399537546676, 0.9907435304120153], "final_y": [0.16485577190506284, 0.1648557719052638, 0.16485577190479628]}, "mutation_prompt": null}
{"id": "223dd399-79a4-45e3-8748-10a547b4e0fd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7  # Change line: Adaptive inertia for dynamic exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        base_population = np.random.uniform(lb, ub, (self.population_size // 2, self.dim))\n        opposite_population = lb + ub - base_population  # Change line: Quasi-oppositional initialization\n        population = np.vstack([base_population, opposite_population])\n        return np.clip(population, lb, ub)\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n            self.inertia *= 0.99  # Change line: Gradually reduce inertia over iterations\n\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Refine exploration by adaptive inertia and integrate symmetry in initialization for enhanced sampling.", "configspace": "", "generation": 23, "fitness": 0.9694358724681388, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9527393389658182, 0.9814624965396496, 0.9741057818989483], "final_y": [0.16485577190500833, 0.1648557719047885, 0.1648557719050614]}, "mutation_prompt": null}
{"id": "7926a4ad-fdb3-4464-a342-c156a664451b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        base_structure = np.random.uniform(lb, ub, (self.population_size, period))\n        population = np.tile(base_structure, (1, self.dim // period + 1))[:, :self.dim]  # Change line: Implement periodic initialization\n        return np.clip(population, lb, ub)\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce a periodic initialization mechanism to enhance solution diversity and initial convergence.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (20, 2) and arg 1 with shape (10,).').", "error": "ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (20, 2) and arg 1 with shape (10,).')", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {}, "mutation_prompt": null}
{"id": "f5e2fb6e-3844-410f-88f5-1f897900f0b5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.3  # Change line: Slightly increase social coefficient for improved cooperation\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Infuse dynamic social interaction by slightly increasing the social coefficient for improved cooperation in particle swarm optimization.", "configspace": "", "generation": 25, "fitness": 0.9849056404669972, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9905811572781535, 0.9813780136368593, 0.982757750485979], "final_y": [0.1648557719053112, 0.16485577190480438, 0.16485577190511502]}, "mutation_prompt": null}
{"id": "e5badbf3-6f55-4f94-af88-87ae2020b02e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6  # Change line: Dynamic inertia adjustment to improve adaptive balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.inertia = 0.5 + np.random.rand() * 0.1  # Dynamic inertia adjustment\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce dynamic inertia adjustment in PSO to enhance convergence performance.", "configspace": "", "generation": 26, "fitness": 0.984232019760792, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.984 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9873047125450283, 0.9776906971033877, 0.9877006496339598], "final_y": [0.16485577190474188, 0.16485577190506018, 0.1648557719048741]}, "mutation_prompt": null}
{"id": "1da2786d-01b1-414c-9bac-bbf5098ee695", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        perturbed_solution = self._encourage_periodicity(solution, bounds)  # Change 1: Encourage periodicity initially\n        result = minimize(func, perturbed_solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def _periodicity_aware_perturbation(self, solution, bounds):  # Change 2: New function\n        period = self.dim // 4  # Change 3: Adjust periodic perturbation\n        perturbation = np.sin(np.linspace(0, 2 * np.pi, period))  # Change 4: Use sinusoidal perturbation\n        perturbed_solution = solution + np.tile(perturbation, self.dim // period)\n        return np.clip(perturbed_solution, bounds[0], bounds[1])\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._periodicity_aware_perturbation(best_solution, bounds)  # Change 5: Apply perturbation\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Integrate a periodicity-aware perturbation strategy to enhance local search capabilities and convergence speed.", "configspace": "", "generation": 27, "fitness": 0.9856912186658094, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.990242676254333, 0.9779763263476656, 0.9888546533954296], "final_y": [0.16485577190540723, 0.16485577190479628, 0.16485577190483214]}, "mutation_prompt": null}
{"id": "9ee007ea-fb2c-467a-98bb-3685d21cb066", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6\n        self.cognitive_coef = 1.3  # Change line: Increase cognitive coefficient for better convergence speed and solution quality\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhance performance by increasing the cognitive coefficient to improve convergence speed and solution quality.", "configspace": "", "generation": 28, "fitness": 0.9847856119852082, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9884821274651993, 0.9742336566771799, 0.9916410518132452], "final_y": [0.16485577190540113, 0.1648557719049074, 0.1648557719052256]}, "mutation_prompt": null}
{"id": "fe15868d-6f3a-4115-b608-83266de0d8e3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.9  # Initial inertia\n        self.inertia_decay = 0.98  # Decay inertia adaptively\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n        self.inertia *= self.inertia_decay  # Apply inertia decay\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        # Use Fourier transform to enforce periodicity\n        freq_domain = np.fft.rfft(solution)\n        period = max(2, self.dim // 4)\n        # Retain only the first 'period' frequencies\n        freq_domain[period:] = 0\n        periodic_solution = np.fft.irfft(freq_domain, n=self.dim)\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "AdaptiveHybridPSONM", "description": "Introduce adaptive inertia in PSO and enhance periodicity enforcement through Fourier analysis for better convergence.", "configspace": "", "generation": 29, "fitness": 0.9831206392572396, "feedback": "The algorithm AdaptiveHybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.983 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9845017655925008, 0.9771216489690735, 0.9877385032101443], "final_y": [0.1648557719051763, 0.16485577190496503, 0.16485577190490397]}, "mutation_prompt": null}
{"id": "680d4f7c-bbc7-4e11-accd-ad7950040508", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6\n        self.cognitive_coef = 1.4  # Change line: Increase cognitive coefficient for better individual learning\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Improve PSO by increasing cognitive coefficient for enhanced individual learning.", "configspace": "", "generation": 30, "fitness": 0.985336539619149, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9904286292390939, 0.976480522797189, 0.989100466821164], "final_y": [0.16485577190480027, 0.16485577190502998, 0.16485577190503198]}, "mutation_prompt": null}
{"id": "adec7406-79d7-4b1c-b64c-384b60a97290", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6\n        self.cognitive_coef = 1.5  # Change line: Adjust cognitive coefficient to enhance personal best influence\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Refine the HybridPSONM algorithm by adjusting the cognitive coefficient to enhance the personal best influence during exploration.", "configspace": "", "generation": 31, "fitness": 0.984365177370902, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.984 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9893239765892303, 0.9729177818004383, 0.9908537737230378], "final_y": [0.1648557719048238, 0.16485577190491107, 0.16485577190478995]}, "mutation_prompt": null}
{"id": "2fea572d-5982-4d09-a396-64576fe81162", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.inertia = 0.5 + 0.4 * np.random.rand()  # Change line: Dynamic inertia adjustment for adaptive exploration-exploitation balance\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce dynamic inertia adjustment to balance exploration and exploitation adaptively.", "configspace": "", "generation": 32, "fitness": 0.9828068666492945, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.983 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9899710194842919, 0.9701861650020481, 0.9882634154615433], "final_y": [0.16485577190481182, 0.16485577190481027, 0.1648557719047975]}, "mutation_prompt": null}
{"id": "e4853fed-6204-447d-a975-61f4ad5ec241", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6\n        self.cognitive_coef = 1.3  # Change line: Slightly increase cognitive coefficient for improved individual exploration\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Slightly increase cognitive coefficient for improved individual exploration in the optimization process.", "configspace": "", "generation": 33, "fitness": 0.9847856119852082, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9884821274651993, 0.9742336566771799, 0.9916410518132452], "final_y": [0.16485577190540113, 0.1648557719049074, 0.1648557719052256]}, "mutation_prompt": null}
{"id": "2e85bfa3-2ff9-48e0-964d-4d7a39f4534a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6  # Change line 1: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.4  # Change line 2: Increase social coefficient for better convergence\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Adjust social coefficient for improved convergence and introduce diverse initialization to enhance coverage.", "configspace": "", "generation": 34, "fitness": 0.978089630012483, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.978 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9613728702480934, 0.98890126502354, 0.9839947547658155], "final_y": [0.1648557719049626, 0.16485577190485168, 0.16485577190604928]}, "mutation_prompt": null}
{"id": "a08e602d-1e11-41fa-a3c4-e488e790ca2e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7  # Change line: Further increase inertia for improved global search capability\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.9  # Change line: Increase scale factor for initial diversity\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Refine the inertia weight for better exploration while enhancing periodicity in initialization.", "configspace": "", "generation": 35, "fitness": 0.9423707320932363, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.059. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.986249981029462, 0.8585719097088855, 0.9822903055413613], "final_y": [0.16485577190483602, 0.16485577190501477, 0.16485577190496015]}, "mutation_prompt": null}
{"id": "ae4e27cc-9f41-4704-a1a1-6cce5d956a68", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6\n        self.cognitive_coef = 1.4  # Change line: Slightly increase cognitive coefficient for better individual exploration\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Slightly adjust the cognitive coefficient for improved individual exploration in Particle Swarm Optimization.", "configspace": "", "generation": 36, "fitness": 0.985336539619149, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9904286292390939, 0.976480522797189, 0.989100466821164], "final_y": [0.16485577190480027, 0.16485577190502998, 0.16485577190503198]}, "mutation_prompt": null}
{"id": "de2151b2-9d3b-44a3-9f5e-689396db20d8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass QODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.F = 0.8\n        self.CR = 0.9\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_population = lb + ub - population\n        combined_population = np.vstack((population, opposite_population))\n        return combined_population[:self.population_size]\n\n    def _mutate(self, population):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        mutant_vector = a + self.F * (b - c)\n        return mutant_vector\n\n    def _crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial_vector = np.where(crossover_mask, mutant, target)\n        return trial_vector\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n        best_solution = None\n        best_score = float('inf')\n\n        # Differential Evolution\n        for _ in range(self.init_budget // self.population_size):\n            for i in range(self.population_size):\n                target = population[i]\n                mutant = self._mutate(population)\n                trial = self._crossover(target, mutant)\n                trial = np.clip(trial, *bounds)\n                trial_score = func(trial)\n                target_score = func(target)\n                if trial_score < target_score:\n                    population[i] = trial\n                    if trial_score < best_score:\n                        best_score = trial_score\n                        best_solution = trial\n\n        # Encourage periodicity\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n        \n        # Local refinement\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "QODE", "description": "Leverage Quasi-Oppositional Differential Evolution (QODE) with adaptive weight factors to explore and exploit the search space efficiently and encourage periodicity for multilayered structure optimization.", "configspace": "", "generation": 37, "fitness": 0.7439480355224473, "feedback": "The algorithm QODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.744 with standard deviation 0.026. And the mean value of best solutions found was 0.180 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.7624370505922906, 0.7069081174146725, 0.7624989385603786], "final_y": [0.16805331823751213, 0.1856073110487403, 0.18620713821158774]}, "mutation_prompt": null}
{"id": "51b0fc6a-9a36-410b-8f8e-0065a1f5ac79", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        # Adaptive inertia dynamically changes based on the iteration count\n        adaptive_inertia = self.inertia * (0.5 + np.random.rand() * 0.5)\n        self.velocities = (adaptive_inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        # Dynamic period adjustment based on solution quality\n        period = max(2, min(self.dim // 4, int((1.0 / np.std(solution)) * 5)))\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive inertia and dynamic periodic encouragement to enhance exploration and tractability of wave interference patterns.", "configspace": "", "generation": 38, "fitness": 0.9785573796208284, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.979 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9926446783896191, 0.9660144880878276, 0.9770129723850385], "final_y": [0.1648557719051621, 0.16485577190505762, 0.16485577190479295]}, "mutation_prompt": null}
{"id": "6faa3881-7821-455e-9a32-3b4a252743c7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.6\n        self.cognitive_coef = 1.3  # Change line: Slightly increase the cognitive coefficient for better individual exploration\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Slightly increase the cognitive coefficient to enhance the individual exploration capability.", "configspace": "", "generation": 39, "fitness": 0.9847856119852082, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9884821274651993, 0.9742336566771799, 0.9916410518132452], "final_y": [0.16485577190540113, 0.1648557719049074, 0.1648557719052256]}, "mutation_prompt": null}
{"id": "519d5819-6250-4911-8c74-b95f01d9b55f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce a slightly higher inertia weight to improve the balance between exploration and exploitation in the PSO phase.", "configspace": "", "generation": 40, "fitness": 0.986585578735712, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.987 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d6e3993b-36d5-41d6-99f1-96da35af4dd5", "metadata": {"aucs": [0.9898854585047704, 0.9788353760988489, 0.9910359016035164], "final_y": [0.16485577190475764, 0.16485577190483047, 0.16485577190500245]}, "mutation_prompt": null}
{"id": "195c013b-21bd-4b45-9b0b-0592a998d60e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.4  # Change line: Increase social coefficient for better global exploration\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Increase social coefficient for more effective global exploration in PSO phase.", "configspace": "", "generation": 41, "fitness": 0.9837723384930372, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.984 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.990386871047276, 0.9788174141556081, 0.9821127302762276], "final_y": [0.1648557719048236, 0.16485577190475664, 0.16485577190476453]}, "mutation_prompt": null}
{"id": "40751932-f840-4d19-8636-2c8b6946b6e6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.3  # Change line: Slightly increase social coefficient for better convergence\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Slightly increase social coefficient to improve information sharing among particles for better convergence.", "configspace": "", "generation": 42, "fitness": 0.9851531539697741, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9911962317543583, 0.980514687188857, 0.9837485429661067], "final_y": [0.16485577190498513, 0.16485577190476497, 0.16485577190476886]}, "mutation_prompt": null}
{"id": "a45f1949-c33d-412f-9578-e4e87178e08b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.9  # Change line: Use adaptive inertia strategy\n        self.cognitive_coef = 1.4  # Change line: Adjust cognitive coefficient\n        self.social_coef = 1.4  # Change line: Adjust social coefficient\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.elite_ratio = 0.1  # Change line: Introduce elite ratio for elite selection\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iter):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.inertia = 0.9 - (iteration / max_iter) * 0.5  # Change line: Adaptive inertia decrease\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _elite_selection(self, population, scores):\n        elite_count = int(self.elite_ratio * self.population_size)\n        elite_indices = np.argsort(scores)[:elite_count]\n        return population[elite_indices]\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        max_iter = self.init_budget // self.population_size\n        for iteration in range(max_iter):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iter)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n            if iteration % 5 == 0:  # Change line: Apply elite selection every 5 iterations\n                elite_population = self._elite_selection(population, scores)\n                population[:len(elite_population)] = elite_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhance HybridPSONM by integrating adaptive inertia weight and elite selection to improve convergence speed and solution quality.", "configspace": "", "generation": 43, "fitness": 0.9656760952101929, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9811579891600776, 0.9486360702948707, 0.9672342261756306], "final_y": [0.1648557719047855, 0.16485577190509904, 0.1648557719049969]}, "mutation_prompt": null}
{"id": "d3f273e8-92f1-4e7a-b2d9-9a4ad6f1e3ee", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Initial inertia value\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        dynamic_inertia = self.inertia - (self.inertia * (iteration / max_iterations))  # Line changed: Dynamic inertia weight\n        self.velocities = (dynamic_inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Utilize a dynamic inertia weight to further balance exploration and exploitation in the PSO phase.", "configspace": "", "generation": 44, "fitness": 0.986253519990746, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9915204026848216, 0.9766141031756352, 0.9906260541117812], "final_y": [0.16485577190475043, 0.16485577190475276, 0.1648557719050493]}, "mutation_prompt": null}
{"id": "ae38f4ab-7370-48c8-8797-2aad7befdb78", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.3  # Change line: Slightly increase social coefficient for better convergence\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Increase social coefficient slightly to enhance cooperation and convergence towards global best.", "configspace": "", "generation": 45, "fitness": 0.9851531539697741, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9911962317543583, 0.980514687188857, 0.9837485429661067], "final_y": [0.16485577190498513, 0.16485577190476497, 0.16485577190476886]}, "mutation_prompt": null}
{"id": "d3f51325-a106-440d-b5c2-01daca1d365a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.4  # Change line: Increase social coefficient for enhanced global search\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Adjusted the social coefficient to enhance the global collaborative search in the PSO phase.", "configspace": "", "generation": 46, "fitness": 0.9837723384930372, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.984 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.990386871047276, 0.9788174141556081, 0.9821127302762276], "final_y": [0.1648557719048236, 0.16485577190475664, 0.16485577190476453]}, "mutation_prompt": null}
{"id": "a45dae2f-26bb-49b0-93cf-0c5ac959a1c2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7  # Change line: Further increase inertia to enhance exploration\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n                personal_best_scores += 0.01  # Change line: Encourage improvement by subtly rewarding all individuals\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Refine inertia and update personal best tracking in PSO for enhanced convergence.", "configspace": "", "generation": 47, "fitness": 0.9847715237341133, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9894103473109633, 0.9759063997690096, 0.9889978241223666], "final_y": [0.16485577190514022, 0.16485577190488698, 0.16485577190483625]}, "mutation_prompt": null}
{"id": "65e7ff58-10ad-484f-a4c7-2557f1fcc3fa", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.5  # Change line: Increase cognitive coefficient for better personal experience exploration\n        self.social_coef = 0.9  # Change line: Decrease social coefficient to slightly reduce influence of global best\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Maintain the inertia weight but adjust the cognitive and social coefficients to enhance exploration capabilities.", "configspace": "", "generation": 48, "fitness": 0.9446189683559654, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.061. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9846392816408671, 0.8582511633976815, 0.9909664600293477], "final_y": [0.16485577190497336, 0.16485577190484368, 0.16485577190496892]}, "mutation_prompt": null}
{"id": "efb54331-4883-468b-8973-730dbc72eef1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.4  # Change line: Slightly increase cognitive_coef for better individual adaptability\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Slightly adjust the cognitive coefficient to enhance individual learning and adaptability within the PSO phase.", "configspace": "", "generation": 49, "fitness": 0.9863319007944434, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9900485441804201, 0.9798075881325171, 0.9891395700703934], "final_y": [0.1648557719047542, 0.1648557719048689, 0.16485577190480172]}, "mutation_prompt": null}
{"id": "6be81a7d-b39e-42c1-a575-1aa0105b5e56", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.3  # Change line: Slightly increase cognitive coefficient for better exploration\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhance exploration by increasing the cognitive coefficient slightly in the PSO phase.", "configspace": "", "generation": 50, "fitness": 0.9857155703499675, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9902119284041416, 0.9784056309082124, 0.9885291517375481], "final_y": [0.1648557719054906, 0.16485577190482237, 0.16485577190479095]}, "mutation_prompt": null}
{"id": "273ff7db-66ff-4b1e-8b6f-695bae12fea5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Introduce adaptive inertia by linearly decreasing it\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        adaptive_inertia = self.inertia - 0.2 * (iteration / max_iterations)  # Line updated to introduce adaptive inertia\n        self.velocities = (adaptive_inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive inertia to dynamically balance exploration and exploitation in PSO phase.", "configspace": "", "generation": 51, "fitness": 0.9854086861370424, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9895879417029686, 0.9766618464155103, 0.9899762702926482], "final_y": [0.1648557719048015, 0.16485577190483902, 0.1648557719049255]}, "mutation_prompt": null}
{"id": "dae8bcca-4f9c-4314-8827-fc89df89642c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Introduce adaptive inertia for dynamic exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.inertia = 0.5 + (0.9 - 0.5) * (self.budget - self.init_budget) / self.budget  # Adaptive inertia\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce an adaptive inertia weight to dynamically balance exploration and exploitation in the PSO phase.", "configspace": "", "generation": 52, "fitness": 0.9847190238072052, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9892442446809345, 0.9762274237202717, 0.9886854030204092], "final_y": [0.16485577190477596, 0.16485577190523348, 0.16485577190507184]}, "mutation_prompt": null}
{"id": "6bf0fb58-0dd9-43ca-ac1a-6e593cf7f264", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.5  # Change line: Increase social coefficient for better convergence speed and exploration\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Increase social coefficient to improve convergence speed and global exploration.", "configspace": "", "generation": 53, "fitness": 0.9793742753776226, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.979 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9886812381788608, 0.977309622984246, 0.9721319649697611], "final_y": [0.16485577190514955, 0.1648557719048228, 0.16485577190478728]}, "mutation_prompt": null}
{"id": "8465fe09-4d42-4e18-bc5e-682871aa1635", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65 \n        self.cognitive_coef = 1.2  # Original line\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self.cognitive_coef = 0.5 + 0.5 * np.random.rand()  # Change line: Adaptive cognitive coefficient\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhance the PSO phase by using an adaptive cognitive coefficient for better exploration-exploitation balance.", "configspace": "", "generation": 54, "fitness": 0.9444903444013567, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.059. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9852644261576448, 0.8605640222191523, 0.9876425848272731], "final_y": [0.1648557719059044, 0.16485577190495937, 0.1648557719048397]}, "mutation_prompt": null}
{"id": "093b322a-53a8-45ce-aeec-27533628189a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.3  # Change line: Slightly increase cognitive coefficient for better adaptability\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Increase the cognitive coefficient slightly to enhance the algorithm's adaptability to individual solutions.", "configspace": "", "generation": 55, "fitness": 0.9857155703499675, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9902119284041416, 0.9784056309082124, 0.9885291517375481], "final_y": [0.1648557719054906, 0.16485577190482237, 0.16485577190479095]}, "mutation_prompt": null}
{"id": "799f0819-efc1-4393-be12-590fc5bdec21", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.5  # Change line: Increase cognitive coefficient for enhanced exploration\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Increase cognitive coefficient to enhance individual exploration capabilities.", "configspace": "", "generation": 56, "fitness": 0.9852421046937293, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9884643119738039, 0.978154766795752, 0.9891072353116319], "final_y": [0.16485577190491307, 0.16485577190538514, 0.16485577190509437]}, "mutation_prompt": null}
{"id": "c8957d4f-06fb-4351-9749-0036e408a5a8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        constriction_factor = 0.729  # Change line: Introduce constriction factor to velocity update\n        self.velocities = (constriction_factor * (self.inertia * self.velocities +\n                          self.cognitive_coef * r1 * (personal_best - population) +\n                          self.social_coef * r2 * (global_best - population)))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Adjust velocity update formula in PSO to enhance convergence speed by incorporating constriction coefficient.", "configspace": "", "generation": 57, "fitness": 0.9795199974684916, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.980 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9875520497382685, 0.9721633998822333, 0.9788445427849732], "final_y": [0.1648557719047976, 0.16485577190491052, 0.16485577190472234]}, "mutation_prompt": null}
{"id": "02c2e925-0eca-4da3-b989-1d62b1e69ed8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Initial inertia\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iter_count, max_iter):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        dynamic_inertia = self.inertia - 0.3 * (iter_count / max_iter)  # Change line: Introduce dynamic inertia\n        self.velocities = (dynamic_inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        max_iter = self.init_budget // self.population_size\n        for iter_count in range(max_iter):\n            self._update_velocities(population, personal_best, global_best, iter_count, max_iter)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce a dynamic inertia weight to adaptively balance exploration and exploitation in the PSO phase.", "configspace": "", "generation": 58, "fitness": 0.9857636310356029, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9896458231139681, 0.9784190855151531, 0.9892259844776876], "final_y": [0.16485577190482525, 0.16485577190490863, 0.164855771904862]}, "mutation_prompt": null}
{"id": "bdfbd4ae-ebae-4f92-9c8d-2d507f7761b6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.5  # Change line: Increase social coefficient for improved convergence\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Increase social coefficient to enhance convergence speed by promoting stronger global information sharing.", "configspace": "", "generation": 59, "fitness": 0.9793742753776226, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.979 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9886812381788608, 0.977309622984246, 0.9721319649697611], "final_y": [0.16485577190514955, 0.1648557719048228, 0.16485577190478728]}, "mutation_prompt": null}
{"id": "6c7c0711-6756-4773-96cc-e53a24150421", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 3)  # Change line: Dynamically adjust period based on dimension\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Refine the periodicity encouragement step by dynamically adjusting the period based on problem dimension to improve solution quality.", "configspace": "", "generation": 60, "fitness": 0.986576068359812, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.987 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.989860284417401, 0.9788320195306915, 0.9910359011313437], "final_y": [0.1648557719048762, 0.1648557719047563, 0.16485577190595269]}, "mutation_prompt": null}
{"id": "3ea0e182-9cd5-4456-b4ce-9eeba33317d1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n    \n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)  # Change line: Dynamically adjust cognitive coefficient\n        self.social_coef = min(2.0, self.social_coef + 0.01)  # Change line: Dynamically adjust social coefficient\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce dynamic cognitive and social coefficients to improve adaptation during the PSO phase.", "configspace": "", "generation": 61, "fitness": 0.9880899953398702, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.988 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "519d5819-6250-4911-8c74-b95f01d9b55f", "metadata": {"aucs": [0.9914481269972102, 0.982119407837596, 0.9907024511848043], "final_y": [0.1648557719049405, 0.1648557719050724, 0.16485577190485046]}, "mutation_prompt": null}
{"id": "e3a6a3b3-250e-4cbb-9b34-1ca1b889a19b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Change line: Increase population size for better exploration\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n    \n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.velocities = (self.inertia * self.velocities + \n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Increase the population size for improved diversity and solution quality in the PSO phase.", "configspace": "", "generation": 62, "fitness": 0.944088511663141, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.060. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3ea0e182-9cd5-4456-b4ce-9eeba33317d1", "metadata": {"aucs": [0.9865212784013482, 0.8592770694913308, 0.9864671870967439], "final_y": [0.16485577190513556, 0.16485577190480027, 0.16485577190483824]}, "mutation_prompt": null}
{"id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99  # New line: Introduce velocity decay\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)  # Change line: Dynamically adjust cognitive coefficient\n        self.social_coef = min(2.0, self.social_coef + 0.01)  # Change line: Dynamically adjust social coefficient\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce a velocity decay factor to the PSO phase to enhance convergence stability.", "configspace": "", "generation": 63, "fitness": 0.9881340811458074, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.988 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3ea0e182-9cd5-4456-b4ce-9eeba33317d1", "metadata": {"aucs": [0.99118099968703, 0.9822996924731245, 0.9909215512772674], "final_y": [0.16485577190513656, 0.16485577190489176, 0.1648557719048187]}, "mutation_prompt": null}
{"id": "d0b175f8-3534-4488-b6a8-b98000621716", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99  # New line: Introduce velocity decay\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)  # Change line: Dynamically adjust cognitive coefficient\n        self.social_coef = min(2.0, self.social_coef + 0.01)  # Change line: Dynamically adjust social coefficient\n        self.inertia = 0.5 + (0.5 * np.mean(personal_best - global_best)**2)  # Change line: Introduce adaptive inertia\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive inertia weights in the PSO phase to enhance exploration and exploitation dynamics.", "configspace": "", "generation": 64, "fitness": 0.7728598289759679, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.167. And the mean value of best solutions found was 0.236 (0. is the best) with standard deviation 0.101.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.8875326019973725, 0.5364858653055162, 0.8945610196250152], "final_y": [0.16485577190475276, 0.3792029072839809, 0.16485577190507827]}, "mutation_prompt": null}
{"id": "75fc26a8-5bb0-4bed-9ba3-0aead9cf9c99", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.velocity_decay = 0.99 if np.random.rand() > 0.5 else 0.95  # New line: Adaptive velocity decay\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive velocity decay to balance exploration and exploitation dynamically.", "configspace": "", "generation": 65, "fitness": 0.9866400641173332, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.987 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9921426345657445, 0.9772869629153091, 0.9904905948709458], "final_y": [0.16485577190563028, 0.16485577190477407, 0.16485577190480094]}, "mutation_prompt": null}
{"id": "02f39c19-f1a4-4718-9147-553044fffb75", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.velocities = (1 - self.init_budget / self.budget) * self.velocity_decay * (self.inertia * self.velocities +  # Change line: Adaptive velocity decay based on iteration\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive velocity decay based on iteration count to balance exploration and exploitation.", "configspace": "", "generation": 66, "fitness": 0.9530674181729819, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9563875643291344, 0.9358466627573956, 0.9669680274324158], "final_y": [0.16485577190500256, 0.1648557719049787, 0.16485577190480616]}, "mutation_prompt": null}
{"id": "b13e0413-7b2c-40de-a631-320f794fcc16", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99  # New line: Introduce velocity decay\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)  # Change line: Dynamically adjust cognitive coefficient\n        self.social_coef = np.random.uniform(0.5, 2.0)  # Change line: Randomize social coefficient for better exploration\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Improved global exploration by randomizing the social coefficient more dynamically.", "configspace": "", "generation": 67, "fitness": 0.9442620416030746, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.064. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9898828950072409, 0.8537696599064598, 0.9891335698955228], "final_y": [0.16485577190528344, 0.16485577190477574, 0.16485577190491152]}, "mutation_prompt": null}
{"id": "8a20bde1-052e-48c1-8302-52779c14bf96", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99  # New line: Introduce velocity decay\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))  # Change line: Remove multiplication by 0.8 for full spread exploration\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)  # Change line: Dynamically adjust cognitive coefficient\n        self.social_coef = min(2.0, self.social_coef + 0.01)  # Change line: Dynamically adjust social coefficient\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Adjust the initial population spread to better explore the search space and enhance solution diversity.", "configspace": "", "generation": 68, "fitness": 0.9768213660091583, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9613315869715405, 0.9869142677034703, 0.982218243352464], "final_y": [0.1648557719047583, 0.16485577190521428, 0.1648557719047492]}, "mutation_prompt": null}
{"id": "b11826d0-29b5-441a-989e-7920b7202431", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99  # New line: Introduce velocity decay\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n        # New line: Introduce quasi-oppositional initialization\n        opposite_population = lb + ub - population\n        return np.vstack((population, opposite_population))\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)  # Change line: Dynamically adjust cognitive coefficient\n        self.social_coef = min(2.0, self.social_coef + 0.01)  # Change line: Dynamically adjust social coefficient\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhance the population's diversity by using quasi-oppositional initialization to improve exploration.", "configspace": "", "generation": 69, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,10) (40,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,10) (40,10) ')", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {}, "mutation_prompt": null}
{"id": "7e6df495-138f-4752-9245-9132e7a5a934", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Dynamic inertia adjustment for better convergence\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        # Introducing a dynamic inertia adjustment\n        self.inertia = max(0.4, self.inertia * 0.99)\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce a dynamic inertia adjustment in PSO for improved convergence balancing.", "configspace": "", "generation": 70, "fitness": 0.9864998324511998, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.989117681519857, 0.9792243131778122, 0.9911575026559298], "final_y": [0.16485577190484801, 0.16485577190567247, 0.16485577190501544]}, "mutation_prompt": null}
{"id": "e117a7b9-ee5b-4e72-9ac5-c2b4cc1337be", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.inertia = max(0.4, self.inertia - 0.01)  # Change line: Dynamically adjust inertia\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhance the exploration-exploitation balance by dynamically adjusting the inertia coefficient during the PSO phase.", "configspace": "", "generation": 71, "fitness": 0.9847120046744046, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9883536634003829, 0.976436452293797, 0.9893458983290341], "final_y": [0.1648557719048951, 0.16485577190903866, 0.16485577190501677]}, "mutation_prompt": null}
{"id": "445c111c-8092-4e05-a323-c32b0919d2d1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.95  # Change line: Adjust velocity decay factor to improve convergence\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)  # Change line: Dynamically adjust cognitive coefficient\n        self.social_coef = min(2.0, self.social_coef + 0.01)  # Change line: Dynamically adjust social coefficient\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Adjust the velocity decay factor to enhance convergence stability and improve periodic solutions.", "configspace": "", "generation": 72, "fitness": 0.9880828417849944, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.988 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9916263960148124, 0.9807259899509544, 0.9918961393892163], "final_y": [0.1648557719047642, 0.16485577190508316, 0.16485577190507994]}, "mutation_prompt": null}
{"id": "68e26ad8-aca5-460b-945c-c53626828cd3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.5 + np.random.rand() * 0.5  # Changed line: Introduce self-adaptive inertia weight\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce self-adaptive inertia weight in PSO to dynamically balance exploration and exploitation.", "configspace": "", "generation": 73, "fitness": 0.9794704289969243, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.979 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9876152686222284, 0.9662093596995374, 0.9845866586690072], "final_y": [0.1648557719048228, 0.16485577190475909, 0.16485577190482914]}, "mutation_prompt": null}
{"id": "dc3e5b38-e009-4601-9bab-c60f11b7a738", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99  # New line: Introduce velocity decay\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)  # Change line: Dynamically adjust cognitive coefficient\n        self.social_coef = min(2.0, self.social_coef + 0.01)  # Change line: Dynamically adjust social coefficient\n        self.inertia = max(0.4, self.inertia * 0.995)  # New line: Dynamically adjust inertia\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Fine-tune velocity decay in PSO by adjusting inertia dynamically to enhance convergence.", "configspace": "", "generation": 74, "fitness": 0.9876203216465044, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.988 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9887041816384082, 0.9827862462207743, 0.9913705370803307], "final_y": [0.16485577190476008, 0.1648557719047583, 0.16485577190518197]}, "mutation_prompt": null}
{"id": "075810e6-d3e0-41c0-ba4f-0e96a8329529", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.8\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.elitism_rate = 0.2\n        self.dynamic_mutation_rate = 0.05\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n\n    def _select_parents(self, population, fitness):\n        selected_indices = np.random.choice(self.population_size, size=self.population_size, p=fitness/fitness.sum())\n        return population[selected_indices]\n\n    def _crossover(self, parent1, parent2):\n        if np.random.rand() < self.crossover_rate:\n            point = np.random.randint(1, self.dim)\n            child1 = np.concatenate([parent1[:point], parent2[point:]])\n            child2 = np.concatenate([parent2[:point], parent1[point:]])\n            return child1, child2\n        return parent1, parent2\n\n    def _mutate(self, individual, bounds):\n        if np.random.rand() < self.mutation_rate:\n            lb, ub = bounds\n            mutation_vector = np.random.uniform(lb, ub, self.dim)\n            individual = np.clip(individual + self.dynamic_mutation_rate * (mutation_vector - individual), lb, ub)\n        return individual\n\n    def _adaptive_mutation(self, iteration):\n        self.mutation_rate = min(0.9, self.mutation_rate + 0.01 * iteration / self.init_budget)\n\n    def _ga_step(self, population, func, bounds):\n        fitness = 1.0 / (1.0 + self._evaluate_population(population, func))\n        best_indices = np.argsort(fitness)[-int(self.elitism_rate * self.population_size):]\n        elites = population[best_indices]\n\n        new_population = self._select_parents(population, fitness)\n        new_population = [self._mutate(child, bounds) for child in new_population]\n\n        children = []\n        for i in range(0, self.population_size, 2):\n            parent1, parent2 = new_population[i], new_population[min(i+1, self.population_size-1)]\n            child1, child2 = self._crossover(parent1, parent2)\n            children.append(self._mutate(child1, bounds))\n            children.append(self._mutate(child2, bounds))\n\n        new_population = np.array(children)[:self.population_size]\n        return np.vstack((elites, new_population[:-len(elites)]))\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        for iteration in range(self.init_budget // self.population_size):\n            population = self._ga_step(population, func, bounds)\n            self._adaptive_mutation(iteration)\n\n        best_solution = population[np.argmin(self._evaluate_population(population, func))]\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "AdaptiveGA", "description": "Implement an Adaptive Genetic Algorithm with Dynamic Elitism and Local Search to enhance convergence and solution quality for multilayered photonic structure optimization.", "configspace": "", "generation": 75, "fitness": 0.9158607700675025, "feedback": "The algorithm AdaptiveGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9298792906441989, 0.8970841284608533, 0.9206188910974554], "final_y": [0.16485577190473533, 0.1648557719047763, 0.16485577190480227]}, "mutation_prompt": null}
{"id": "39773723-451d-4bd4-a39d-ba775b754153", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Change line: Increase population size for better exploration\n        self.inertia = 0.65  \n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99  \n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)  \n        self.social_coef = min(2.0, self.social_coef + 0.01)  \n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Increase the population size to enhance diversity and improve exploration.", "configspace": "", "generation": 76, "fitness": 0.9434616865026108, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.943 with standard deviation 0.062. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9871991920610074, 0.8561013694502577, 0.9870844979965671], "final_y": [0.16485577190484557, 0.16485577190479317, 0.16485577190514988]}, "mutation_prompt": null}
{"id": "7b1bb007-5b04-4b34-9f1f-0b7078403e77", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7  # Changed line: Set inertia to a slightly higher value for better exploration\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99  # New line: Introduce velocity decay\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)  # Change line: Dynamically adjust cognitive coefficient\n        self.social_coef = min(2.0, self.social_coef + 0.01)  # Change line: Dynamically adjust social coefficient\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        for _ in range(self.init_budget // self.population_size):\n            self._update_velocities(population, personal_best, global_best)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive inertia in PSO for improved exploration-exploitation balance.", "configspace": "", "generation": 77, "fitness": 0.9837605259599201, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.984 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9882884092454827, 0.9719626167765743, 0.9910305518577034], "final_y": [0.16485577190480372, 0.16485577190475265, 0.16485577190545286]}, "mutation_prompt": null}
{"id": "9380a25d-42e1-4b16-8f4c-3d20edee0d4e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Slightly increase inertia for better exploration-exploitation balance\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99  # Original line: Introduce velocity decay\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)  # Change line: Dynamically adjust cognitive coefficient\n        self.social_coef = min(2.0, self.social_coef + 0.01)  # Change line: Dynamically adjust social coefficient\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))  # New line: Adjust velocity decay dynamically based on iteration\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Adjust the velocity decay factor to dynamically vary with iterations for enhanced convergence.", "configspace": "", "generation": 78, "fitness": 0.9882353026736101, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.988 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8b4881d4-56dd-4a5f-9d2e-76b342d3cee7", "metadata": {"aucs": [0.9912373284044969, 0.9824998320898527, 0.9909687475264806], "final_y": [0.1648557719053133, 0.1648557719060687, 0.1648557719049153]}, "mutation_prompt": null}
{"id": "e61847fc-f2a8-4bfb-a47f-27b5aa520b1b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.95\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.005)\n        self.social_coef = min(2.0, self.social_coef + 0.015)\n        self.velocity_decay = 0.99 + (0.015 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 5)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhance the HybridPSONM by improving initialization, velocity updates, and encouraging periodicity more effectively.", "configspace": "", "generation": 79, "fitness": 0.9665563012862562, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9380a25d-42e1-4b16-8f4c-3d20edee0d4e", "metadata": {"aucs": [0.9634783743070104, 0.9867409109870254, 0.9494496185647329], "final_y": [0.16485577190486034, 0.164855771904852, 0.16485577190484124]}, "mutation_prompt": null}
{"id": "7c6b9f2e-5052-41ac-9cc6-485af80bebac", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65  # Change line: Adaptive inertia to balance exploration and exploitation\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.5 + 0.15 * (1 - iteration / max_iterations)  # New line: Adaptive inertia based on iteration\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive inertia to enhance exploration and exploitation balance throughout iterations.", "configspace": "", "generation": 80, "fitness": 0.9879763200070494, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.988 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9380a25d-42e1-4b16-8f4c-3d20edee0d4e", "metadata": {"aucs": [0.9910375068426023, 0.9821425721932723, 0.9907488809852735], "final_y": [0.16485577190528122, 0.16485577190502732, 0.16485577190478584]}, "mutation_prompt": null}
{"id": "becb0212-641f-4712-b899-054e605284d5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))  # New line: Introduce dynamic inertia adjustment\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhance global convergence by introducing a dynamic inertia adjustment based on iteration count.", "configspace": "", "generation": 81, "fitness": 0.9885340532130901, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.989 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9380a25d-42e1-4b16-8f4c-3d20edee0d4e", "metadata": {"aucs": [0.9917509251434642, 0.9822880757021478, 0.9915631587936582], "final_y": [0.16485577190486278, 0.1648557719049616, 0.16485577190479261]}, "mutation_prompt": null}
{"id": "54e2ab94-47a8-4401-8351-608aa3b7d73b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01 + 0.005 * (iteration / max_iterations))  # Modified line: Adaptive coefficients\n        self.social_coef = min(2.0, self.social_coef + 0.01 - 0.005 * (iteration / max_iterations))\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive cognitive and social coefficients for better exploration and exploitation balance.", "configspace": "", "generation": 82, "fitness": 0.9882904524694132, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.988 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.9917392774161596, 0.9820578467646641, 0.9910742332274156], "final_y": [0.1648557719048579, 0.1648557719047944, 0.1648557719047622]}, "mutation_prompt": null}
{"id": "ce53e7d9-a44e-4e52-af2f-9f73263c4a14", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))\n        recent_improvement = np.min(personal_best) - np.min(population)  # New line: Adjust velocity decay based on improvement\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations)) + 0.005 * recent_improvement\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Improve exploration by adjusting velocity decay based on performance improvement.", "configspace": "", "generation": 83, "fitness": 0.9879749682088125, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.988 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.9907278127473238, 0.9821140819065655, 0.991083009972548], "final_y": [0.16485577190487188, 0.1648557719051449, 0.16485577190488587]}, "mutation_prompt": null}
{"id": "d05d25d8-e8a1-4180-97f2-4e6f5ad56010", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))\n        self.velocity_decay = 0.99 + (0.015 * (iteration / max_iterations))  # Adjusted line: Refine velocity decay adjustment\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Subtly refine global convergence by enhancing dynamic velocity decay adjustment based on iteration count.", "configspace": "", "generation": 84, "fitness": 0.9882889143272916, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.988 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.99103152669572, 0.9822819802704018, 0.9915532360157528], "final_y": [0.16485577190511036, 0.16485577190480194, 0.16485577190479395]}, "mutation_prompt": null}
{"id": "0a5fd330-4b39-407f-ae3d-9bdc75c9e3ac", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = 1.2 - (0.7 * (iteration / max_iterations))  # Changed line: Adaptive cognitive coefficient\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))  # New line: Introduce dynamic inertia adjustment\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive cognitive and social coefficients based on iteration count to balance exploration and exploitation.", "configspace": "", "generation": 85, "fitness": 0.9869761404042304, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.987 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.991326675439106, 0.9786142754483804, 0.9909874703252048], "final_y": [0.16485577190483036, 0.16485577190478773, 0.16485577190681366]}, "mutation_prompt": null}
{"id": "2a97eb93-c7bb-49ed-9dec-fba263c4aceb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))  # New line: Introduce adaptive velocity decay\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive velocity decay to balance exploration and exploitation dynamically based on iteration progress.", "configspace": "", "generation": 86, "fitness": 0.9885340532130901, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.989 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.9917509251434642, 0.9822880757021478, 0.9915631587936582], "final_y": [0.16485577190486278, 0.1648557719049616, 0.16485577190479261]}, "mutation_prompt": null}
{"id": "f0bb3ec8-1685-4346-88a9-4c96592d961e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.005)  # Adjusted decay rate\n        self.social_coef = min(2.0, self.social_coef + 0.005)  # Adjusted growth rate\n        self.inertia = 0.65 - (0.25 * (iteration / max_iterations))  # Modified dynamic inertia range\n        self.velocity_decay = 0.98 + (0.02 * (iteration / max_iterations))  # Adjusted velocity decay\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n\n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 3)  # Updated to encourage larger periodic patterns\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive dynamic parameters and hybrid periodicity enforcement to enhance convergence and solution quality.", "configspace": "", "generation": 87, "fitness": 0.9747153785732195, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.9602048207184334, 0.9872465903946989, 0.9766947246065264], "final_y": [0.16485577190527811, 0.1648557719048348, 0.16485577190483403]}, "mutation_prompt": null}
{"id": "841d8c6d-a290-4d4d-818d-18a196d26d1c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        # Adapt coefficients dynamically based on iteration\n        self.cognitive_coef = 1.2 - (0.7 * (iteration / max_iterations))  # Changed line\n        self.social_coef = 0.8 + (1.2 * (iteration / max_iterations))\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))  \n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive cognitive and social coefficients to enhance exploration and exploitation balance.", "configspace": "", "generation": 88, "fitness": 0.9885051294816461, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.989 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.9894906090252674, 0.9840433307198403, 0.9919814486998306], "final_y": [0.1648557719048086, 0.16485577190504175, 0.1648557719048046]}, "mutation_prompt": null}
{"id": "112372e5-a641-45c3-ab35-26c9ed3240cc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        mutation = np.random.normal(0, 0.05, self.velocities.shape)  # New line: Introduce mutation step\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population) + mutation)\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce a mutation step in the velocity update to enhance exploration of the search space.", "configspace": "", "generation": 89, "fitness": 0.9856460512471047, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.9875221486177533, 0.9789425309657899, 0.9904734741577708], "final_y": [0.16485577190474832, 0.16485577190499734, 0.1648557719047865]}, "mutation_prompt": null}
{"id": "e9d46c94-1c58-417f-829a-332d770260d0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass ImprovedHybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_population = lb + ub - population\n        return np.vstack((population, opposite_population))[:self.population_size]\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        learning_rate = 0.5 + 0.5 * (iteration / max_iterations)\n        self.velocities = (self.inertia - learning_rate * (iteration / max_iterations)) * self.velocities + \\\n                          self.cognitive_coef * r1 * (personal_best - population) + \\\n                          self.social_coef * r2 * (global_best - population)\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='L-BFGS-B', bounds=list(zip(*bounds)), options={'maxfun': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "ImprovedHybridPSONM", "description": "Introduce adaptive learning rates combined with quasi-oppositional initialization for improved exploration and convergence.", "configspace": "", "generation": 90, "fitness": 0.9737747496876551, "feedback": "The algorithm ImprovedHybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.955438177307675, 0.9851188586020255, 0.9807672131532646], "final_y": [0.1648559666166428, 0.16485621487065705, 0.1648564524927263]}, "mutation_prompt": null}
{"id": "81a4af71-b3a7-48bd-bbf6-65871bdb7bc6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))  # New line: Introduce dynamic inertia adjustment\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        lb, ub = bounds\n        result = minimize(func, solution, method='L-BFGS-B', bounds=list(zip(lb, ub)), options={'maxfun': self.local_budget})  # Changed to 'L-BFGS-B'\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Improve local search by using L-BFGS-B instead of Nelder-Mead for better handling of bounds.", "configspace": "", "generation": 91, "fitness": 0.9885335297021841, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.989 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.9917504668359611, 0.9822879266894196, 0.9915621955811713], "final_y": [0.1648560956542916, 0.16485587574861982, 0.16485648386433038]}, "mutation_prompt": null}
{"id": "d6849565-890f-4a5b-81f9-d03b5bb3beaa", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.9  # Change: 0.8 to 0.9\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))  # New line: Introduce dynamic inertia adjustment\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Adjust initial population range to 0.9 to improve global exploration.", "configspace": "", "generation": 92, "fitness": 0.9397743322233801, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.940 with standard deviation 0.057. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.9864502221359056, 0.8590403283558345, 0.9738324461784004], "final_y": [0.16485577190537237, 0.16485577190491396, 0.16485577190615353]}, "mutation_prompt": null}
{"id": "f22ef717-0737-46c6-ba47-7a28ccf96da1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, self.cognitive_coef - 0.01)\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))  # New line: Introduce dynamic inertia adjustment\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population) + np.random.normal(0, 0.1, self.velocities.shape))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce velocity perturbation for enhanced exploration to improve convergence rate.", "configspace": "", "generation": 93, "fitness": 0.9856301743585453, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.9876604881245395, 0.9795865630506828, 0.9896434719004135], "final_y": [0.16485577190481226, 0.16485577190483802, 0.16485577190552425]}, "mutation_prompt": null}
{"id": "17fbcfbe-e303-47aa-af54-b2511db0a417", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        diversity = np.std(population, axis=0).mean()  # New line: Calculate population diversity\n        self.cognitive_coef = max(0.5, 1.5 - diversity)  # New line: Adjust cognitive coefficient based on diversity\n        self.social_coef = min(2.0, self.social_coef + 0.01)\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))  \n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Leverage adaptive cognitive and social coefficients scaling based on the population's diversity to enhance convergence.", "configspace": "", "generation": 94, "fitness": 0.9463350639203778, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.062. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.9888655433407312, 0.8587830139753558, 0.9913566344450466], "final_y": [0.16485577190501766, 0.16485577190477796, 0.16485577190478917]}, "mutation_prompt": null}
{"id": "de8b1127-0c8f-438c-ba45-46f5a34f7b7d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _adaptive_velocity_update(self, population, personal_best, global_best, scores):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        fitness_scores = 1.0 / (1.0 + scores - np.min(scores))\n        for i in range(self.population_size):\n            self.inertia = 0.5 + 0.1 * fitness_scores[i]\n            self.cognitive_coef = 1.2 + 0.5 * fitness_scores[i]\n            self.social_coef = 1.2 + 0.5 * fitness_scores[i]\n            self.velocities[i] = self.inertia * self.velocities[i] + \\\n                                 self.cognitive_coef * r1[i] * (personal_best[i] - population[i]) + \\\n                                 self.social_coef * r2[i] * (global_best - population[i])\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._adaptive_velocity_update(population, personal_best, global_best, personal_best_scores)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive velocity updates using a novel fitness-proportional learning rate strategy for enhanced convergence.", "configspace": "", "generation": 95, "fitness": 0.9382541680914551, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.938 with standard deviation 0.059. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.9805684440584546, 0.8544497680465093, 0.9797442921694016], "final_y": [0.16485577190542366, 0.16485577190485956, 0.1648557719048387]}, "mutation_prompt": null}
{"id": "a9b590f6-39b1-47d4-a918-869d264c631e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, 1.5 - (iteration / max_iterations))  # Changed line: Adaptive cognitive coefficient\n        self.social_coef = min(2.5, 0.5 + (iteration / max_iterations))  # Changed line: Adaptive social coefficient\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce adaptive cognitive and social coefficients to enhance exploration and exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.9895297900401984, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.990 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "becb0212-641f-4712-b899-054e605284d5", "metadata": {"aucs": [0.990199087747866, 0.9867943487321414, 0.9915959336405876], "final_y": [0.1648557719048458, 0.16485577190498168, 0.16485577190486256]}, "mutation_prompt": null}
{"id": "7025def8-1103-4501-b580-e05ff245fae0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        scale_factor = np.linspace(0.6, 1.0, self.population_size).reshape(-1, 1)  # Changed line: Dynamic initialization scaling\n        return lb + scale_factor * (ub - lb)\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, 1.5 - (iteration / max_iterations))  # Changed line: Adaptive cognitive coefficient\n        self.social_coef = min(2.5, 0.5 + (iteration / max_iterations))  # Changed line: Adaptive social coefficient\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget})\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Introduce dynamic initialization scaling to better explore the early search space.", "configspace": "", "generation": 97, "fitness": 0.627861979096581, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.628 with standard deviation 0.010. And the mean value of best solutions found was 0.275 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a9b590f6-39b1-47d4-a918-869d264c631e", "metadata": {"aucs": [0.6263465442733904, 0.6169659631581563, 0.6402734298581965], "final_y": [0.27495646124977136, 0.2749564612497628, 0.274956461249767]}, "mutation_prompt": null}
{"id": "927c91ac-9f71-40b2-9bef-25752f81a213", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, 1.5 - (iteration / max_iterations))  # Changed line: Adaptive cognitive coefficient\n        self.social_coef = min(2.5, 0.5 + (iteration / max_iterations))  # Changed line: Adaptive social coefficient\n        self.inertia = 0.65 - (0.3 * (iteration / max_iterations))\n        self.velocity_decay = 0.99 + (0.01 * (iteration / max_iterations))\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        new_population = np.copy(population)\n        max_iterations = self.init_budget // self.population_size\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget, 'xatol': 1e-8})  # Increased precision\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Improve local search effectiveness by increasing the precision of the local optimizer.", "configspace": "", "generation": 98, "fitness": 0.9895297900404098, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.990 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a9b590f6-39b1-47d4-a918-869d264c631e", "metadata": {"aucs": [0.9901990877480177, 0.9867943487324565, 0.9915959336407552], "final_y": [0.1648557719046988, 0.16485577190469825, 0.16485577190469825]}, "mutation_prompt": null}
{"id": "39454a29-7840-42f2-a2fc-ad4acaef30b1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.65\n        self.cognitive_coef = 1.2\n        self.social_coef = 1.2\n        self.init_budget = budget // 2\n        self.local_budget = budget - self.init_budget\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.velocity_decay = 0.99\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.8\n\n    def _update_velocities(self, population, personal_best, global_best, iteration, max_iterations):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.cognitive_coef = max(0.5, 1.5 - (iteration / max_iterations))  # Changed line: Adaptive cognitive coefficient\n        self.social_coef = min(2.5, 0.5 + (iteration / max_iterations))  # Changed line: Adaptive social coefficient\n        self.inertia = 0.7 - (0.4 * (iteration / max_iterations))  # Changed line: More adaptive inertia\n        self.velocity_decay = 0.98 + (0.02 * (iteration / max_iterations))  # Changed line: Adjusted decay factor\n        self.velocities = self.velocity_decay * (self.inertia * self.velocities +\n                           self.cognitive_coef * r1 * (personal_best - population) +\n                           self.social_coef * r2 * (global_best - population))\n\n    def _pso_step(self, population, func, bounds):\n        lb, ub = bounds\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        \n        dynamic_pop_size = self.population_size + 5  # Changed line: Dynamic population size\n        new_population = np.copy(population)\n        max_iterations = self.init_budget // dynamic_pop_size  # Changed line: Updated iteration count\n        for iteration in range(max_iterations):\n            self._update_velocities(population, personal_best, global_best, iteration, max_iterations)\n            new_population = population + self.velocities\n            new_population = np.clip(new_population, lb, ub)\n            scores = np.array([func(ind) for ind in new_population])\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best[better_mask] = new_population[better_mask]\n            if np.min(scores) < func(global_best):\n                global_best = new_population[np.argmin(scores)]\n            population = new_population\n        return global_best\n\n    def _encourage_periodicity(self, solution, bounds):\n        lb, ub = bounds\n        period = max(2, self.dim // 4)\n        periodic_solution = np.tile(solution[:period], self.dim // period + 1)[:self.dim]\n        return np.clip(periodic_solution, lb, ub)\n\n    def _local_refinement(self, solution, func, bounds):\n        result = minimize(func, solution, method='Nelder-Mead', options={'maxfev': self.local_budget, 'xatol': 1e-8})  # Increased precision\n        return result.x\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        population = self._initialize_population(bounds)\n\n        best_solution = self._pso_step(population, func, bounds)\n        best_solution = self._encourage_periodicity(best_solution, bounds)\n\n        if self.local_budget > 0:\n            best_solution = self._local_refinement(best_solution, func, bounds)\n\n        return best_solution", "name": "HybridPSONM", "description": "Enhance global exploration with adaptive inertia and dynamic population size for robust convergence.", "configspace": "", "generation": 99, "fitness": 0.9886371120939405, "feedback": "The algorithm HybridPSONM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.989 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "927c91ac-9f71-40b2-9bef-25752f81a213", "metadata": {"aucs": [0.9875510189312716, 0.9873361304911176, 0.9910241868594319], "final_y": [0.16485577190469847, 0.16485577190469825, 0.16485577190469825]}, "mutation_prompt": null}
