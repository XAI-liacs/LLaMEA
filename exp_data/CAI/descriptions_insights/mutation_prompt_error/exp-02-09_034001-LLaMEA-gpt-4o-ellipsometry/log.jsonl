{"id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.8  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "A hybrid metaheuristic algorithm combining differential evolution with adaptive neighborhood search for efficient exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.3669334528663475, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.367 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.3669334528663475, 0.3669334528663475, 0.3669334528663475], "final_y": [0.00012094385909586264, 0.00012094385909586264, 0.00012094385909586264]}, "mutation_prompt": null}
{"id": "cbbf9777-3202-40fa-9237-c1766da2b05a", "solution": "import numpy as np\n\nclass EnhancedHybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.8  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        elite_fraction = 0.1  # Fraction of population considered elite\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Sort population by fitness to identify elite\n            elite_size = max(1, int(elite_fraction * population_size))\n            elite_indices = np.argsort(fitness)[:elite_size]\n            elite_population = population[elite_indices]\n\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    # Choose an elite point to guide the search\n                    elite_point = elite_population[np.random.randint(elite_size)]\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (elite_point - local_search_point)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "EnhancedHybridMetaheuristicOptimizer", "description": "An enhanced hybrid metaheuristic combining differential evolution with dynamic adaptive neighborhood search and elite preservation for improved convergence.", "configspace": "", "generation": 1, "fitness": 0.30604272497311913, "feedback": "The algorithm EnhancedHybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.306 with standard deviation 0.000. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.30604272497311913, 0.30604272497311913, 0.30604272497311913], "final_y": [0.0005070021168555401, 0.0005070021168555401, 0.0005070021168555401]}, "mutation_prompt": null}
{"id": "1dc7c217-12da-4c5e-8ed1-09b6f8cd9fdc", "solution": "import numpy as np\n\nclass EnhancedHybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        np.random.seed(42)\n\n        # Initialize population and control parameters\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        F = 0.5 + 0.3 * np.random.rand(population_size)  # Self-adaptive mutation factor\n        CR = 0.8 + 0.1 * np.random.rand(population_size)  # Self-adaptive crossover rate\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F[i] * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR[i]\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic Local Search\n                if np.random.rand() < 0.2:  # 20% chance to perform local search\n                    intensity = 1.0 - (evaluations / self.budget)\n                    perturbation = np.random.normal(0, 0.1 * intensity, self.dim) * (ub - lb)\n                    neighbor = population[i] + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "EnhancedHybridMetaheuristicOptimizer", "description": "An enhanced hybrid metaheuristic optimizer integrating self-adaptive differential evolution with dynamic local search to effectively balance exploration and exploitation in high-dimensional spaces.", "configspace": "", "generation": 2, "fitness": 0.2847765886482976, "feedback": "The algorithm EnhancedHybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.285 with standard deviation 0.000. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.2847765886482976, 0.2847765886482976, 0.2847765886482976], "final_y": [0.0012283253277234135, 0.0012283253277234135, 0.0012283253277234135]}, "mutation_prompt": null}
{"id": "2e89556f-8c7e-4e89-a5e4-79514217d58e", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.8  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adjusted Mutation Strategy\n                mutant = population[a] + F * (population[b] - population[c]) + 0.1 * (population[a] - population[i])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration by adjusting mutation strategy to include an additional scaling factor.", "configspace": "", "generation": 3, "fitness": 0.2956427348910735, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.296 with standard deviation 0.000. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.2956427348910735, 0.2956427348910735, 0.2956427348910735], "final_y": [0.002477125352077332, 0.002477125352077332, 0.002477125352077332]}, "mutation_prompt": null}
{"id": "b130c0f3-36ae-4441-86f0-808cd879b18a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.85  # Mutation factor for differential evolution (adjusted for better exploration)\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduce a new strategy by slightly increasing the mutation factor to enhance exploration capabilities.", "configspace": "", "generation": 4, "fitness": 0.27599827522147236, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.276 with standard deviation 0.000. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.27599827522147236, 0.27599827522147236, 0.27599827522147236], "final_y": [0.0012395229429282785, 0.0012395229429282785, 0.0012395229429282785]}, "mutation_prompt": null}
{"id": "e07ebbda-15ab-48d5-813a-62d1c4517a2a", "solution": "import numpy as np\n\nclass CooperativeParticleClusterOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        cluster_size = 5 * self.dim  # Heuristic choice for initial cluster size\n        num_clusters = 2  # Number of clusters\n        inertia_weight = 0.7\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n        np.random.seed(42)\n\n        # Initialize particle clusters randomly within bounds\n        clusters = [np.random.uniform(lb, ub, (cluster_size, self.dim)) for _ in range(num_clusters)]\n        velocities = [np.random.uniform(-1, 1, (cluster_size, self.dim)) for _ in range(num_clusters)]\n        fitness_clusters = [np.array([func(ind) for ind in cluster]) for cluster in clusters]\n        evaluations = cluster_size * num_clusters\n\n        personal_bests = [np.copy(cluster) for cluster in clusters]\n        personal_best_fitness = [np.copy(fitness) for fitness in fitness_clusters]\n\n        global_best = None\n        global_best_fitness = np.inf\n\n        for i in range(num_clusters):\n            min_idx = np.argmin(personal_best_fitness[i])\n            if personal_best_fitness[i][min_idx] < global_best_fitness:\n                global_best_fitness = personal_best_fitness[i][min_idx]\n                global_best = personal_bests[i][min_idx]\n\n        while evaluations < self.budget:\n            for i in range(num_clusters):\n                # Update velocities and positions\n                for j in range(cluster_size):\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    velocities[i][j] = (inertia_weight * velocities[i][j] +\n                                        cognitive_coeff * r1 * (personal_bests[i][j] - clusters[i][j]) +\n                                        social_coeff * r2 * (global_best - clusters[i][j]))\n                    clusters[i][j] = clusters[i][j] + velocities[i][j]\n                    clusters[i][j] = np.clip(clusters[i][j], lb, ub)\n\n                # Evaluate new positions\n                for j in range(cluster_size):\n                    fitness = func(clusters[i][j])\n                    evaluations += 1\n\n                    if fitness < personal_best_fitness[i][j]:\n                        personal_bests[i][j] = clusters[i][j]\n                        personal_best_fitness[i][j] = fitness\n\n                        if fitness < global_best_fitness:\n                            global_best_fitness = fitness\n                            global_best = clusters[i][j]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic regrouping phase\n            if evaluations % (self.budget // 3) == 0:\n                all_particles = np.vstack(clusters)\n                all_fitness = np.hstack(personal_best_fitness)\n                sorted_indices = np.argsort(all_fitness)\n                clusters = [all_particles[sorted_indices[k*cluster_size:(k+1)*cluster_size]] for k in range(num_clusters)]\n                fitness_clusters = [all_fitness[sorted_indices[k*cluster_size:(k+1)*cluster_size]] for k in range(num_clusters)]\n                personal_bests = [np.copy(cluster) for cluster in clusters]\n                personal_best_fitness = [np.copy(fitness) for fitness in fitness_clusters]\n\n        return global_best, global_best_fitness", "name": "CooperativeParticleClusterOptimizer", "description": "A cooperative particle cluster optimizer using dynamic regrouping and convergence-driven phase switches to balance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.19568846490531155, "feedback": "The algorithm CooperativeParticleClusterOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.196 with standard deviation 0.000. And the mean value of best solutions found was 0.485 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.19568846490531155, 0.19568846490531155, 0.19568846490531155], "final_y": [0.48544304467873445, 0.48544304467873445, 0.48544304467873445]}, "mutation_prompt": null}
{"id": "a34166c6-3cdb-4388-8161-af7bd01279b1", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.85  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "An enhanced hybrid metaheuristic algorithm with adjusted mutation factor for improved convergence in black box optimization.", "configspace": "", "generation": 6, "fitness": 0.2755680563511791, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.276 with standard deviation 0.000. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.2755680563511791, 0.2755680563511791, 0.2755680563511791], "final_y": [0.0022875565264638548, 0.0022875565264638548, 0.0022875565264638548]}, "mutation_prompt": null}
{"id": "b21dd5b5-005a-49cd-b819-78f7dba0fbe0", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.9  # Mutation factor for differential evolution (changed from 0.8 to 0.9)\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "An enhanced version of the hybrid metaheuristic algorithm with increased mutation factor for improved exploration capabilities.", "configspace": "", "generation": 7, "fitness": 0.28219922859023827, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.282 with standard deviation 0.000. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.28219922859023827, 0.28219922859023827, 0.28219922859023827], "final_y": [0.0010065252368830011, 0.0010065252368830011, 0.0010065252368830011]}, "mutation_prompt": null}
{"id": "dd74d908-a403-40a9-a8fe-7edfb60df2aa", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.8  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            diversity = np.std(population, axis=0) / (ub - lb)  # Calculate diversity\n\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR = 0.5 + 0.4 * np.mean(diversity)  # Adjust crossover probability\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration by dynamically adjusting the crossover probability based on diversity.", "configspace": "", "generation": 8, "fitness": 0.20707833555973532, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.207 with standard deviation 0.000. And the mean value of best solutions found was 0.099 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.20707833555973532, 0.20707833555973532, 0.20707833555973532], "final_y": [0.09871836267433752, 0.09871836267433752, 0.09871836267433752]}, "mutation_prompt": null}
{"id": "48f130e0-5ff7-47d7-9917-b8faccd1863a", "solution": "import numpy as np\n\nclass EnhancedHybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.8  # Initial mutation factor for differential evolution\n        CR = 0.9  # Initial crossover probability\n        decay_rate = 0.99  # Parameter decay rate\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamically adjust parameters\n            F *= decay_rate\n            CR = min(0.9, CR * decay_rate + 0.1)  # Ensure CR doesn't diminish too much\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "EnhancedHybridMetaheuristicOptimizer", "description": "A hybrid metaheuristic algorithm integrating differential evolution with adaptive neighborhood search and dynamic parameter adjustment for improved optimization efficiency and robustness.", "configspace": "", "generation": 9, "fitness": 0.3398139913099596, "feedback": "The algorithm EnhancedHybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.340 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.3398139913099596, 0.3398139913099596, 0.3398139913099596], "final_y": [0.00010035905588643156, 0.00010035905588643156, 0.00010035905588643156]}, "mutation_prompt": null}
{"id": "5d069931-df75-4831-b333-7a3c7492230c", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 10 * self.dim  # Heuristic choice\n        max_vel = 0.2 * (ub - lb)\n        min_vel = -max_vel\n        inertia_weight = 0.9  # Initial inertia weight\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        np.random.seed(42)\n\n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(min_vel, max_vel, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_fitness = np.array([func(ind) for ind in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_fitness)]\n        global_best_fitness = np.min(personal_best_fitness)\n        evaluations = num_particles\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = cognitive_coeff * r1 * (personal_best_positions[i] - positions[i])\n                social_velocity = social_coeff * r2 * (global_best_position - positions[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n                \n                # Clamp velocity\n                velocities[i] = np.clip(velocities[i], min_vel, max_vel)\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new fitness\n                fitness = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness\n                    personal_best_positions[i] = positions[i]\n\n                if fitness < global_best_fitness:\n                    global_best_fitness = fitness\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamically update inertia weight\n            inertia_weight = 0.4 + 0.5 * ((self.budget - evaluations) / self.budget)\n\n        # Return the best found solution\n        return global_best_position, global_best_fitness", "name": "AdaptiveParticleSwarmOptimizer", "description": "An adaptive particle swarm optimization algorithm incorporating velocity-based boundary adjustments and a dynamic inertia weight for versatile exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.24010348093927736, "feedback": "The algorithm AdaptiveParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.000. And the mean value of best solutions found was 0.017 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.24010348093927736, 0.24010348093927736, 0.24010348093927736], "final_y": [0.016719875776704522, 0.016719875776704522, 0.016719875776704522]}, "mutation_prompt": null}
{"id": "c20b3f47-5465-40af-81e3-4b6978f7ea0b", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.8  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 - evaluations / self.budget)  # Dynamic F\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid metaheuristic algorithm with adaptive mutation and survival strategies for improved exploration and exploitation.", "configspace": "", "generation": 11, "fitness": 0.3567682864206092, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.357 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.3567682864206092, 0.3567682864206092, 0.3567682864206092], "final_y": [0.000172480466376781, 0.000172480466376781, 0.000172480466376781]}, "mutation_prompt": null}
{"id": "2aba8d07-bc03-4865-a465-a02cca861131", "solution": "import numpy as np\n\nclass EnhancedHybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.8  # Initial mutation factor for differential evolution\n        CR = 0.9  # Initial crossover probability\n        decay_rate = 0.995  # Decay rate for dynamic parameter adjustment\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic adjustment of parameters\n            F *= decay_rate\n            CR = 0.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "EnhancedHybridMetaheuristicOptimizer", "description": "An enhanced hybrid metaheuristic optimizer incorporating differential evolution with adaptive neighborhood search and dynamic parameter adjustment to improve exploration and convergence speed.", "configspace": "", "generation": 12, "fitness": 0.2538846995928784, "feedback": "The algorithm EnhancedHybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.254 with standard deviation 0.000. And the mean value of best solutions found was 0.028 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.2538846995928784, 0.2538846995928784, 0.2538846995928784], "final_y": [0.028042860046776356, 0.028042860046776356, 0.028042860046776356]}, "mutation_prompt": null}
{"id": "7e426cb4-66d8-4ffc-946c-1287a855fb70", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid metaheuristic algorithm with dynamic mutation factor for improved convergence.", "configspace": "", "generation": 13, "fitness": 0.4017005118984553, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.402 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd636cde-9b9d-4841-8623-9e4c1f1e27d2", "metadata": {"aucs": [0.40170051189845524, 0.40170051189845524, 0.40170051189845524], "final_y": [5.126344811877269e-06, 5.126344811877269e-06, 5.126344811877269e-06]}, "mutation_prompt": null}
{"id": "af930ff3-c1d3-46a4-beae-71fca0321c6a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR = 0.5 + 0.4 * np.random.rand()  # Adaptive crossover probability\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid metaheuristic algorithm with adaptive crossover probability for improved convergence.", "configspace": "", "generation": 14, "fitness": 0.29100289493089393, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.291 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e426cb4-66d8-4ffc-946c-1287a855fb70", "metadata": {"aucs": [0.29100289493089393, 0.29100289493089393, 0.29100289493089393], "final_y": [0.00018402474688929566, 0.00018402474688929566, 0.00018402474688929566]}, "mutation_prompt": null}
{"id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved convergence via enhanced local search probability.", "configspace": "", "generation": 15, "fitness": 0.4689877154674004, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.469 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e426cb4-66d8-4ffc-946c-1287a855fb70", "metadata": {"aucs": [0.46898771546740037, 0.46898771546740037, 0.46898771546740037], "final_y": [3.659158936262329e-07, 3.659158936262329e-07, 3.659158936262329e-07]}, "mutation_prompt": null}
{"id": "617ebdc7-e4df-4353-b234-5f148b6cdc71", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.7  # Mutation factor for differential evolution (was 0.5)\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Refined mutation strategy for improved exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.3148315637355271, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.315 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.3148315637355271, 0.3148315637355271, 0.3148315637355271], "final_y": [0.00025164295228863147, 0.00025164295228863147, 0.00025164295228863147]}, "mutation_prompt": null}
{"id": "8c04c826-8645-45e5-b8d3-091c299775eb", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive mutation factor\n                F = 0.8 if evaluations < self.budget * 0.5 else 0.5\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced convergence through adaptive mutation factor in differential evolution.", "configspace": "", "generation": 17, "fitness": 0.3252983717094453, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.325 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.3252983717094453, 0.3252983717094453, 0.3252983717094453], "final_y": [4.392640984657734e-05, 4.392640984657734e-05, 4.392640984657734e-05]}, "mutation_prompt": null}
{"id": "651ae611-7c1f-4397-b618-02cb44bf8bef", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.20:  # 20% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced local search probability from 15% to 20% to improve exploration.", "configspace": "", "generation": 18, "fitness": 0.34236441692435715, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.342 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.34236441692435715, 0.34236441692435715, 0.34236441692435715], "final_y": [1.1587480070138046e-05, 1.1587480070138046e-05, 1.1587480070138046e-05]}, "mutation_prompt": null}
{"id": "daeca49b-c7b2-403f-b3ba-5028a6a05957", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F_initial = 0.5  # Initial mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            F = F_initial * (1 - evaluations / self.budget)  # Dynamic adjustment of F\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.25:  # 25% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration by dynamic mutation factor adjustment and improved local search probability.", "configspace": "", "generation": 19, "fitness": 0.2518593887554742, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.252 with standard deviation 0.000. And the mean value of best solutions found was 0.042 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.2518593887554742, 0.2518593887554742, 0.2518593887554742], "final_y": [0.04202228682503951, 0.04202228682503951, 0.04202228682503951]}, "mutation_prompt": null}
{"id": "8e393c1c-4cb8-4c8e-84ab-78120fdef3e5", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population using chaotic sequence within bounds\n        population = lb + (ub - lb) * np.sin(np.pi * (np.random.rand(population_size, self.dim)))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduced diversity through chaotic initialization in the population.", "configspace": "", "generation": 20, "fitness": 0.33272609184766966, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.333 with standard deviation 0.000. And the mean value of best solutions found was 0.003 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.33272609184766966, 0.33272609184766966, 0.33272609184766966], "final_y": [0.002529189583908562, 0.002529189583908562, 0.002529189583908562]}, "mutation_prompt": null}
{"id": "c1348e73-c6c4-4f1f-a921-8f68103d995c", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.20:  # 20% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced convergence via increased local search probability.", "configspace": "", "generation": 21, "fitness": 0.34236441692435715, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.342 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.34236441692435715, 0.34236441692435715, 0.34236441692435715], "final_y": [1.1587480070138046e-05, 1.1587480070138046e-05, 1.1587480070138046e-05]}, "mutation_prompt": null}
{"id": "81fc02d1-7f41-4679-a6d2-8965afdd42d7", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_adaptive = 0.5 + (0.5 * (evaluations / self.budget))  # Adaptive mutation factor\n                mutant = population[a] + F_adaptive * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration with adaptive mutation factor for improved diversity.", "configspace": "", "generation": 22, "fitness": 0.32114507018790717, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.321 with standard deviation 0.000. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.32114507018790717, 0.32114507018790717, 0.32114507018790717], "final_y": [0.0009023556645604847, 0.0009023556645604847, 0.0009023556645604847]}, "mutation_prompt": null}
{"id": "e285bda0-a2d6-437d-9b37-f1f8f71b6373", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F = max(0.1, np.std(fitness) / (np.mean(fitness) if np.mean(fitness) != 0 else 1))  # Adaptive mutation factor\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introducing adaptive mutation factor based on fitness variance to enhance exploration and exploitation balance.", "configspace": "", "generation": 23, "fitness": 0.3346150204754754, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.335 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.3346150204754754, 0.3346150204754754, 0.3346150204754754], "final_y": [7.106983458756402e-05, 7.106983458756402e-05, 7.106983458756402e-05]}, "mutation_prompt": null}
{"id": "8a6a180e-3d4c-4188-8b90-85d0b8a5fffa", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15 + 0.05 * (1 - evaluations / self.budget):  # Dynamic local search probability\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploitation phase through dynamic local search strategy.", "configspace": "", "generation": 24, "fitness": 0.35142618779585, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.351 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.35142618779585, 0.35142618779585, 0.35142618779585], "final_y": [3.430326400641881e-05, 3.430326400641881e-05, 3.430326400641881e-05]}, "mutation_prompt": null}
{"id": "83c31fe7-e201-4484-a3cd-f82f1dea1817", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness <= fitness[i]:  # Changed from < to <=\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced solution selection by incorporating greedy selection strategy.", "configspace": "", "generation": 25, "fitness": 0.37194028648741745, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.372 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.3719402864874174, 0.3719402864874174, 0.3719402864874174], "final_y": [4.161474326750327e-05, 4.161474326750327e-05, 4.161474326750327e-05]}, "mutation_prompt": null}
{"id": "a618e984-54e7-47e6-9f4b-c172b448c5c4", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.25:  # Increased probability of local search to 25%\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced adaptive neighborhood search probability for improved convergence.", "configspace": "", "generation": 26, "fitness": 0.31946140116225086, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.319 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.31946140116225086, 0.31946140116225086, 0.31946140116225086], "final_y": [9.692155555770476e-05, 9.692155555770476e-05, 9.692155555770476e-05]}, "mutation_prompt": null}
{"id": "8d8902ff-3716-4095-a581-789390b7d243", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.20:  # 20% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration by adjusting local search probability.", "configspace": "", "generation": 27, "fitness": 0.42670321387370896, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.427 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.4267032138737089, 0.4267032138737089, 0.4267032138737089], "final_y": [3.935152845796551e-06, 3.935152845796551e-06, 3.935152845796551e-06]}, "mutation_prompt": null}
{"id": "d4a6e0f7-8253-48b7-8aff-5c311c6ac57a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search with dynamic probability\n                dynamic_probability = 0.15 + (0.05 * (1.0 - (evaluations / self.budget))) # Change here\n                if np.random.rand() < dynamic_probability:  # Adjusted probability for local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced adaptive neighborhood search strategy with dynamic probability adjustment.", "configspace": "", "generation": 28, "fitness": 0.35723237605557157, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.357 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.35723237605557157, 0.35723237605557157, 0.35723237605557157], "final_y": [4.512610014558799e-05, 4.512610014558799e-05, 4.512610014558799e-05]}, "mutation_prompt": null}
{"id": "e541cc4d-64ac-4d8e-8454-4f14218bc221", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.20:  # Increased to 20% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced adaptive local search probability to improve solution quality.", "configspace": "", "generation": 29, "fitness": 0.3727516008155587, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.373 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.3727516008155587, 0.3727516008155587, 0.3727516008155587], "final_y": [2.3726779133770433e-05, 2.3726779133770433e-05, 2.3726779133770433e-05]}, "mutation_prompt": null}
{"id": "e8fce206-0cec-47b1-b3d2-43b25e21d40b", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptively adjust F based on evaluations\n                adaptive_F = F + (0.3 * (1 - evaluations / self.budget))  # Change made here\n                mutant = population[a] + adaptive_F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploitation with adaptive mutation factor in differential evolution.", "configspace": "", "generation": 30, "fitness": 0.305104240293376, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.305 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.305104240293376, 0.305104240293376, 0.305104240293376], "final_y": [5.242901255678208e-05, 5.242901255678208e-05, 5.242901255678208e-05]}, "mutation_prompt": null}
{"id": "1d11e0ac-2e2d-42cc-a22d-54a58ad30420", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR = 0.8 + 0.2 * (1 - evaluations / self.budget)  # Dynamic adjustment\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved convergence via dynamic crossover probability adjustment.", "configspace": "", "generation": 31, "fitness": 0.40926487064128514, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.409 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.40926487064128514, 0.40926487064128514, 0.40926487064128514], "final_y": [3.55671158389671e-05, 3.55671158389671e-05, 3.55671158389671e-05]}, "mutation_prompt": null}
{"id": "88d4ceac-ed0a-426b-800d-64194964b920", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Enhanced Mutation Strategy\n                mutant = population[a] + np.random.uniform(0.4, 0.6) * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced adaptive mutation strategy to balance exploration and exploitation.", "configspace": "", "generation": 32, "fitness": 0.3271732253781493, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.327 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.3271732253781493, 0.3271732253781493, 0.3271732253781493], "final_y": [0.00014090259231383157, 0.00014090259231383157, 0.00014090259231383157]}, "mutation_prompt": null}
{"id": "9bc08843-59c1-4674-9d13-0f15b268964f", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = 0.5 + 0.5 * (evaluations / self.budget)  # Dynamic scaling factor\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced mutation strategy via dynamic scaling factor adaptation.", "configspace": "", "generation": 33, "fitness": 0.34782696851088724, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.348 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.34782696851088724, 0.34782696851088724, 0.34782696851088724], "final_y": [0.00032333801331506324, 0.00032333801331506324, 0.00032333801331506324]}, "mutation_prompt": null}
{"id": "10ce97f1-a5e8-4ca3-99ff-070f2e89b1f5", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.25:  # 25% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved convergence through increased adaptive neighborhood search probability.", "configspace": "", "generation": 34, "fitness": 0.31946140116225086, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.319 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.31946140116225086, 0.31946140116225086, 0.31946140116225086], "final_y": [9.692155555770476e-05, 9.692155555770476e-05, 9.692155555770476e-05]}, "mutation_prompt": null}
{"id": "3e275d60-8ae4-4c6a-a42e-d45f94583057", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.25:  # 25% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced convergence using diversified local search strategies.", "configspace": "", "generation": 35, "fitness": 0.37948143101873627, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.379 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.3794814310187363, 0.3794814310187363, 0.3794814310187363], "final_y": [6.79181403331127e-05, 6.79181403331127e-05, 6.79181403331127e-05]}, "mutation_prompt": null}
{"id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration using dynamic mutation factor adjustment in differential evolution.", "configspace": "", "generation": 36, "fitness": 0.46937358471915847, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.469 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "99beefa8-2ed1-42e7-b02b-075d3a8ca03a", "metadata": {"aucs": [0.46937358471915847, 0.46937358471915847, 0.46937358471915847], "final_y": [2.9814101506648723e-06, 2.9814101506648723e-06, 2.9814101506648723e-06]}, "mutation_prompt": null}
{"id": "6b2c3808-9005-451b-993e-1ac4922079f3", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        decay_rate = 0.99  # Added decay rate for F\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: introduce decay rate to dynamic mutation factor\n                F_dynamic = F * decay_rate * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration by introducing a decay rate to mutation factor for refined adaptation in differential evolution.", "configspace": "", "generation": 37, "fitness": 0.31670244218863564, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.317 with standard deviation 0.000. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.31670244218863564, 0.31670244218863564, 0.31670244218863564], "final_y": [0.0006608919985898083, 0.0006608919985898083, 0.0006608919985898083]}, "mutation_prompt": null}
{"id": "d457d788-59a5-41ce-b27f-72e658643f9d", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                local_search_prob = 0.15 * (1 + (0.5 * (evaluations / self.budget)))  # Incremental enhancement\n                if np.random.rand() < local_search_prob:  # Modified probability\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Incrementally enhance local search probability to intensify exploration as budget depletes.", "configspace": "", "generation": 38, "fitness": 0.28205882862710474, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.282 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.28205882862710474, 0.28205882862710474, 0.28205882862710474], "final_y": [0.00032903266509486665, 0.00032903266509486665, 0.00032903266509486665]}, "mutation_prompt": null}
{"id": "f71e2df6-a351-4466-bfb7-bc8ba3fbfef3", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR_dynamic = CR * (1 - (evaluations / self.budget))  # Dynamic crossover probability\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved exploration and exploitation by dynamically adjusting crossover probability in differential evolution.", "configspace": "", "generation": 39, "fitness": 0.31386282275933863, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.314 with standard deviation 0.000. And the mean value of best solutions found was 0.005 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.31386282275933863, 0.31386282275933863, 0.31386282275933863], "final_y": [0.005377055691588583, 0.005377055691588583, 0.005377055691588583]}, "mutation_prompt": null}
{"id": "b9cc23d4-9a8b-4746-8bdc-53a3d9b47c4a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Initial mutation factor for differential evolution\n        CR = 0.9  # Initial crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Self-adaptive mutation factor\n                F_dynamic = F + (0.1 * np.random.rand())\n                \n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Self-adaptive crossover probability\n                CR_dynamic = CR + (0.1 * np.random.rand())\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Incorporate a self-adaptive control mechanism for mutation and crossover rates to improve diversity and convergence.", "configspace": "", "generation": 40, "fitness": 0.3578342364155562, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.358 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3578342364155561, 0.3578342364155561, 0.3578342364155561], "final_y": [1.4335665820392355e-05, 1.4335665820392355e-05, 1.4335665820392355e-05]}, "mutation_prompt": null}
{"id": "8202a8ca-54be-4864-bac6-4582ade87f14", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive crossover probability\n                CR_adaptive = CR * (1 - (evaluations / self.budget))  # Line changed\n                crossover = np.random.rand(self.dim) < CR_adaptive\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Incorporates adaptive crossover probability based on remaining budget to refine the exploration-exploitation balance.", "configspace": "", "generation": 41, "fitness": 0.25969095913605933, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.000. And the mean value of best solutions found was 0.024 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.25969095913605933, 0.25969095913605933, 0.25969095913605933], "final_y": [0.024131941439068126, 0.024131941439068126, 0.024131941439068126]}, "mutation_prompt": null}
{"id": "39052d0f-30ee-4148-bf3b-213e62d1dbec", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution (Change made here)\n                if trial_fitness < fitness[i] or np.random.rand() < 0.1:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduce stochastic selection pressure to enhance convergence speed in differential evolution.", "configspace": "", "generation": 42, "fitness": 0.30102782537460737, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.000. And the mean value of best solutions found was 0.002 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.30102782537460737, 0.30102782537460737, 0.30102782537460737], "final_y": [0.0015810119902416743, 0.0015810119902416743, 0.0015810119902416743]}, "mutation_prompt": null}
{"id": "400cc915-99ac-44ed-bc26-877c8d470479", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR * (1 - (evaluations / self.budget))\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved convergence speed by enhancing crossover probability adaptation in differential evolution.", "configspace": "", "generation": 43, "fitness": 0.314680121239293, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.315 with standard deviation 0.000. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.314680121239293, 0.314680121239293, 0.314680121239293], "final_y": [0.00776910241597075, 0.00776910241597075, 0.00776910241597075]}, "mutation_prompt": null}
{"id": "0fd31616-0cd1-4e54-ae9d-66d9cf84250b", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.85  # Crossover probability (Changed from 0.9 to 0.85)\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Fine-tuned crossover probability for improved convergence in differential evolution.", "configspace": "", "generation": 44, "fitness": 0.3265050028726144, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.327 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3265050028726144, 0.3265050028726144, 0.3265050028726144], "final_y": [0.00017696879633696878, 0.00017696879633696878, 0.00017696879633696878]}, "mutation_prompt": null}
{"id": "60991daf-5cfb-4c9b-b602-7affeb5ba661", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR_dynamic = CR * (1 - (0.5 * (evaluations / self.budget)))  # Changed dynamic crossover probability\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration by adaptive crossover probability based on current evaluations in differential evolution.", "configspace": "", "generation": 45, "fitness": 0.2877098204306472, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.288 with standard deviation 0.000. And the mean value of best solutions found was 0.012 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.2877098204306472, 0.2877098204306472, 0.2877098204306472], "final_y": [0.01200742530031846, 0.01200742530031846, 0.01200742530031846]}, "mutation_prompt": null}
{"id": "3aa3d142-6c99-49dd-9bf4-a23eb55e4d6a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                # Change made here: dynamic crossover probability based on current evaluations\n                CR_dynamic = CR * (1 - (0.5 * (evaluations / self.budget)))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced balance between exploration and exploitation using a dynamic crossover probability.", "configspace": "", "generation": 46, "fitness": 0.3160511882533943, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.316 with standard deviation 0.000. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3160511882533943, 0.3160511882533943, 0.3160511882533943], "final_y": [0.004034815297770835, 0.004034815297770835, 0.004034815297770835]}, "mutation_prompt": null}
{"id": "a417f8d8-0e53-4d56-b41c-ad1333a54958", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Change made here: Enhanced local search with self-adaptive perturbation\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation_scale = 0.1 * (np.max(fitness) - np.min(fitness)) / (np.max(fitness) + 1e-9)\n                    perturbation = np.random.normal(0, perturbation_scale, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced local search by introducing self-adaptive perturbation scale based on fitness diversity.", "configspace": "", "generation": 47, "fitness": 0.3534604222128366, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.353 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3534604222128366, 0.3534604222128366, 0.3534604222128366], "final_y": [0.00019475261236866836, 0.00019475261236866836, 0.00019475261236866836]}, "mutation_prompt": null}
{"id": "cc9f21d0-4c6b-41e0-8b2b-f86a510848be", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR_dynamic = CR * (1 - (evaluations / self.budget))  # Changed line\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduce adaptive crossover probability to enhance exploration and exploitation balance in differential evolution.", "configspace": "", "generation": 48, "fitness": 0.21898588779415806, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.219 with standard deviation 0.000. And the mean value of best solutions found was 0.043 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.21898588779415806, 0.21898588779415806, 0.21898588779415806], "final_y": [0.04340459779195104, 0.04340459779195104, 0.04340459779195104]}, "mutation_prompt": null}
{"id": "8ba0d550-b659-43b8-a3e5-2ff55948f458", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with dynamic CR\n                CR_dynamic = CR * (1 - (evaluations / self.budget))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introducing dynamic crossover rate adaptation in the differential evolution process to enhance diversity.", "configspace": "", "generation": 49, "fitness": 0.20044663982398314, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.200 with standard deviation 0.000. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.20044663982398314, 0.20044663982398314, 0.20044663982398314], "final_y": [0.13117530782846074, 0.13117530782846074, 0.13117530782846074]}, "mutation_prompt": null}
{"id": "b54d1fd3-7637-4789-ae36-685571a7e7c2", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Change made here: adaptive crossover probability based on current evaluations\n                CR = 0.9 * (1 - (evaluations / self.budget))\n\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introducing adaptive crossover probability to balance exploration and exploitation in differential evolution.", "configspace": "", "generation": 50, "fitness": 0.20044663982398314, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.200 with standard deviation 0.000. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.20044663982398314, 0.20044663982398314, 0.20044663982398314], "final_y": [0.13117530782846074, 0.13117530782846074, 0.13117530782846074]}, "mutation_prompt": null}
{"id": "af313fa2-a482-475c-a622-5aaf38f652d2", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover\n                CR_adaptive = CR * (1 - (evaluations / self.budget))  # Line change\n                crossover = np.random.rand(self.dim) < CR_adaptive  # Line change\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Elitist Selection\n                if trial_fitness < fitness[i]:  # Line change\n                    population[i] = trial\n                fitness[i] = min(fitness[i], trial_fitness)  # Line change\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration with adaptive crossover probability and elitist selection in differential evolution.", "configspace": "", "generation": 51, "fitness": 0.24893812901804646, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.249 with standard deviation 0.000. And the mean value of best solutions found was 0.018 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.24893812901804646, 0.24893812901804646, 0.24893812901804646], "final_y": [0.018228878859308507, 0.018228878859308507, 0.018228878859308507]}, "mutation_prompt": null}
{"id": "97badc98-cb5a-406f-94b5-0d5d3bb93e5a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Random reseeding to introduce diversity\n            if evaluations < self.budget and np.random.rand() < 0.05:  # 5% chance of reseeding\n                new_individual = np.random.uniform(lb, ub, self.dim)\n                new_fitness = func(new_individual)\n                evaluations += 1\n                worst_index = np.argmax(fitness)\n                if new_fitness < fitness[worst_index]:\n                    population[worst_index] = new_individual\n                    fitness[worst_index] = new_fitness\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduce random reseeding to enhance diversity, improving convergence.", "configspace": "", "generation": 52, "fitness": 0.37678001164545555, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.377 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3767800116454555, 0.3767800116454555, 0.3767800116454555], "final_y": [2.098808239448677e-05, 2.098808239448677e-05, 2.098808239448677e-05]}, "mutation_prompt": null}
{"id": "02e8839e-f2ec-4f01-aaa7-ef10f4abdef3", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Initial crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                # Change made here: adaptive crossover probability based on fitness diversity\n                fitness_diversity = np.std(fitness) / (np.mean(fitness) + 1e-9)  # Avoid division by zero\n                CR_adaptive = CR * (1 + 0.5 * fitness_diversity)\n                crossover = np.random.rand(self.dim) < CR_adaptive\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Incorporate adaptive crossover probability based on fitness diversity to improve convergence.", "configspace": "", "generation": 53, "fitness": 0.3474819886963118, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.347 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.34748198869631175, 0.34748198869631175, 0.34748198869631175], "final_y": [5.2896944845017204e-05, 5.2896944845017204e-05, 5.2896944845017204e-05]}, "mutation_prompt": null}
{"id": "8dac94bb-0176-411c-a3ae-9d954d9176f1", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                # Change made here: dynamic crossover probability based on current evaluations\n                CR_dynamic = CR * (1 - (0.5 * (evaluations / self.budget)))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration using dynamic mutation factor adjustment in differential evolution with adaptive crossover probability.", "configspace": "", "generation": 54, "fitness": 0.28328883347747225, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.283 with standard deviation 0.000. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.28328883347747225, 0.28328883347747225, 0.28328883347747225], "final_y": [0.0042386254737183035, 0.0042386254737183035, 0.0042386254737183035]}, "mutation_prompt": null}
{"id": "0a851dcd-bd29-4573-a6d0-fbb368c44dfd", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor using sine function for exploration\n                F_dynamic = F * (1 + 0.5 * np.sin(np.pi * evaluations / self.budget))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Adaptive mutation factor enhanced with sine-based dynamic scaling to boost exploration over the convergence curve.", "configspace": "", "generation": 55, "fitness": 0.3323548357259588, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.332 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3323548357259588, 0.3323548357259588, 0.3323548357259588], "final_y": [0.00012559297692154054, 0.00012559297692154054, 0.00012559297692154054]}, "mutation_prompt": null}
{"id": "8a469581-e2d9-490f-86f4-765bbd4ff9b6", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Change made here: adaptive crossover probability based on current evaluations\n                CR_dynamic = CR * (1 + (0.5 * (evaluations / self.budget)))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploitation by adaptive crossover probability adjustment in differential evolution.", "configspace": "", "generation": 56, "fitness": 0.32079685077694986, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.321 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.32079685077694986, 0.32079685077694986, 0.32079685077694986], "final_y": [0.0003341552605829916, 0.0003341552605829916, 0.0003341552605829916]}, "mutation_prompt": null}
{"id": "f20774d9-1487-4314-83ae-8cbdff595bf2", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover\n                CR_adaptive = CR * (1 - (0.5 * (evaluations / self.budget)))  # Changed line\n                crossover = np.random.rand(self.dim) < CR_adaptive\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduce adaptive crossover probability to balance exploration and exploitation.", "configspace": "", "generation": 57, "fitness": 0.28328883347747225, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.283 with standard deviation 0.000. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.28328883347747225, 0.28328883347747225, 0.28328883347747225], "final_y": [0.0042386254737183035, 0.0042386254737183035, 0.0042386254737183035]}, "mutation_prompt": null}
{"id": "58791369-1b2f-4c36-95b0-5a08ea06aa23", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: stochastic convergence rate in mutation factor\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget))) * np.random.rand()\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploitation with stochastic convergence rate in differential evolution.", "configspace": "", "generation": 58, "fitness": 0.34532612497888565, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.345 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3453261249788856, 0.3453261249788856, 0.3453261249788856], "final_y": [8.747940941533937e-05, 8.747940941533937e-05, 8.747940941533937e-05]}, "mutation_prompt": null}
{"id": "f7a4b55f-426e-4455-8e86-033f9541a47e", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR_dynamic = CR * (1 - evaluations / self.budget)  # Dynamic crossover probability\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.25:  # Intensified local search chance increased from 15% to 25%\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration through adaptive crossover probability and local search intensification.", "configspace": "", "generation": 59, "fitness": 0.24002729285317392, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.000. And the mean value of best solutions found was 0.047 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.24002729285317392, 0.24002729285317392, 0.24002729285317392], "final_y": [0.046774948332785726, 0.046774948332785726, 0.046774948332785726]}, "mutation_prompt": null}
{"id": "7edcc8de-6386-46d3-99b4-5e335eb58df8", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    adaptive_learning_rate = 0.05 * (1 - evaluations / self.budget)  # Adaptation factor\n                    perturbation = np.random.normal(0, adaptive_learning_rate, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduce a learning rate adaptation to the perturbation in adaptive neighborhood search to enhance local exploitation.", "configspace": "", "generation": 60, "fitness": 0.38454918322605797, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.385 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.384549183226058, 0.384549183226058, 0.384549183226058], "final_y": [0.00010331446112170809, 0.00010331446112170809, 0.00010331446112170809]}, "mutation_prompt": null}
{"id": "c1743543-a386-4cf7-9353-956a4f852e38", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Change made here: adaptive crossover probability\n                CR_dynamic = CR * (0.5 + 0.5 * (evaluations / self.budget))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration with adaptive crossover probability in differential evolution.", "configspace": "", "generation": 61, "fitness": 0.24874504993752078, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.249 with standard deviation 0.000. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.24874504993752078, 0.24874504993752078, 0.24874504993752078], "final_y": [0.0037959281627677702, 0.0037959281627677702, 0.0037959281627677702]}, "mutation_prompt": null}
{"id": "39b9a163-135e-4efb-89c0-ab1fd66ca4f3", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover\n                CR_dynamic = CR * (1 - (evaluations / self.budget))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploitation via adaptive crossover in differential evolution.", "configspace": "", "generation": 62, "fitness": 0.30107607045018125, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.000. And the mean value of best solutions found was 0.005 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.30107607045018125, 0.30107607045018125, 0.30107607045018125], "final_y": [0.004509974344976317, 0.004509974344976317, 0.004509974344976317]}, "mutation_prompt": null}
{"id": "1d127056-1d79-4afc-b94f-611e93103ebc", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5\n        CR_initial = 0.9\n        np.random.seed(42)\n\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover Rate\n                CR_dynamic = CR_initial * (1 - (evaluations / self.budget)) + 0.1\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                else:\n                    # Diversity Preservation Mechanism\n                    if np.random.rand() < 0.1:\n                        random_index = np.random.randint(0, population_size)\n                        random_candidate = np.random.uniform(lb, ub, self.dim)\n                        random_fitness = func(random_candidate)\n                        evaluations += 1\n                        if random_fitness < fitness[random_index]:\n                            population[random_index] = random_candidate\n                            fitness[random_index] = random_fitness\n\n                if np.random.rand() < 0.15:\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduced adaptive crossover rate and diversity preservation mechanism to enhance solution quality.", "configspace": "", "generation": 63, "fitness": 0.2698773582148375, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.270 with standard deviation 0.000. And the mean value of best solutions found was 0.013 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.2698773582148375, 0.2698773582148375, 0.2698773582148375], "final_y": [0.01286740433028118, 0.01286740433028118, 0.01286740433028118]}, "mutation_prompt": null}
{"id": "d5dc397f-a994-42b4-957f-a182d258f6a8", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        # Initialize chaotic sequence\n        chaotic_map = np.random.rand(population_size)\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Update chaotic sequence using logistic map\n                chaotic_map[i] = 3.9 * chaotic_map[i] * (1 - chaotic_map[i])\n\n                # Dynamic mutation factor based on chaotic sequence\n                F_dynamic = F * chaotic_map[i] * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Integrate chaos theory by using chaotic maps for parameter tuning to enhance exploration in dynamic differential evolution.", "configspace": "", "generation": 64, "fitness": 0.4370967520303443, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.437 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.43709675203034426, 0.43709675203034426, 0.43709675203034426], "final_y": [1.055708240025627e-06, 1.055708240025627e-06, 1.055708240025627e-06]}, "mutation_prompt": null}
{"id": "ac250dc9-41d0-438e-b3aa-a0df28ddbe3f", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive probability\n                CR_adaptive = CR * (1 + (0.1 * (evaluations / self.budget)))\n                crossover = np.random.rand(self.dim) < CR_adaptive\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Modified exploration with adaptive crossover probability for improved local search.", "configspace": "", "generation": 65, "fitness": 0.44491605300082276, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.445 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.4449160530008228, 0.4449160530008228, 0.4449160530008228], "final_y": [6.442289739956353e-06, 6.442289739956353e-06, 6.442289739956353e-06]}, "mutation_prompt": null}
{"id": "e81754a1-e9a6-4fb3-8264-d908fe696a2d", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on population diversity\n                diversity = np.std(population, axis=0).mean()\n                F_dynamic = F * (1 + diversity)\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved exploration through adaptive mutation factor scaling based on population diversity.", "configspace": "", "generation": 66, "fitness": 0.16435231317920218, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.164 with standard deviation 0.000. And the mean value of best solutions found was 0.293 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.16435231317920218, 0.16435231317920218, 0.16435231317920218], "final_y": [0.29257456755144734, 0.29257456755144734, 0.29257456755144734]}, "mutation_prompt": null}
{"id": "7fefe4f8-b447-41d5-bfa5-0f40e793ab1e", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover Probability\n                CR_dynamic = CR * (1 - 0.5 * (evaluations / self.budget))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introducing adaptive crossover probability to balance exploration and exploitation in differential evolution.", "configspace": "", "generation": 67, "fitness": 0.28328883347747225, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.283 with standard deviation 0.000. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.28328883347747225, 0.28328883347747225, 0.28328883347747225], "final_y": [0.0042386254737183035, 0.0042386254737183035, 0.0042386254737183035]}, "mutation_prompt": null}
{"id": "11ec8a85-16bc-48a8-8307-6fbee07efe88", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor with non-uniform scaling\n                phase_factor = (evaluations / self.budget) ** 0.5\n                F_dynamic = F * (1 + 0.5 * phase_factor)\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved convergence by integrating non-uniform mutation scaling based on evolution phase.", "configspace": "", "generation": 68, "fitness": 0.36358535723021995, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.364 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.36358535723022, 0.36358535723022, 0.36358535723022], "final_y": [0.00017569047828301383, 0.00017569047828301383, 0.00017569047828301383]}, "mutation_prompt": null}
{"id": "d688448e-ab1d-4cbc-ae2b-e4e0855318b5", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive probability\n                fitness_std = np.std(fitness)\n                CR_adaptive = CR * (1.0 - (fitness_std / (np.max(fitness) - np.min(fitness) + 1e-9)))\n                crossover = np.random.rand(self.dim) < CR_adaptive\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved exploitation by using adaptive crossover probability based on current fitness diversity.", "configspace": "", "generation": 69, "fitness": 0.2558933162745526, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.256 with standard deviation 0.000. And the mean value of best solutions found was 0.013 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.2558933162745526, 0.2558933162745526, 0.2558933162745526], "final_y": [0.012564729863625333, 0.012564729863625333, 0.012564729863625333]}, "mutation_prompt": null}
{"id": "faa7c299-97f3-4e49-b619-302aee282e42", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover\n                CR_dynamic = CR * (1 - (evaluations / self.budget))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration by dynamic crossover probability adjustment in differential evolution.", "configspace": "", "generation": 70, "fitness": 0.24280489462254018, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.000. And the mean value of best solutions found was 0.057 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.24280489462254018, 0.24280489462254018, 0.24280489462254018], "final_y": [0.05681282791621891, 0.05681282791621891, 0.05681282791621891]}, "mutation_prompt": null}
{"id": "f5f972da-b6ab-437f-85f3-60d64cad7e02", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR_initial = 0.9  # Initial crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Dynamic Crossover Probability Adjustment\n                CR_dynamic = CR_initial * (1 - (evaluations / self.budget))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduce adaptive crossover probability adjustment based on current evaluations for better exploration-exploitation balance.", "configspace": "", "generation": 71, "fitness": 0.20044663982398314, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.200 with standard deviation 0.000. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.20044663982398314, 0.20044663982398314, 0.20044663982398314], "final_y": [0.13117530782846074, 0.13117530782846074, 0.13117530782846074]}, "mutation_prompt": null}
{"id": "4da48208-7d75-4064-be36-95b37b4e69e2", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Simulated Annealing Local Search\n                temperature = 1.0 - evaluations / self.budget\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1 * temperature, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i] or np.exp((fitness[i] - neighbor_fitness) / temperature) > np.random.rand():\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                # Adaptive population size\n                if evaluations % (self.budget // 10) == 0:\n                    population_size = max(5, population_size // 2)\n                    population = population[:population_size]\n                    fitness = fitness[:population_size]\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration and exploitation using adaptive population size and simulated annealing-inspired local search in differential evolution.", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('list.remove(x): x not in list').", "error": "ValueError('list.remove(x): x not in list')", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {}, "mutation_prompt": null}
{"id": "7274ca73-5db8-4754-8500-eb49f5455c68", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Dynamic Crossover Probability\n                CR_dynamic = CR * (1 - (0.5 * (evaluations / self.budget)))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduced dynamic crossover probability adjustment based on current evaluations in differential evolution.", "configspace": "", "generation": 73, "fitness": 0.3039978089018036, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.304 with standard deviation 0.000. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3039978089018036, 0.3039978089018036, 0.3039978089018036], "final_y": [0.0036304558492085805, 0.0036304558492085805, 0.0036304558492085805]}, "mutation_prompt": null}
{"id": "859cd8e0-e68f-459e-8e00-11bbebd7ed66", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR_dynamic = CR * (1 - (evaluations / self.budget))  # Dynamic crossover\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced convergence by incorporating a dynamic crossover probability based on the number of evaluations.", "configspace": "", "generation": 74, "fitness": 0.2810880147505598, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.281 with standard deviation 0.000. And the mean value of best solutions found was 0.018 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.2810880147505598, 0.2810880147505598, 0.2810880147505598], "final_y": [0.018171400646851806, 0.018171400646851806, 0.018171400646851806]}, "mutation_prompt": null}
{"id": "4bb10b9a-b51b-41e9-a74e-727bed1b53a1", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Initial crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Modify crossover probability dynamically\n                CR_dynamic = CR * (1 - (0.5 * (evaluations / self.budget)))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduce adaptive crossover probability based on current evaluations for better balance between exploration and exploitation.", "configspace": "", "generation": 75, "fitness": 0.2944668848357157, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.294 with standard deviation 0.000. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.2944668848357157, 0.2944668848357157, 0.2944668848357157], "final_y": [0.0011430484891164288, 0.0011430484891164288, 0.0011430484891164288]}, "mutation_prompt": null}
{"id": "4788eea6-1f85-4e9a-8499-e398b25e973d", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR_dynamic = CR * (0.5 + 0.5 * np.random.rand())  # Dynamic crossover\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved exploration by varying crossover probability dynamically in differential evolution.", "configspace": "", "generation": 76, "fitness": 0.2697069394694741, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.270 with standard deviation 0.000. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.2697069394694741, 0.2697069394694741, 0.2697069394694741], "final_y": [0.004383612444982983, 0.004383612444982983, 0.004383612444982983]}, "mutation_prompt": null}
{"id": "c4252878-9105-46c5-9ccd-033517f016b6", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        def logistic_map(x):\n            return 3.9 * x * (1 - x)\n\n        chaotic_factor = logistic_map(np.random.rand())\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on chaotic map\n                F_dynamic = F * (1 + (chaotic_factor * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced mutation diversity by incorporating chaotic maps and adaptive control in differential evolution.", "configspace": "", "generation": 77, "fitness": 0.40227885644903855, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.402 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.4022788564490386, 0.4022788564490386, 0.4022788564490386], "final_y": [2.044585285559865e-06, 2.044585285559865e-06, 2.044585285559865e-06]}, "mutation_prompt": null}
{"id": "454ee91e-f154-4e28-9bb1-9a6c211484d2", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    # Change: Adaptive perturbation based on fitness variance\n                    pert_factor = np.std(fitness) / np.mean(fitness) if np.mean(fitness) != 0 else 0.1\n                    perturbation = np.random.normal(0, pert_factor, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved local search using adaptive perturbation based on fitness variance to enhance convergence.", "configspace": "", "generation": 78, "fitness": 0.3290365052230999, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.329 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3290365052230999, 0.3290365052230999, 0.3290365052230999], "final_y": [7.229782732429493e-05, 7.229782732429493e-05, 7.229782732429493e-05]}, "mutation_prompt": null}
{"id": "102881f8-69e8-45d2-b461-8620785ddc37", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                direction = np.random.choice([-1, 1])  # Change: Stochastic directional search\n                mutant = population[a] + direction * F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Incorporate stochastic directional search to enhance convergence in the mutation phase.", "configspace": "", "generation": 79, "fitness": 0.33792998295677296, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.338 with standard deviation 0.000. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3379299829567729, 0.3379299829567729, 0.3379299829567729], "final_y": [0.0005320900172374916, 0.0005320900172374916, 0.0005320900172374916]}, "mutation_prompt": null}
{"id": "eac98c60-1c89-449e-b249-41f4f90325e8", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        # CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover\n                CR_dynamic = 0.9 * (1 - (evaluations / self.budget)) + 0.1\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduced adaptive crossover probability based on current evaluations to balance exploration and exploitation.", "configspace": "", "generation": 80, "fitness": 0.25721716844620357, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.257 with standard deviation 0.000. And the mean value of best solutions found was 0.023 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.25721716844620357, 0.25721716844620357, 0.25721716844620357], "final_y": [0.023482452571201396, 0.023482452571201396, 0.023482452571201396]}, "mutation_prompt": null}
{"id": "6ff2f37f-1c1f-4a72-b7e6-b91821ae99a7", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover\n                CR_dynamic = CR * (1 - (evaluations / self.budget))  # Change here\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduce adaptive crossover probability to balance exploration and exploitation in differential evolution.", "configspace": "", "generation": 81, "fitness": 0.3064095465416007, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.306 with standard deviation 0.000. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3064095465416007, 0.3064095465416007, 0.3064095465416007], "final_y": [0.0040084000814095775, 0.0040084000814095775, 0.0040084000814095775]}, "mutation_prompt": null}
{"id": "66f284eb-b846-4e96-b62c-4262cf7fbf7f", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR_initial = 0.9  # Initial crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Dynamic Crossover Probability Adjustment\n                CR_dynamic = CR_initial * (1 - (0.5 * (evaluations / self.budget)))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration by adjusting crossover probability based on evaluations in differential evolution.", "configspace": "", "generation": 82, "fitness": 0.2944668848357157, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.294 with standard deviation 0.000. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.2944668848357157, 0.2944668848357157, 0.2944668848357157], "final_y": [0.0011430484891164288, 0.0011430484891164288, 0.0011430484891164288]}, "mutation_prompt": null}
{"id": "24ad6b2c-b5db-4fb5-84f9-e666e15c6928", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15 * np.sin(evaluations):  # Chaotic local search probability\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved diversity using chaotic local search probabilities for enhanced convergence in differential evolution.", "configspace": "", "generation": 83, "fitness": 0.3929278640528186, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.393 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.39292786405281854, 0.39292786405281854, 0.39292786405281854], "final_y": [3.298005262620486e-05, 3.298005262620486e-05, 3.298005262620486e-05]}, "mutation_prompt": null}
{"id": "024e3217-61c9-4819-8879-df90b9eef738", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover: higher probability as evaluations progress\n                CR_dynamic = CR * (1 - (evaluations / self.budget))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive Neighborhood Search\n                if np.random.rand() < 0.25:  # Increased chance to perform local search\n                    local_search_point = population[i]\n                    perturbation_scale = 0.05 if evaluations / self.budget < 0.5 else 0.1\n                    perturbation = np.random.normal(0, perturbation_scale, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved adaptive mutation and crossover strategy in differential evolution with enhanced local search.", "configspace": "", "generation": 84, "fitness": 0.25453454223580985, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.255 with standard deviation 0.000. And the mean value of best solutions found was 0.041 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.25453454223580985, 0.25453454223580985, 0.25453454223580985], "final_y": [0.04057894591778934, 0.04057894591778934, 0.04057894591778934]}, "mutation_prompt": null}
{"id": "b20f8fbb-236c-4fa5-b9e3-4073b1057656", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR_dynamic = CR * (1 - (evaluations / self.budget))  # Change made here\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploitation through adaptive crossover probability in differential evolution.", "configspace": "", "generation": 85, "fitness": 0.2646411999706608, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.265 with standard deviation 0.000. And the mean value of best solutions found was 0.023 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.2646411999706608, 0.2646411999706608, 0.2646411999706608], "final_y": [0.022834102743252805, 0.022834102743252805, 0.022834102743252805]}, "mutation_prompt": null}
{"id": "cc90fb34-7615-45ac-b005-75373fffa38b", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Adjust population size dynamically\n            population_size = int(10 * self.dim * (1 + (evaluations / (2 * self.budget))))\n            for i in range(min(len(population), population_size)):\n                # Differential Evolution Mutation\n                indices = list(range(len(population)))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enriched exploration with adaptive population size in differential evolution.", "configspace": "", "generation": 86, "fitness": 0.3475854070834676, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.348 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3475854070834675, 0.3475854070834675, 0.3475854070834675], "final_y": [3.8075536916608325e-05, 3.8075536916608325e-05, 3.8075536916608325e-05]}, "mutation_prompt": null}
{"id": "05df83a1-b21d-4c66-b16d-358be510082d", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Initial crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Dynamic Crossover\n                CR_dynamic = CR * (1 - (0.5 * (evaluations / self.budget)))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduced a dynamic crossover probability that adapts based on the progress of evaluations to improve exploration and exploitation balance.", "configspace": "", "generation": 87, "fitness": 0.28328883347747225, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.283 with standard deviation 0.000. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.28328883347747225, 0.28328883347747225, 0.28328883347747225], "final_y": [0.0042386254737183035, 0.0042386254737183035, 0.0042386254737183035]}, "mutation_prompt": null}
{"id": "f6c27cd0-26c6-4c0e-9487-1b067c952954", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Variable Crossover Probability\n                CR_dynamic = CR * (1 - (evaluations / self.budget))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration using variable crossover probability adapted based on progress in differential evolution.", "configspace": "", "generation": 88, "fitness": 0.2810880147505598, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.281 with standard deviation 0.000. And the mean value of best solutions found was 0.018 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.2810880147505598, 0.2810880147505598, 0.2810880147505598], "final_y": [0.018171400646851806, 0.018171400646851806, 0.018171400646851806]}, "mutation_prompt": null}
{"id": "33abed85-1440-4d39-99df-62787d9a3897", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover\n                CR_dynamic = CR * (1 - (evaluations / self.budget))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration using dynamic mutation factor adjustment in differential evolution with adaptive crossover probability.", "configspace": "", "generation": 89, "fitness": 0.20044663982398314, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.200 with standard deviation 0.000. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.20044663982398314, 0.20044663982398314, 0.20044663982398314], "final_y": [0.13117530782846074, 0.13117530782846074, 0.13117530782846074]}, "mutation_prompt": null}
{"id": "516f34aa-0cd8-4467-9dcf-d6a6bd39bdb8", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        main_population_size = 7 * self.dim  # Reduced for multi-population strategy\n        sub_population_size = 3 * self.dim  # Additional sub-population\n        population_size = main_population_size + sub_population_size\n        F_base = 0.5  # Base mutation factor\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Dynamic mutation factor based on dimensionality\n                F_dynamic = F_base * (1 + (0.3 * (self.dim / (ub - lb).mean())))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Adaptive multi-population strategy with dimensional mutation factor for enhanced convergence in differential evolution.", "configspace": "", "generation": 90, "fitness": 0.3497467995849184, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.350 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3497467995849184, 0.3497467995849184, 0.3497467995849184], "final_y": [3.243432356593027e-05, 3.243432356593027e-05, 3.243432356593027e-05]}, "mutation_prompt": null}
{"id": "8cc89065-48a4-4f3a-b28b-0ae08890b3b9", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15 * (1 - evaluations / self.budget):  # Updated line\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration with adaptive neighborhood search probability in dynamic mutation-based differential evolution.", "configspace": "", "generation": 91, "fitness": 0.3431185742645686, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.343 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3431185742645686, 0.3431185742645686, 0.3431185742645686], "final_y": [0.0001431011247521937, 0.0001431011247521937, 0.0001431011247521937]}, "mutation_prompt": null}
{"id": "8ebdf4a3-41cf-4465-b0e9-4531d30ec37d", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: adaptive learning rate based on fitness improvement\n                F_adaptive = F * (1 + (0.5 * np.abs(fitness[i] - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)))\n                mutant = population[a] + F_adaptive * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduce learning rate adaptation based on fitness improvement in differential evolution.", "configspace": "", "generation": 92, "fitness": 0.3066272771128683, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.307 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3066272771128683, 0.3066272771128683, 0.3066272771128683], "final_y": [0.0003625826784070684, 0.0003625826784070684, 0.0003625826784070684]}, "mutation_prompt": null}
{"id": "063c786b-3525-48f1-a276-22d8d419f4e8", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive Crossover\n                CR_dynamic = CR * (1 - (evaluations / self.budget))  # Adjusted line\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Introduced adaptive crossover probability to enhance convergence in differential evolution.", "configspace": "", "generation": 93, "fitness": 0.21898588779415806, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.219 with standard deviation 0.000. And the mean value of best solutions found was 0.043 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.21898588779415806, 0.21898588779415806, 0.21898588779415806], "final_y": [0.04340459779195104, 0.04340459779195104, 0.04340459779195104]}, "mutation_prompt": null}
{"id": "39b31a4d-879b-45f0-99ab-5cc85da0f52c", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with dynamic crossover probability\n                CR_dynamic = CR * (1 - (0.5 * (evaluations / self.budget)))\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced convergence by dynamically adjusting crossover probability based on the current budget utilization.", "configspace": "", "generation": 94, "fitness": 0.2944668848357157, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.294 with standard deviation 0.000. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.2944668848357157, 0.2944668848357157, 0.2944668848357157], "final_y": [0.0011430484891164288, 0.0011430484891164288, 0.0011430484891164288]}, "mutation_prompt": null}
{"id": "f6e1f8fe-d4e5-4fb9-809d-88d801b12548", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR_dynamic = CR * (0.5 + 0.5 * (1 - evaluations / self.budget))  # Changed line\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Improved exploration by incorporating a time-adaptive crossover probability in the differential evolution process.", "configspace": "", "generation": 95, "fitness": 0.3160511882533943, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.316 with standard deviation 0.000. And the mean value of best solutions found was 0.004 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3160511882533943, 0.3160511882533943, 0.3160511882533943], "final_y": [0.004034815297770835, 0.004034815297770835, 0.004034815297770835]}, "mutation_prompt": null}
{"id": "f72fc795-8b39-43f3-83db-20bdf88711d5", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with a self-adaptive scaling factor\n                CR_adaptive = CR * (1 - (evaluations / self.budget))\n                crossover = np.random.rand(self.dim) < CR_adaptive\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Incorporate a self-adaptive scaling factor for crossover probability to enhance convergence rate.  ", "configspace": "", "generation": 96, "fitness": 0.2810880147505598, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.281 with standard deviation 0.000. And the mean value of best solutions found was 0.018 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.2810880147505598, 0.2810880147505598, 0.2810880147505598], "final_y": [0.018171400646851806, 0.018171400646851806, 0.018171400646851806]}, "mutation_prompt": null}
{"id": "63c1813b-f9fe-44f7-8cab-97df22deeb46", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                CR_dynamic = CR * (1 - (evaluations / self.budget))  # Dynamic crossover probability\n                crossover = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration using dynamic mutation factor adjustment and adaptive crossover probability in differential evolution.", "configspace": "", "generation": 97, "fitness": 0.20044663982398314, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.200 with standard deviation 0.000. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.20044663982398314, 0.20044663982398314, 0.20044663982398314], "final_y": [0.13117530782846074, 0.13117530782846074, 0.13117530782846074]}, "mutation_prompt": null}
{"id": "5db8a2fe-bd67-4062-b201-5428a54f7669", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: adaptive mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget))) * np.random.uniform(0.9, 1.1)\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_prob = np.random.uniform(0.8, 1.0)\n                crossover = np.random.rand(self.dim) < crossover_prob\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration and exploitation through adaptive mutation factor and crossover probability.", "configspace": "", "generation": 98, "fitness": 0.3651333139193498, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.365 with standard deviation 0.000. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3651333139193498, 0.3651333139193498, 0.3651333139193498], "final_y": [1.2505119754080645e-05, 1.2505119754080645e-05, 1.2505119754080645e-05]}, "mutation_prompt": null}
{"id": "a1fcbd48-70bb-4ee7-8660-7b1b9f87ea3c", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim  # Heuristic choice\n        F = 0.5  # Mutation factor for differential evolution\n        CR = 0.9  # Crossover probability\n        np.random.seed(42)\n\n        # Initialize population randomly within bounds\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change made here: dynamic mutation factor based on current evaluations\n                F_dynamic = F * (1 + (0.5 * (evaluations / self.budget)))\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select the better solution\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive Neighborhood Search\n                if np.random.rand() < 0.15:  # 15% chance to perform local search\n                    local_search_point = population[i]\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    neighbor = local_search_point + perturbation\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_fitness = func(neighbor)\n                    evaluations += 1\n\n                    if neighbor_fitness < fitness[i]:\n                        population[i] = neighbor\n                        fitness[i] = neighbor_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Stochastic rank-based selection\n            rank_indices = np.argsort(fitness)\n            rank_probabilities = np.array([1.0 / (rank + 1) for rank in range(population_size)])\n            rank_probabilities /= rank_probabilities.sum()\n            selected_indices = np.random.choice(rank_indices, population_size, p=rank_probabilities)\n            population = population[selected_indices]\n            fitness = fitness[selected_indices]\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridMetaheuristicOptimizer", "description": "Integrate stochastic rank-based selection to enhance exploration and maintain diversity in differential evolution.", "configspace": "", "generation": 99, "fitness": 0.3359094353049097, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.336 with standard deviation 0.000. And the mean value of best solutions found was 0.007 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f5a344de-6d5d-4983-a1b0-3a5188d3384c", "metadata": {"aucs": [0.3359094353049097, 0.3359094353049097, 0.3359094353049097], "final_y": [0.006710613418643694, 0.006710613418643694, 0.006710613418643694]}, "mutation_prompt": null}
