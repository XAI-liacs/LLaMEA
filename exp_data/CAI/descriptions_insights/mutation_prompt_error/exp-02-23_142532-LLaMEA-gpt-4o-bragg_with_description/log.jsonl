{"id": "0b944169-6254-4059-94d2-7312c89cb6f5", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.dim, :self.dim]\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm combines evolutionary strategies with orthogonal array sampling for balanced exploration and exploitation in black box optimization.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 280, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 128, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 67, in __call__\nValueError: shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)\n.", "error": "ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)')Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 280, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 128, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 67, in __call__\nValueError: shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "65b8936a-2d3a-4507-af8f-448f9cbdc76c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.9\n        self.mutation_rate_adapt = 0.1\n        self.crossover_rate_adapt = 0.1\n\n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n\n    def differential_mutation(self, population, best_idx):\n        \"\"\" Perform differential mutation on the population \"\"\"\n        idxs = [i for i in range(self.population_size) if i != best_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_rate * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        \"\"\" Perform crossover between target and mutant vectors \"\"\"\n        trial = np.copy(target)\n        for i in range(self.dim):\n            if np.random.rand() < self.crossover_rate:\n                trial[i] = mutant[i]\n        return trial\n\n    def adapt_parameters(self):\n        \"\"\" Adapt mutation and crossover rates \"\"\"\n        self.mutation_rate = max(0.1, min(0.9, self.mutation_rate + np.random.randn() * self.mutation_rate_adapt))\n        self.crossover_rate = max(0.1, min(0.9, self.crossover_rate + np.random.randn() * self.crossover_rate_adapt))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n\n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n\n            new_population = []\n            for i in range(self.population_size):\n                if i == max_idx:\n                    new_population.append(population[i])\n                    continue\n                mutant = self.differential_mutation(population, max_idx)\n                trial = self.crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness > fitness[i]:\n                    new_population.append(trial)\n                else:\n                    new_population.append(population[i])\n\n            population = np.array(new_population)\n\n            # Adapt parameters\n            self.adapt_parameters()\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "The algorithm leverages differential evolution combined with adaptive mutation and crossover rates to dynamically balance exploration and exploitation in black box optimization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'bounds' is not defined\").", "error": "NameError(\"name 'bounds' is not defined\")", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "a3471383-eb34-4811-b8f6-09fdf5c7c1cf", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        # Correct the size of orthogonal_expansion to match population and dimension\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, self.dim // 2)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.dim, :self.dim]\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm integrates a corrected orthogonal array to ensure compatibility with dimensions for balanced exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (10,) and (3,10) not aligned: 10 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (10,) and (3,10) not aligned: 10 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "5a35ad85-5c92-462d-8294-2fac3b6b577b", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 4  # Fixed orthogonal size\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.dim, :self.dim]\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm primarily uses evolutionary strategies enhanced with orthogonal array sampling for effective exploration and exploitation, with a fixed orthogonal size to prevent shape misalignment.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('only integer scalar arrays can be converted to a scalar index').", "error": "TypeError('only integer scalar arrays can be converted to a scalar index')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "2f55b08f-4f10-40ee-9c36-b7b9c5cb47bb", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.dim, :self.dim]\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array[:self.dim], top_individuals) / 2.0  # Align dimensionality\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm utilizes evolutionary strategies with orthogonal array sampling, incorporating dimensionality alignment correction for effective exploration and exploitation.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "a876541f-ba02-43eb-a151-66340de05e52", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.dim, :min(self.dim, orthogonal_expansion.shape[1])]\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "Improved handling of orthogonal array sizes to prevent dimension misalignment errors.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "c2bce68d-dd5a-4d60-adf9-bfa4f43ae7c7", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.orthogonal_size, :self.dim]  # Fixed dimension alignment\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm combines evolutionary strategies with orthogonal array sampling for balanced exploration and exploitation in black box optimization, now fixing the array dimension alignment issue.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "b56443d6-0910-4503-ab9c-61f97975416c", "solution": "import numpy as np\n\nclass AdaptiveOrthogonalDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.orthogonal_size, :self.dim]\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def differential_mutation(self, target_idx, population, bounds):\n        \"\"\" Perform differential mutation \"\"\"\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n    \n    def crossover(self, target, mutant):\n        \"\"\" Perform crossover between target and mutant vectors \"\"\"\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            new_population = []\n            for i in range(self.population_size):\n                mutant = self.differential_mutation(i, population, bounds)\n                offspring = self.crossover(population[i], mutant)\n                new_population.append(offspring)\n            \n            # Apply orthogonal array sampling for added diversity\n            orthogonal_array = self.orthogonal_array()\n            for array in orthogonal_array:\n                candidate = np.dot(array, new_population[:self.orthogonal_size]) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            new_population = np.array(new_population)\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "AdaptiveOrthogonalDifferentialEvolution", "description": "The algorithm utilizes adaptive differential evolution with orthogonal array sampling to enhance convergence and diversity in black box optimization.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "05ba239d-4719-444e-b8d8-0167567dca8b", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.orthogonal_size, :self.dim]  # Adjusted for correct dimension alignment\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim) * 0.1  # Adjusted mutation strength\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array[:len(top_individuals)], top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "Enhances diversity and exploration by adjusting orthogonal array integration and mutation strategy in an evolutionary optimizer.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('only integer scalar arrays can be converted to a scalar index').", "error": "TypeError('only integer scalar arrays can be converted to a scalar index')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "390f78ef-7cb4-433a-bd06-83e7eff6c7a5", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.orthogonal_size, :self.dim]  # Changed line\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm refines the use of orthogonal arrays by correcting the dimensionality mismatch issue for improved population diversity.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "63fb39fa-79a3-4029-9765-ab5137a2434c", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        expanded = np.tile(orthogonal_expansion, (self.dim // base.shape[0] + 1, 1))  # Ensure sufficient dimensions\n        return expanded[:self.dim, :self.dim]\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm combines evolutionary strategies with orthogonal array sampling for balanced exploration and exploitation in black box optimization, ensuring proper alignment of shapes for orthogonal array sampling.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "f5fcb4ea-e604-46f2-b7e2-915713cc513d", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base[:self.orthogonal_size], self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.dim, :self.dim] if self.dim <= base.shape[0] else base[:self.dim, :self.dim]\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "Enhanced OrthogonalEvolutionaryOptimizer with corrected orthogonal array generation ensuring proper dimensionality alignment for black box optimization.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 12 and the array at index 1 has size 9').", "error": "ValueError('all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 12 and the array at index 1 has size 9')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "64880767-072c-497f-818f-5313aaac0131", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:min(self.dim, orthogonal_expansion.shape[0]), :self.dim]  # Adjusted dimension alignment\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "Introduced a repair mechanism to handle dimension misalignment by adjusting the orthogonal array sampling.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "a6e63ad4-a9ac-4337-ba09-8aa834ca8337", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n\n    def adaptive_parameters(self, evaluations):\n        \"\"\" Adapt parameters based on evaluations to balance exploration and exploitation \"\"\"\n        scaling_factor = 1 - (evaluations / self.budget)\n        self.mutation_rate = max(0.05, scaling_factor * 0.1)\n        self.cross_rate = 0.5 + (0.5 * (1 - scaling_factor))\n\n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        expansion_size = self.orthogonal_size * 2\n        orthogonal_expansion = np.vstack([np.tile(base, (expansion_size, 1)), np.repeat(base, expansion_size, axis=0)])\n        orthogonal_expansion = orthogonal_expansion[:self.dim, :self.dim]\n        return orthogonal_expansion\n\n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n\n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n\n            # Adapt parameters based on evaluations\n            self.adaptive_parameters(evaluations)\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            orthogonal_array = self.orthogonal_array()\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / self.orthogonal_size\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm integrates evolutionary strategies with orthogonal array sampling and adaptive parameter tuning to enhance exploration, exploitation, and diversity in optimization.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (2,) and (3,10) not aligned: 2 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (2,) and (3,10) not aligned: 2 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "ae0fdb2d-ea1d-4dd9-8b6c-66a8668a6d14", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.orthogonal_size, :self.dim]  # Corrected dimensional alignment\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm enhances evolutionary and orthogonal array sampling by correcting the orthogonal array expansion for dimensional alignment.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "523317ff-033b-4a02-a90a-e1b16c7f7f87", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.orthogonal_size, :self.dim]  # Aligned dimensions\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm enhances evolutionary optimization by integrating orthogonal array sampling for better exploration and exploitation, with an adjustment in the orthogonal array method to align dimensions correctly.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "3965e38a-c07a-4325-9eea-559a28cd4140", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.orthogonal_size, :self.dim]  # Corrected dimension alignment\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm enhances exploration by correcting the orthogonal array usage, aligning its dimension correctly for better diversity.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)').", "error": "ValueError('shapes (4,) and (3,10) not aligned: 4 (dim 0) != 3 (dim 0)')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "77a7aed4-d2c1-4673-a21d-ee9605f2d4c9", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.orthogonal_size, :self.orthogonal_size]  # Fix: Align orthogonal array size\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "The algorithm combines evolutionary strategies with orthogonal array sampling for balanced exploration and exploitation in black box optimization, with a fix to align the orthogonal array and top individuals correctly.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('only integer scalar arrays can be converted to a scalar index').", "error": "TypeError('only integer scalar arrays can be converted to a scalar index')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "912bf5ba-9ae0-4648-b7b1-b5b0446b39fe", "solution": "import numpy as np\n\nclass OrthogonalEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.orthogonal_size = 3\n        self.mutation_rate = 0.1\n        self.cross_rate = 0.5\n    \n    def orthogonal_array(self):\n        \"\"\" Generates an orthogonal array for diversified sampling \"\"\"\n        base = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n        orthogonal_expansion = np.hstack([np.tile(base, (self.orthogonal_size, 1)), np.repeat(base, self.orthogonal_size, axis=0)])\n        return orthogonal_expansion[:self.population_size, :self.orthogonal_size]  # Corrected dimension alignment\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize a population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def crossover(self, parent1, parent2):\n        \"\"\" Perform crossover between two parents \"\"\"\n        mask = np.random.rand(self.dim) < self.cross_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual, bounds):\n        \"\"\" Mutate an individual with a given mutation rate \"\"\"\n        mutation_vector = np.random.randn(self.dim)\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        individual[mask] += mutation_vector[mask]\n        individual = np.clip(individual, bounds.lb, bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        orthogonal_array = self.orthogonal_array()\n        best_solution = None\n        best_fitness = float('-inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            fitness = np.array([func(ind) for ind in population])\n            evaluations += len(fitness)\n            \n            # Update best solution found\n            max_idx = np.argmax(fitness)\n            if fitness[max_idx] > best_fitness:\n                best_fitness = fitness[max_idx]\n                best_solution = population[max_idx]\n            \n            # Select top individuals\n            top_indices = np.argsort(fitness)[-self.orthogonal_size:]\n            top_individuals = population[top_indices]\n\n            # Generate new population using crossover and mutation\n            new_population = []\n            for parent1, parent2 in zip(top_individuals, np.roll(top_individuals, 1, axis=0)):\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring, bounds)\n                new_population.append(offspring)\n\n            # Include orthogonal array designs for diversity\n            for array in orthogonal_array:\n                candidate = np.dot(array, top_individuals) / 2.0\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                new_population.append(candidate)\n\n            # Ensure new population doesn't exceed population size\n            population = new_population[:self.population_size]\n        \n        return best_solution", "name": "OrthogonalEvolutionaryOptimizer", "description": "Improved OrthogonalEvolutionaryOptimizer with corrected orthogonal array expansion for dimensional alignment.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('only integer scalar arrays can be converted to a scalar index').", "error": "TypeError('only integer scalar arrays can be converted to a scalar index')", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {}, "mutation_prompt": null}
{"id": "46b8c3c7-711b-41a4-bae5-7b7e3c5ba3cd", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.5\n        self.learning_rate = 0.5\n        self.velocity_clamp = 0.1\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize particles and velocities within given bounds \"\"\"\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        \"\"\" Update velocity based on personal and global best \"\"\"\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamically adjust cognitive and social components based on success\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm employs a dynamic swarm intelligence approach where particles adaptively update their exploration-exploitation balance based on a learning mechanism derived from historical success rates.", "configspace": "", "generation": 19, "fitness": 0.4646992437053042, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.465 with standard deviation 0.036. And the mean value of best solutions found was 0.430 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "0b944169-6254-4059-94d2-7312c89cb6f5", "metadata": {"aucs": [0.438886891040944, 0.5156021051537936, 0.439608734921175], "final_y": [0.44872444609890283, 0.3916669615790621, 0.44987130905579487]}, "mutation_prompt": null}
{"id": "35a3e699-aa1e-4d7b-9bb4-f1a30684d77d", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.5\n        self.learning_rate = 0.5\n        self.velocity_clamp = 0.1\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize particles and velocities within given bounds \"\"\"\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        \"\"\" Update velocity based on personal and global best \"\"\"\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamically adjust cognitive and social components based on success\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            self.inertia_weight = 0.7 + 0.3 * (0.5 - success_rate)  # Adjusting inertia weight\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced adaptive inertia weight based on success rate to improve convergence and exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.4645511403098561, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.465 with standard deviation 0.036. And the mean value of best solutions found was 0.430 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "46b8c3c7-711b-41a4-bae5-7b7e3c5ba3cd", "metadata": {"aucs": [0.43881545486689055, 0.5152465603366299, 0.43959140572604793], "final_y": [0.4488143761421036, 0.39203321807062264, 0.44988522930519237]}, "mutation_prompt": null}
{"id": "be3c26b7-10c1-4289-b06c-714751aa280b", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.5\n        self.learning_rate = 0.5\n        self.velocity_clamp = 0.1\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize particles and velocities within given bounds \"\"\"\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        \"\"\" Update velocity based on personal and global best with decay \"\"\"\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        decay = 0.99  # Introduced decay factor\n        new_velocity = (inertia + cognitive + social) * decay\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamically adjust cognitive and social components based on success\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm employs a dynamic swarm intelligence approach where particles adaptively update their exploration-exploitation balance using a learning mechanism derived from historical success rates, with an enhanced velocity update that incorporates a decay term to maintain diversity.", "configspace": "", "generation": 21, "fitness": 0.464649109082458, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.465 with standard deviation 0.036. And the mean value of best solutions found was 0.430 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "46b8c3c7-711b-41a4-bae5-7b7e3c5ba3cd", "metadata": {"aucs": [0.4389061918578938, 0.5154321883455066, 0.43960894704397346], "final_y": [0.44870526864233307, 0.39186391617001004, 0.44987109268107417]}, "mutation_prompt": null}
{"id": "49a3976d-8825-44f6-b934-db5a19339599", "solution": "import numpy as np\n\nclass DifferentialEvolutionaryStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.adaptive_pressure = 0.5\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize population within given bounds \"\"\"\n        return np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n    \n    def mutate(self, population, idx):\n        \"\"\" Perform differential mutation \"\"\"\n        indices = list(range(self.population_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.mutation_factor * (population[b] - population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n    \n    def crossover(self, target, mutant):\n        \"\"\" Perform crossover between target and mutant \"\"\"\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.initialize_population(bounds)\n        fitness = np.array([func(individual) for individual in population])\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(population, i)\n                offspring = self.crossover(population[i], mutant)\n                offspring_fitness = func(offspring)\n                evaluations += 1\n                \n                # Selection based on fitness\n                if offspring_fitness > fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n            \n                if evaluations >= self.budget:\n                    break\n            \n            # Adjust mutation factor and crossover rate adaptively\n            successful_offsprings = np.mean(fitness > np.median(fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + self.adaptive_pressure * (0.5 - successful_offsprings), 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + self.adaptive_pressure * successful_offsprings, 0.5, 1.0)\n            \n        best_idx = np.argmax(fitness)\n        return population[best_idx]", "name": "DifferentialEvolutionaryStrategy", "description": "The algorithm combines evolutionary strategies with differential mutation, using adaptive selection pressure and mutation strategies to balance exploration and exploitation.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'bounds' is not defined\").", "error": "NameError(\"name 'bounds' is not defined\")", "parent_id": "46b8c3c7-711b-41a4-bae5-7b7e3c5ba3cd", "metadata": {}, "mutation_prompt": null}
{"id": "19cbe2d2-828e-489b-93c6-a9dcde751e88", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.5\n        self.learning_rate = 0.5\n        self.velocity_clamp = 0.1\n    \n    def initialize_population(self, bounds):\n        \"\"\" Initialize particles and velocities within given bounds \"\"\"\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        \"\"\" Update velocity based on personal and global best \"\"\"\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.inertia_weight_max - ((self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget))\n            \n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamically adjust cognitive and social components based on success\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n        return global_best", "name": "AdaptiveSwarmOptimizerV2", "description": "The algorithm utilizes a dynamic swarm intelligence approach with adaptive inertia weight, balancing exploration and exploitation based on the convergence speed of the swarm.", "configspace": "", "generation": 23, "fitness": 0.4646781353068506, "feedback": "The algorithm AdaptiveSwarmOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.465 with standard deviation 0.036. And the mean value of best solutions found was 0.430 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "46b8c3c7-711b-41a4-bae5-7b7e3c5ba3cd", "metadata": {"aucs": [0.43877666139631055, 0.5156596795325223, 0.43959806499171894], "final_y": [0.44884353982608327, 0.39163116269574405, 0.4498814835344719]}, "mutation_prompt": null}
{"id": "f5f28261-a6cf-49fd-b938-bc2f2cd97836", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.5\n        self.learning_rate = 0.5\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm enhances the Adaptive Swarm Optimizer by introducing adaptive inertia weight, dynamic adjustment of velocity clamp based on convergence, and the use of a probabilistic resampling mechanism to explore diverse solutions.", "configspace": "", "generation": 24, "fitness": 0.617732757645613, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.299 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "46b8c3c7-711b-41a4-bae5-7b7e3c5ba3cd", "metadata": {"aucs": [0.5604375902129741, 0.6700911458855128, 0.6226695368383518], "final_y": [0.3217744122557823, 0.2828261961064621, 0.2912854898098818]}, "mutation_prompt": null}
{"id": "c153567b-017c-47ae-b5d1-5cc67a1167f4", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.5\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm improves by slightly adjusting the learning rate to enhance exploration and convergence balance.", "configspace": "", "generation": 25, "fitness": 0.6177997040563945, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "f5f28261-a6cf-49fd-b938-bc2f2cd97836", "metadata": {"aucs": [0.5604375902129741, 0.6700911458855128, 0.6228703760706966], "final_y": [0.3217744122557823, 0.2828261961064621, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "9ccc4db5-6630-466c-ac1d-d7a41897758e", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.5\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                success_rate = np.mean(personal_best_values > global_best_value)\n                if np.random.rand() < 0.1 * (1 - success_rate):  # Adjusted probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm enhances exploration by adjusting the probability of probabilistic resampling based on the success rate.", "configspace": "", "generation": 26, "fitness": 0.6177997040563945, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "c153567b-017c-47ae-b5d1-5cc67a1167f4", "metadata": {"aucs": [0.5604375902129741, 0.6700911458855128, 0.6228703760706966], "final_y": [0.3217744122557823, 0.2828261961064621, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "aef4924b-f752-4ead-959f-527e206accd9", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm enhances convergence speed by slightly increasing the velocity update influence of the social component for better alignment with global bests.", "configspace": "", "generation": 27, "fitness": 0.6177998859994699, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "c153567b-017c-47ae-b5d1-5cc67a1167f4", "metadata": {"aucs": [0.5604381360422004, 0.6700911458855128, 0.6228703760706966], "final_y": [0.3217744122557823, 0.2828261961064621, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "7f315eea-7163-4f85-ab23-a7b171e25bdc", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.55  # Slightly increased cognitive component\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm introduces a slight increase in the cognitive component to better explore local regions and improve convergence.", "configspace": "", "generation": 28, "fitness": 0.6177998859994699, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {"aucs": [0.5604381360422004, 0.6700911458855128, 0.6228703760706966], "final_y": [0.3217744122557823, 0.2828261961064621, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "56280f12-1471-4e3d-a82c-17206266dee6", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.45  # Minimum inertia weight, slightly increased\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm improves convergence by slightly increasing the minimum inertia weight to maintain better exploration.", "configspace": "", "generation": 29, "fitness": 0.6177998859994699, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {"aucs": [0.5604381360422004, 0.6700911458855128, 0.6228703760706966], "final_y": [0.3217744122557823, 0.2828261961064621, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "d0c0f385-5e84-4f69-972a-8787635b6d8b", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6\n        self.learning_rate = 0.6\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4\n        self.max_velocity_clamp = 0.2\n        self.elite_memory = [None, float('-inf')]  # Store the best solution found\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def update_inertia(self, success_rate):\n        self.inertia_weight = max(self.min_inertia, self.inertia_weight * (1 - 0.5 * success_rate))\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    if value > self.elite_memory[1]:\n                        self.elite_memory = [particles[i], value]\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.update_inertia(success_rate)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n        \n        return self.elite_memory[0]", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm adapts dynamically with environmental feedback, incorporating a novel elite memory mechanism and adaptive inertia to accelerate convergence and improve exploration-exploitation balance.", "configspace": "", "generation": 30, "fitness": 0.6177998859994699, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {"aucs": [0.5604381360422004, 0.6700911458855128, 0.6228703760706966], "final_y": [0.3217744122557823, 0.2828261961064621, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "a90a63c6-da96-4a22-9fd7-d25e87439e07", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6\n        self.learning_rate = 0.6\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4\n        self.max_velocity_clamp = 0.2\n        self.dynamic_resampling_prob = 0.1  # Initial resampling probability\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < self.dynamic_resampling_prob:\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n\n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.98)  # More adaptive inertia\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.dynamic_resampling_prob = max(0.05, self.dynamic_resampling_prob * 0.99)  # Dynamic resampling adjustment\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Improved Adaptive Swarm Optimizer using dynamic particle resampling and adaptive inertia to enhance exploration capabilities.", "configspace": "", "generation": 31, "fitness": 0.5426532694975462, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.543 with standard deviation 0.050. And the mean value of best solutions found was 0.341 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {"aucs": [0.4954014741768529, 0.5210978886655182, 0.6114604456502675], "final_y": [0.35345293881084694, 0.34237983019448115, 0.32828447503647573]}, "mutation_prompt": null}
{"id": "4aa8c2e1-5825-4d45-816a-29e111b964dd", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6\n        self.learning_rate = 0.6\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.mean(np.std(particles, axis=0))  # Calculate diversity\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate * (1 + diversity)  # Adjust based on diversity\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm enhances exploration by adopting a dynamic strategy for learning rate and social component adjustments based on diversity in the swarm.", "configspace": "", "generation": 32, "fitness": 0.6177998859994699, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {"aucs": [0.5604381360422004, 0.6700911458855128, 0.6228703760706966], "final_y": [0.3217744122557823, 0.2828261961064621, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "6de77052-2f98-401e-b90c-1d0c035e4c83", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.98)  # Adjusted line\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm adjusts the inertia weight dynamically based on the improvement rate, enhancing balance between exploration and exploitation.", "configspace": "", "generation": 33, "fitness": 0.6177998859994699, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {"aucs": [0.5604381360422004, 0.6700911458855128, 0.6228703760706966], "final_y": [0.3217744122557823, 0.2828261961064621, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "b8be3048-d434-4adb-ab44-1dc93d59c013", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.6  # Slightly increased cognitive component\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence speed by slightly increasing the influence of personal bests in velocity updates for improved exploitation.", "configspace": "", "generation": 34, "fitness": 0.6177998859994699, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {"aucs": [0.5604381360422004, 0.6700911458855128, 0.6228703760706966], "final_y": [0.3217744122557823, 0.2828261961064621, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "d6bc6916-bf71-49a8-8b97-7883443d2141", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n            # Adjust population size based on success rate\n            if success_rate < 0.3:\n                self.population_size = min(50, self.population_size + 1)\n            elif success_rate > 0.7:\n                self.population_size = max(10, self.population_size - 1)\n        \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm refines convergence by dynamically adjusting the balance between exploration and exploitation via adaptive population size and inertia weight based on performance trends.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {}, "mutation_prompt": null}
{"id": "e8d3c663-8768-46ff-865a-f9beb71dd8fd", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n            if np.random.rand() < 0.05:  # Random perturbation to global best\n                global_best += np.random.rand(self.dim) * 0.01 * (bounds.ub - bounds.lb)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm improves global exploration by introducing a random perturbation to the global best position with a small probability.", "configspace": "", "generation": 36, "fitness": 0.5352570319587665, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.535 with standard deviation 0.057. And the mean value of best solutions found was 0.322 (0. is the best) with standard deviation 0.057.", "error": "", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {"aucs": [0.5121156376763971, 0.6142386795477968, 0.4794167786521055], "final_y": [0.2794312331680012, 0.283683464756891, 0.4033200852329012]}, "mutation_prompt": null}
{"id": "921423f3-a200-48d4-bdfc-74802e54bd77", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6\n        self.learning_rate = 0.6\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            self.learning_rate *= 0.99  # Adjust learning rate dynamically\n\n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "The algorithm introduces adaptive learning rates for velocity and particle updates to improve convergence in dynamic landscapes.", "configspace": "", "generation": 37, "fitness": 0.6173199702821379, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.617 with standard deviation 0.045. And the mean value of best solutions found was 0.299 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {"aucs": [0.5604381360422004, 0.6700911458855128, 0.6214306289187006], "final_y": [0.3217744122557823, 0.2828261961064621, 0.29346774406035236]}, "mutation_prompt": null}
{"id": "d2c56b41-d2e5-4e53-b630-d41fbcee9846", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.995)  # Change rate from 0.99 to 0.995\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introducing a dynamic adaptation in particle velocities to enhance exploration capabilities by modifying the inertia weight reduction strategy.", "configspace": "", "generation": 38, "fitness": 0.6177998859994699, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {"aucs": [0.5604381360422004, 0.6700911458855128, 0.6228703760706966], "final_y": [0.3217744122557823, 0.2828261961064621, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "a3d1f631-ddc6-4943-a17d-f577bb777e47", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)  # Adaptive scaling\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive velocity scaling based on global best improvement to enhance exploration and exploitation balance.", "configspace": "", "generation": 39, "fitness": 0.6179510369828832, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "aef4924b-f752-4ead-959f-527e206accd9", "metadata": {"aucs": [0.5605015854826267, 0.6704801909970353, 0.6228713344689877], "final_y": [0.3217744122557823, 0.2826100422569072, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "dcf0ed67-c62a-4df4-aa33-dbd86b5ec79f", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.8  # Increased social component\n        self.learning_rate = 0.7  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4\n        self.max_velocity_clamp = 0.3  # Increased max clamp\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        momentum = 0.5 * np.random.rand(self.dim) * (global_best - personal_best)  # Added momentum term\n        new_velocity = inertia + cognitive + social + momentum\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.15:  # Increased probability of resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.1)  # Faster scaling\n\n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.98)  # Faster decay\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.02)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic leader selection and momentum-based movement to enhance exploratory diversity and convergence speed in swarm optimization.", "configspace": "", "generation": 40, "fitness": 0.5647863666036436, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.565 with standard deviation 0.015. And the mean value of best solutions found was 0.323 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "a3d1f631-ddc6-4943-a17d-f577bb777e47", "metadata": {"aucs": [0.5654558914134014, 0.5457153309710311, 0.5831878774264985], "final_y": [0.31320792444111156, 0.3428836562228479, 0.3115676573643682]}, "mutation_prompt": null}
{"id": "81caaa4b-c6c4-48b8-a069-f7c5d04384ab", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)  # Adaptive scaling\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * (0.99 + 0.01 * np.random.rand()))  # Randomized decay\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce randomness in inertia weight decay for better exploration-exploitation trade-off.", "configspace": "", "generation": 41, "fitness": 0.522101785519813, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.522 with standard deviation 0.065. And the mean value of best solutions found was 0.361 (0. is the best) with standard deviation 0.057.", "error": "", "parent_id": "a3d1f631-ddc6-4943-a17d-f577bb777e47", "metadata": {"aucs": [0.47132691682346406, 0.6144164171064036, 0.4805620226295715], "final_y": [0.3986440714364099, 0.280613272354738, 0.4048763404119733]}, "mutation_prompt": null}
{"id": "37147cbc-7122-4631-bc76-798f9f21bba7", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)  # Adaptive scaling\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n\n            if np.random.rand() < 0.05:  # New random positional reset based on global best improvement\n                particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhance global exploration by introducing random positional resets based on global best improvement.", "configspace": "", "generation": 42, "fitness": 0.5359377425669531, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.536 with standard deviation 0.023. And the mean value of best solutions found was 0.361 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "a3d1f631-ddc6-4943-a17d-f577bb777e47", "metadata": {"aucs": [0.5472784781989162, 0.5568864834906124, 0.5036482660113308], "final_y": [0.3466683045124469, 0.3566597992117635, 0.38068653309185574]}, "mutation_prompt": null}
{"id": "5bbaf927-7fb2-48fb-bcba-0b01ca385b88", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < np.linalg.norm(velocities[i]):  # Probabilistic resampling based on velocity magnitude\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)  # Adaptive scaling\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhance the balance between exploration and exploitation by probabilistically applying resampling based on velocity magnitude.", "configspace": "", "generation": 43, "fitness": 0.6158407326106922, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.616 with standard deviation 0.010. And the mean value of best solutions found was 0.285 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "a3d1f631-ddc6-4943-a17d-f577bb777e47", "metadata": {"aucs": [0.6015522367621269, 0.6215730239761907, 0.6243969370937589], "final_y": [0.2586080060684742, 0.30929318192984867, 0.2862062548777655]}, "mutation_prompt": null}
{"id": "17a7d755-a1dc-478c-810c-5a79f3b67d4a", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  # Slightly increased social component\n        self.learning_rate = 0.6  # Adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_velocity_clamp = 0.2\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best):\n        inertia = self.inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:  # Introduce probabilistic resampling\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)  # Adaptive scaling\n\n                if evaluations >= self.budget:\n                    break\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * (0.99 + 0.01 * success_rate))  # Adapt inertia weight\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive inertia weight adjustment based on global best improvement to maintain exploration-exploitation balance.", "configspace": "", "generation": 44, "fitness": 0.6179510369828832, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "a3d1f631-ddc6-4943-a17d-f577bb777e47", "metadata": {"aucs": [0.5605015854826267, 0.6704801909970353, 0.6228713344689877], "final_y": [0.3217744122557823, 0.2826100422569072, 0.2906901688888386]}, "mutation_prompt": null}
{"id": "9536e283-f997-447d-ae54-914fffcb4dc8", "solution": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6\n        self.learning_rate = 0.5  # Slightly adjusted learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.3  # Adjusted minimum inertia weight\n        self.max_velocity_clamp = 0.25  # Adjusted max velocity clamp\n        self.stagnation_count = 0  # Track iterations without improvement\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, stagnation_factor):\n        inertia = self.inertia_weight * stagnation_factor * velocity  # Apply stagnation factor\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            improved = False\n            for i in range(self.population_size):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, 1 + self.stagnation_count / 10)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n\n                if np.random.rand() < 0.1:\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                    improved = True\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n\n            if not improved:\n                self.stagnation_count += 1\n                # Introduce leader-based mutation\n                if self.stagnation_count > 5:\n                    leader_idx = np.random.choice(self.population_size)\n                    particles[leader_idx] += np.random.normal(0, 0.1, size=self.dim)\n\n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * 0.99)\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedSwarmOptimizer", "description": "Incorporate dynamic inertia weight adjustment based on swarm stagnation and introduce a leader-based mutation strategy to maintain diversity and avoid premature convergence.", "configspace": "", "generation": 45, "fitness": 0.6085298204436681, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.609 with standard deviation 0.046. And the mean value of best solutions found was 0.315 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "a3d1f631-ddc6-4943-a17d-f577bb777e47", "metadata": {"aucs": [0.5605491507757595, 0.6704801909970353, 0.5945601195582096], "final_y": [0.3217744122557823, 0.2826100422569072, 0.33928891877942735]}, "mutation_prompt": null}
{"id": "a699d49b-7eec-43ae-8c3e-dd5bccd32e4d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8  # Factor for dynamic inertia adjustment\n        self.niche_radius = 0.05  # Niche radius for diversity preservation\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Maintain diversity by forming niches\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adjustment\n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Implement dynamic inertia weight adjustment and niche formation to enhance solution diversity and convergence speed.", "configspace": "", "generation": 46, "fitness": 0.6180523633977448, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "a3d1f631-ddc6-4943-a17d-f577bb777e47", "metadata": {"aucs": [0.560639600102761, 0.6707221684055514, 0.622795321684922], "final_y": [0.3217744122557823, 0.28246068656394674, 0.29065087081136254]}, "mutation_prompt": null}
{"id": "11704393-a55c-4eed-a43c-1c53028b9950", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8  # Factor for dynamic inertia adjustment\n        self.niche_radius = 0.05  # Niche radius for diversity preservation\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            if np.random.rand() < 0.2:  # Line changed: stochastic leader selection\n                global_best = personal_bests[np.argmax(personal_best_values)]  # Line changed\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Integrate adaptive learning rate and stochastic leader selection to further enhance solution exploration and exploitation balance.", "configspace": "", "generation": 47, "fitness": 0.5228883544705033, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.523 with standard deviation 0.065. And the mean value of best solutions found was 0.361 (0. is the best) with standard deviation 0.057.", "error": "", "parent_id": "a699d49b-7eec-43ae-8c3e-dd5bccd32e4d", "metadata": {"aucs": [0.47218312002264684, 0.614774285007967, 0.48170765838089624], "final_y": [0.3971688310010896, 0.27992508138469996, 0.4048763404119733]}, "mutation_prompt": null}
{"id": "69461c6d-c8a0-443e-ac61-5d81420709de", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8  # Factor for dynamic inertia adjustment\n        self.niche_radius = 0.05  # Niche radius for diversity preservation\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                if np.random.rand() < 0.05:  # Added particle reset strategy\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce particle reset strategy to enhance exploration capability and avoid premature convergence.", "configspace": "", "generation": 48, "fitness": 0.5103759395160373, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.510 with standard deviation 0.032. And the mean value of best solutions found was 0.369 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "a699d49b-7eec-43ae-8c3e-dd5bccd32e4d", "metadata": {"aucs": [0.47092436513265323, 0.5109376060299602, 0.5492658473854986], "final_y": [0.41811330268008906, 0.35331165416634724, 0.3367543406345751]}, "mutation_prompt": null}
{"id": "f1baafd9-faf3-4b43-ba26-ace7d06e06bb", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8  \n        self.niche_radius = 0.05  \n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius = max(0.01, self.niche_radius * (1 + 0.1 * (len(unique_particles) / self.population_size)))\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce dynamic niche radius adjustment based on diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 49, "fitness": 0.617209499381877, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.617 with standard deviation 0.045. And the mean value of best solutions found was 0.302 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "a699d49b-7eec-43ae-8c3e-dd5bccd32e4d", "metadata": {"aucs": [0.560639600102761, 0.6707221684055514, 0.6202667296373183], "final_y": [0.3217744122557823, 0.28246068656394674, 0.30299571724383834]}, "mutation_prompt": null}
{"id": "79c8f4b1-9ec1-4940-a7d0-7e07d6439c09", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8  # Factor for dynamic inertia adjustment\n        self.niche_radius = 0.05  # Niche radius for diversity preservation\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Maintain diversity by forming niches\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Dynamic inertia weight adjustment\n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n\n            self.learning_rate = max(0.1, self.learning_rate * (1 - success_rate))  # Adjust learning rate based on success rate\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce adaptive learning rate adjustment based on success rate to improve convergence speed and solution accuracy.", "configspace": "", "generation": 50, "fitness": 0.6180523633977448, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.045. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "a699d49b-7eec-43ae-8c3e-dd5bccd32e4d", "metadata": {"aucs": [0.560639600102761, 0.6707221684055514, 0.622795321684922], "final_y": [0.3217744122557823, 0.28246068656394674, 0.29065087081136254]}, "mutation_prompt": null}
{"id": "78d8dcd3-6416-4181-ba41-7435be1ddf5b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n    \n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.15:  # Changed mutation rate from 0.1 to 0.15\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n                    self.niche_radius *= 0.95  # Adaptive niche radius adjustment\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            success_rate = np.mean(personal_best_values > global_best_value)\n            self.cognitive_comp += self.learning_rate * (1 - success_rate)\n            self.social_comp += self.learning_rate * success_rate\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Integrate adaptive niche radius and particle rejuvenation to enhance exploration and convergence.", "configspace": "", "generation": 51, "fitness": 0.5591802555025409, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.559 with standard deviation 0.022. And the mean value of best solutions found was 0.329 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "a699d49b-7eec-43ae-8c3e-dd5bccd32e4d", "metadata": {"aucs": [0.557573454263974, 0.5329351940438638, 0.5870321181997848], "final_y": [0.3035719412813108, 0.374215410736374, 0.3078171417726522]}, "mutation_prompt": null}
{"id": "f3ea084e-6ae7-419e-94c1-3df33adac907", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01  # New: Adapt niche radius\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor  # New: Update niche radius\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp + self.learning_rate * 0.1)  # New: Adjust cognitive\n            self.social_comp = max(1.0, self.social_comp + self.learning_rate * 0.1)  # New: Adjust social\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce adaptive niche radius and dynamic cognitive/social component scaling to improve solution exploration and convergence.", "configspace": "", "generation": 52, "fitness": 0.6235864171609725, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "a699d49b-7eec-43ae-8c3e-dd5bccd32e4d", "metadata": {"aucs": [0.5608054030048668, 0.667794079327928, 0.6421597691501228], "final_y": [0.3217744122557823, 0.284236331594945, 0.259359965922074]}, "mutation_prompt": null}
{"id": "2b053629-e7f8-4045-87a3-be486a1eb908", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01  # New: Adapt niche radius\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)  # Changed: Adaptive velocity scaling\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor  # New: Update niche radius\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp + self.learning_rate * 0.1)  # New: Adjust cognitive\n            self.social_comp = max(1.0, self.social_comp + self.learning_rate * 0.1)  # New: Adjust social\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce an adaptive velocity scaling factor to enhance exploration and convergence rates.", "configspace": "", "generation": 53, "fitness": 0.6239078785555546, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "f3ea084e-6ae7-419e-94c1-3df33adac907", "metadata": {"aucs": [0.5608321027609503, 0.6678261981103467, 0.643065334795367], "final_y": [0.3217744122557823, 0.284236331594945, 0.2583036320262294]}, "mutation_prompt": null}
{"id": "8555fe20-31cf-4c02-aa06-24bbae9a2712", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01  # New: Adapt niche radius\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        pulsation = np.sin(np.random.rand() * np.pi)  # New: Introduce stochastic pulsation\n        new_velocity = (inertia + cognitive + social) * pulsation\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)  # Changed: Adaptive velocity scaling\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor  # New: Update niche radius\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp + self.learning_rate * 0.1)  # New: Adjust cognitive\n            self.social_comp = max(1.0, self.social_comp + self.learning_rate * 0.1)  # New: Adjust social\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce stochastic pulsation to velocity updating for preventing premature convergence.", "configspace": "", "generation": 54, "fitness": 0.5290503719735052, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.529 with standard deviation 0.019. And the mean value of best solutions found was 0.366 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "2b053629-e7f8-4045-87a3-be486a1eb908", "metadata": {"aucs": [0.5041614495395501, 0.5486153437540924, 0.5343743226268735], "final_y": [0.3757508513375456, 0.370765514464643, 0.3511157510730688]}, "mutation_prompt": null}
{"id": "dc4ff259-ffb2-48cc-a612-c126ea81c647", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.3  # Changed: Reduced minimum inertia\n        self.max_velocity_clamp = 0.25  # Changed: Increased maximum velocity clamp\n        self.dynamic_inertia_factor = 0.85  # Changed: Increased dynamic inertia factor\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.02  # Changed: Increased adaptive niche factor\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.1, self.velocity_clamp * 1.1)  # Changed: Adjusted velocity scaling\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor  \n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.2:  # Changed: Increased random restart probability\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Changed: Adjusted velocity clamp update\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.1, self.cognitive_comp + self.learning_rate * 0.05)  # Changed: Adjust cognitive\n            self.social_comp = max(1.1, self.social_comp + self.learning_rate * 0.05)  # Changed: Adjust social\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.02)\n        \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Utilize dynamic niche radius and adaptive inertia weight adjustments for improved exploration and convergence.", "configspace": "", "generation": 55, "fitness": 0.6174663801813952, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.617 with standard deviation 0.062. And the mean value of best solutions found was 0.290 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "2b053629-e7f8-4045-87a3-be486a1eb908", "metadata": {"aucs": [0.5746245794684415, 0.7056737712257721, 0.5721007898499719], "final_y": [0.28472543248408777, 0.26338334449837963, 0.3206535229707598]}, "mutation_prompt": null}
{"id": "9f890ffb-230e-49d0-a28f-0243ddddd5e4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01  # New: Adapt niche radius\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        mutation = 0.01 * (np.random.rand(self.dim) - 0.5)  # Introduce mutation step for exploration\n        new_velocity = inertia + cognitive + social + mutation\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)  # Changed: Adaptive velocity scaling\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor  # New: Update niche radius\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp + self.learning_rate * 0.1)  # New: Adjust cognitive\n            self.social_comp = max(1.0, self.social_comp + self.learning_rate * 0.1)  # New: Adjust social\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce a mutation step in the velocity update to enhance exploration.", "configspace": "", "generation": 56, "fitness": 0.5172787294545552, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.517 with standard deviation 0.010. And the mean value of best solutions found was 0.375 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "2b053629-e7f8-4045-87a3-be486a1eb908", "metadata": {"aucs": [0.5029318874261126, 0.5268845635129835, 0.5220197374245694], "final_y": [0.3857828078231036, 0.37469429933071097, 0.3635601410493713]}, "mutation_prompt": null}
{"id": "e2837527-af5a-43ff-8259-80eb91903d64", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.02  # Updated: Slightly increase niche adaptation\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        momentum = 0.1 * velocity  # New: Introduce momentum component\n        new_velocity = inertia + cognitive + social + momentum\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp + self.learning_rate * 0.1)\n            self.social_comp = max(1.0, self.social_comp + self.learning_rate * 0.1)\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Employ momentum-based velocity updates to enhance exploitation and adaptive niche management for improved diversity.", "configspace": "", "generation": 57, "fitness": 0.6239060905820574, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "2b053629-e7f8-4045-87a3-be486a1eb908", "metadata": {"aucs": [0.560826565039219, 0.6678261981103467, 0.6430655085966064], "final_y": [0.3217744122557823, 0.284236331594945, 0.2583036320262294]}, "mutation_prompt": null}
{"id": "529d0cf2-e8a3-4aaa-890c-910f735745e9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.02  # Changed: Slightly increase the adaptive niche factor\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)  # Changed: Adaptive velocity scaling\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor  # New: Update niche radius\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp + self.learning_rate * 0.1)  # New: Adjust cognitive\n            self.social_comp = max(1.0, self.social_comp + self.learning_rate * 0.1)  # New: Adjust social\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Augment niche diversity preservation by adjusting the adaptive_niche_factor to prevent premature convergence.", "configspace": "", "generation": 58, "fitness": 0.6239078785555546, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "2b053629-e7f8-4045-87a3-be486a1eb908", "metadata": {"aucs": [0.5608321027609503, 0.6678261981103467, 0.643065334795367], "final_y": [0.3217744122557823, 0.284236331594945, 0.2583036320262294]}, "mutation_prompt": null}
{"id": "f23c077c-c8e9-4046-b5b7-df290817d7f2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1:\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = 1.5 + 0.5 * np.sin(evaluations * np.pi / self.budget)  # Changed: Dynamic cognitive component\n            self.social_comp = 1.5 + 0.5 * np.cos(evaluations * np.pi / self.budget)  # Changed: Dynamic social component\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Refine adaptive velocity scaling by incorporating dynamic cognitive and social components for enhanced convergence.", "configspace": "", "generation": 59, "fitness": 0.6225765057048407, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.623 with standard deviation 0.045. And the mean value of best solutions found was 0.290 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "2b053629-e7f8-4045-87a3-be486a1eb908", "metadata": {"aucs": [0.5608404831826933, 0.6678261981103467, 0.6390628358214819], "final_y": [0.3217744122557823, 0.284236331594945, 0.2634875374207504]}, "mutation_prompt": null}
{"id": "512770be-bfac-4486-b74e-2fea1cfe3938", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.6  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n\n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n\n                particles[i] += np.random.normal(0, 0.01, self.dim)  # New: Add Gaussian mutation\n\n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp + self.learning_rate * 0.1)\n            self.social_comp = max(1.0, self.social_comp + self.learning_rate * 0.1)\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance exploration by introducing a Gaussian mutation operator to particles for better global search.", "configspace": "", "generation": 60, "fitness": 0.49724309142698625, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.497 with standard deviation 0.034. And the mean value of best solutions found was 0.392 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "2b053629-e7f8-4045-87a3-be486a1eb908", "metadata": {"aucs": [0.4511468474676472, 0.534019129508467, 0.5065632973048445], "final_y": [0.4193824107920088, 0.3776884165941422, 0.3790690006196078]}, "mutation_prompt": null}
{"id": "edeaf535-3b79-47e8-8707-057fb3c6b66d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  # Changed: Slightly increased learning rate\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp + self.learning_rate * 0.1)\n            self.social_comp = max(1.0, self.social_comp + self.learning_rate * 0.1)\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            \n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance convergence by slightly increasing the learning rate for faster adaptation to the search space.", "configspace": "", "generation": 61, "fitness": 0.6239082174826025, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "2b053629-e7f8-4045-87a3-be486a1eb908", "metadata": {"aucs": [0.5608331315639986, 0.6678261981103467, 0.6430653227734622], "final_y": [0.3217744122557823, 0.284236331594945, 0.2583036320262294]}, "mutation_prompt": null}
{"id": "c6dd3e46-08b2-49db-a9cc-ae057fe6f68d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n                    self.learning_rate *= 1.02  # Dynamic adjustment based on performance\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp + self.learning_rate * 0.1)\n            self.social_comp = max(1.0, self.social_comp + self.learning_rate * 0.1)\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.99)  # Adjust niche radius to balance exploration\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce dynamic adjustment of learning rate and niche radius based on performance to enhance exploration-exploitation balance.", "configspace": "", "generation": 62, "fitness": 0.6239083788366631, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "edeaf535-3b79-47e8-8707-057fb3c6b66d", "metadata": {"aucs": [0.5608336203462047, 0.6678261981103467, 0.6430653180534378], "final_y": [0.3217744122557823, 0.284236331594945, 0.2583036320262294]}, "mutation_prompt": null}
{"id": "dc007022-733d-4f5e-afd1-30dc40b3ff12", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n                    self.learning_rate *= 1.02  # Dynamic adjustment based on performance\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.99)  # Adjust niche radius to balance exploration\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce a simulated annealing-inspired temperature schedule to dynamically adjust social and cognitive components.  ", "configspace": "", "generation": 63, "fitness": 0.6240281472220032, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "c6dd3e46-08b2-49db-a9cc-ae057fe6f68d", "metadata": {"aucs": [0.5608365045813257, 0.6678261981103467, 0.6434217389743372], "final_y": [0.3217744122557823, 0.284236331594945, 0.25765411884287115]}, "mutation_prompt": null}
{"id": "d9372fb6-d95e-4a8f-b6df-2c352870bec2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1 * np.exp(-evaluations/self.budget): \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.99)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce a decaying probability for random particle reinitialization to improve exploration gradually.", "configspace": "", "generation": 64, "fitness": 0.52788660002241, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.528 with standard deviation 0.075. And the mean value of best solutions found was 0.373 (0. is the best) with standard deviation 0.060.", "error": "", "parent_id": "dc007022-733d-4f5e-afd1-30dc40b3ff12", "metadata": {"aucs": [0.42288324358954, 0.5645298042967642, 0.5962467521809254], "final_y": [0.45778358048110046, 0.32378054118734756, 0.33821841381624307]}, "mutation_prompt": null}
{"id": "525e8e64-7039-4549-82ca-933b813fe5b1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        stochastic_exploration = 0.1 * np.random.randn(self.dim)  # Added stochastic exploration factor\n        new_velocity = inertia + cognitive + social + stochastic_exploration\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n                    self.learning_rate *= 1.02 \n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.99)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce a stochastic exploration factor to enhance the global search capability and prevent premature convergence.", "configspace": "", "generation": 65, "fitness": 0.5778787451973604, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.578 with standard deviation 0.033. And the mean value of best solutions found was 0.325 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "dc007022-733d-4f5e-afd1-30dc40b3ff12", "metadata": {"aucs": [0.5830428363379925, 0.5346476525803918, 0.6159457466736968], "final_y": [0.34109085489114843, 0.3496324032369814, 0.2837909463952928]}, "mutation_prompt": null}
{"id": "c35acca5-f9fe-4af7-81da-24664b818130", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            fitness_var = np.var(personal_best_values)  # Calculate fitness variance\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1 + 0.2 * np.exp(-fitness_var):  # Adaptive mutation\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n                    self.learning_rate *= 1.02  \n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, (self.inertia_weight * self.dynamic_inertia_factor) ** (1 + evaluations/self.budget))  # Non-linear decrease\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.99)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance exploration by incorporating adaptive mutation based on fitness variance and integrating a non-linear decreasing inertia weight schedule.", "configspace": "", "generation": 66, "fitness": 0.592880443828432, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.593 with standard deviation 0.019. And the mean value of best solutions found was 0.297 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "dc007022-733d-4f5e-afd1-30dc40b3ff12", "metadata": {"aucs": [0.6164076942375654, 0.5918712180816279, 0.5703624191661028], "final_y": [0.29869168766812193, 0.28517786472952666, 0.3059324388552178]}, "mutation_prompt": null}
{"id": "cdd395ce-7530-4ed8-9d2a-e629a380ef19", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    perturbation = np.random.randn(self.dim) * 0.1 * (bounds.ub - bounds.lb)\n                    particles[i] += perturbation\n                    particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.95)  # Decrease niche radius for fine-tuning\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Incorporate non-uniform mutation strategy and adaptive niche radius for balancing exploration-exploitation trade-off.", "configspace": "", "generation": 67, "fitness": 0.5316647154253614, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.532 with standard deviation 0.013. And the mean value of best solutions found was 0.332 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "dc007022-733d-4f5e-afd1-30dc40b3ff12", "metadata": {"aucs": [0.5423245385153099, 0.5130050488842034, 0.5396645588765708], "final_y": [0.34849650729943393, 0.3247817968048592, 0.32170536658003224]}, "mutation_prompt": null}
{"id": "9cc4a1a0-73ab-403b-959e-47033854d821", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                if np.random.rand() < (personal_best_values[i] / (global_best_value + 1e-9)):  # Dynamic stochastic selection\n                    velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.99)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce a dynamic stochastic selection mechanism to increase exploration by randomly selecting particles for velocity update with a probability-based on their current fitness.", "configspace": "", "generation": 68, "fitness": 0.5386974825130388, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.539 with standard deviation 0.014. And the mean value of best solutions found was 0.337 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "dc007022-733d-4f5e-afd1-30dc40b3ff12", "metadata": {"aucs": [0.523706912804921, 0.5575107993968205, 0.5348747353373751], "final_y": [0.3466683045124469, 0.3057785444186857, 0.35720823199470775]}, "mutation_prompt": null}
{"id": "a9c1f2b4-05b5-47d6-bf5c-4ae833da3a4a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        chaos_map = np.random.rand()  # Initialize chaotic map variable\n\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n                    self.learning_rate *= 1.02  # Dynamic adjustment based on performance\n\n                if evaluations >= self.budget:\n                    break\n\n            # Use a chaotic map to update the inertia weight\n            chaos_map = 4 * chaos_map * (1 - chaos_map)\n            self.inertia_weight = self.min_inertia + (0.5 * chaos_map) * (0.9 - self.min_inertia)\n\n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.99)  # Adjust niche radius to balance exploration\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce a chaotic map for inertia weight adjustment to enhance exploration and exploitation balance.", "configspace": "", "generation": 69, "fitness": 0.5983359603496753, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.598 with standard deviation 0.049. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "dc007022-733d-4f5e-afd1-30dc40b3ff12", "metadata": {"aucs": [0.5618421663725839, 0.6678667569077956, 0.5652989577686465], "final_y": [0.3217744122557823, 0.284236331594945, 0.25765411884287115]}, "mutation_prompt": null}
{"id": "c6e079f9-f067-4901-9e36-1b0f32307bc7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n        self.elitism_rate = 0.1  # Added for elitism strategy\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            # Elitism: Preserve some best particles\n            elite_indices = np.argsort(personal_best_values)[-int(self.elitism_rate * self.population_size):]\n            elites = particles[elite_indices]\n\n            for i in range(len(particles)):\n                if i < len(elites):  # Skip updating elite particles\n                    continue\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n                    self.learning_rate *= 1.02  # Dynamic adjustment based on performance\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.99)  # Adjust niche radius to balance exploration\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce an elitism strategy and adaptive velocity scaling for enhanced performance and convergence.", "configspace": "", "generation": 70, "fitness": 0.617532373102275, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.618 with standard deviation 0.044. And the mean value of best solutions found was 0.301 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "dc007022-733d-4f5e-afd1-30dc40b3ff12", "metadata": {"aucs": [0.5599627869840877, 0.6673818485791954, 0.625252483743542], "final_y": [0.3217744122557823, 0.284236331594945, 0.29551177551483176]}, "mutation_prompt": null}
{"id": "18c076ad-24e7-4b84-bf3e-89acea5f5622", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)\n                    self.learning_rate *= 1.02  # Dynamic adjustment based on performance\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.learning_rate *= 1 + 0.01 * (np.random.rand() - 0.5)  # Random learning rate adaptation\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.99)  # Adjust niche radius to balance exploration\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce random learning rate adaptation for further exploration and exploitation balance.", "configspace": "", "generation": 71, "fitness": 0.5154293242351177, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.515 with standard deviation 0.052. And the mean value of best solutions found was 0.369 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "dc007022-733d-4f5e-afd1-30dc40b3ff12", "metadata": {"aucs": [0.4752922106184213, 0.5886037767598171, 0.4823919853271149], "final_y": [0.39117931141553985, 0.31035844909480403, 0.4048763404119733]}, "mutation_prompt": null}
{"id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance convergence by dynamically adjusting niche radius and velocity clamp based on exploration-exploitation balance.", "configspace": "", "generation": 72, "fitness": 0.6240411045124487, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "dc007022-733d-4f5e-afd1-30dc40b3ff12", "metadata": {"aucs": [0.5608540699073945, 0.6678468705802827, 0.6434223730496689], "final_y": [0.3217744122557823, 0.284236331594945, 0.25765411884287115]}, "mutation_prompt": null}
{"id": "9e696f96-f6d8-4359-ae3e-ce718455bbe5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        chaos_factor = 0.8 * np.sin(particle)  # Line 1: Chaotic map factor\n        new_velocity = inertia + cognitive + social + chaos_factor\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                turbulence = 0.1 * np.random.normal(size=self.dim)  # Line 2: Add turbulence\n                particles[i] += velocities[i] + turbulence\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  \n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce chaotic maps for velocity updates and stochastic turbulence to balance exploration and exploitation in particle swarm optimization.", "configspace": "", "generation": 73, "fitness": 0.5823200594264851, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.582 with standard deviation 0.039. And the mean value of best solutions found was 0.321 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5836733540292394, 0.5343005533430305, 0.6289862709071856], "final_y": [0.34099436623813617, 0.34854749862783974, 0.27319032455054115]}, "mutation_prompt": null}
{"id": "30cf7edc-e081-41f4-9140-519818b5b82a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = self.max_velocity_clamp / 2  # Reset velocity clamp\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.15 * np.exp(-evaluations/self.budget)))  # Faster cognitive increase\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhanced swarm optimizer improves exploration with accelerated cognitive component increase and velocity clamp reset.", "configspace": "", "generation": 74, "fitness": 0.6161311176802978, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.616 with standard deviation 0.044. And the mean value of best solutions found was 0.300 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5607740227745073, 0.66778501354596, 0.6198343167204261], "final_y": [0.3217744122557823, 0.284236331594945, 0.2942578428406861]}, "mutation_prompt": null}
{"id": "e28e6d3d-2bc4-46f3-9ea0-0a30321899f0", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.95  # Adjusted factor for better inertia decay\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                    \n                if np.random.rand() < 0.05:  # Added mutation step for exploration\n                    particles[i] += np.random.normal(0, 0.02, self.dim)\n                    \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance convergence by adding a mutation step and fine-tuning inertia weight adjustment to improve exploration-exploitation balance.", "configspace": "", "generation": 75, "fitness": 0.5734010888350891, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.573 with standard deviation 0.018. And the mean value of best solutions found was 0.279 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.574126758140636, 0.5953430848282761, 0.5507334235363552], "final_y": [0.25776700271075037, 0.3083227750511258, 0.2710901716263422]}, "mutation_prompt": null}
{"id": "1e55257e-d595-434c-91a5-a3f67cb266df", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                if evaluations % (self.population_size // 2) == 0:  # Dynamic resampling for exploration\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce dynamic particle resampling and adaptive inertia to enhance convergence without losing diversity.", "configspace": "", "generation": 76, "fitness": 0.5457279103768057, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.546 with standard deviation 0.034. And the mean value of best solutions found was 0.325 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5037274410795984, 0.5863679315269187, 0.5470883585239], "final_y": [0.3177568250428956, 0.3333470673409431, 0.3232743966195908]}, "mutation_prompt": null}
{"id": "6473b28d-4812-41c5-b123-5ec91e243c9d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        adaptive_scaling = 1.05 if np.random.rand() < 0.5 else 0.95  # Adaptive scaling factor\n        return np.clip(new_velocity * adaptive_scaling, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.15:  # Increased stochastic perturbation probability\n                    particles[i] += np.random.normal(0, 0.01, self.dim)  # Apply small Gaussian noise\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance convergence by introducing adaptive velocity scaling and a stochastic perturbation mechanism for better local exploration.", "configspace": "", "generation": 77, "fitness": 0.4948882251405508, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.495 with standard deviation 0.038. And the mean value of best solutions found was 0.363 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.44735941358522135, 0.5408081953757848, 0.49649706646064606], "final_y": [0.4045124980969341, 0.37230280544927397, 0.31294250769570486]}, "mutation_prompt": null}
{"id": "df95850f-74e3-44ab-8593-0fe0cb0cc993", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            variance_measure = np.var(personal_best_values)\n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * (1 + variance_measure / 10))\n            self.niche_radius = max(0.01, self.niche_radius * (1 - variance_measure / 20))\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Improve convergence by dynamically adjusting inertia and niche based on population performance variance.", "configspace": "", "generation": 78, "fitness": 0.6240159515083314, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5608416791707078, 0.6678372438957214, 0.6433689314585651], "final_y": [0.3217744122557823, 0.284236331594945, 0.2577757208397514]}, "mutation_prompt": null}
{"id": "07efe7d2-98c8-4570-961c-dc98f1d1bfc6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n        self.mutation_prob = 0.1  # Introduced mutation probability\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < self.mutation_prob:  # Changed to use mutation probability\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.99)  # Fine-tuned adjustment for balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Improve convergence by introducing a dynamic mutation probability for better exploration and fine-tuning the niche radius adjustment.", "configspace": "", "generation": 79, "fitness": 0.6240411045124487, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5608540699073945, 0.6678468705802827, 0.6434223730496689], "final_y": [0.3217744122557823, 0.284236331594945, 0.25765411884287115]}, "mutation_prompt": null}
{"id": "87914237-b3db-4840-8c82-a3192d46512e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)  # Modified factor\n                    self.learning_rate *= 1.03  # Adjusted factor\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.02)  # Modified factor\n            self.niche_radius = max(0.01, self.niche_radius * 0.99)  # Adjusted factor\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce adaptive learning rate and velocity adjustment based on swarm diversity to enhance convergence.", "configspace": "", "generation": 80, "fitness": 0.6240351632319779, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5608486007966025, 0.667835066936417, 0.6434218219629145], "final_y": [0.3217744122557823, 0.284236331594945, 0.25765411884287115]}, "mutation_prompt": null}
{"id": "3e9b1d40-d2c9-4537-ba89-657912a699f4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.09)  # Increase adjustment factor\n                    self.learning_rate *= 1.05  # Increase learning rate adjustment\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * (self.dynamic_inertia_factor + 0.05))  # Slightly increase inertia adjustment\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.15 * np.exp(-evaluations/self.budget)))  # Adjust cognitive component\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.12 * np.exp(-evaluations/self.budget)))  # Adjust social component\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.02)  # Fine-tune velocity clamp adjustment\n            self.niche_radius = max(0.01, self.niche_radius * 0.97)  # Increase niche radius adjustment for exploration-exploitation\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Refine convergence by integrating an adaptive exploration mechanism and fine-tuning the balance factors.", "configspace": "", "generation": 81, "fitness": 0.6174202602477662, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.617 with standard deviation 0.044. And the mean value of best solutions found was 0.298 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5608647549576422, 0.6678591894162176, 0.6235368363694388], "final_y": [0.3217744122557823, 0.284236331594945, 0.2892858216855865]}, "mutation_prompt": null}
{"id": "513538f8-a660-4ee1-8f8a-d63875032133", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce random cognitive and social component multiplicative factors to enhance exploration and exploitation adaptability.", "configspace": "", "generation": 82, "fitness": 0.5410628873459292, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.541 with standard deviation 0.034. And the mean value of best solutions found was 0.347 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.49847175825041223, 0.5828254827137294, 0.5418914210736461], "final_y": [0.37467218014574366, 0.2919482128639508, 0.37416719691634803]}, "mutation_prompt": null}
{"id": "496391b9-c7c7-4363-bcd7-d45ff4d422e0", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n        self.mutation_prob = 0.1\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < self.mutation_prob: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  \n                    self.learning_rate *= 1.02\n                    self.mutation_prob *= 0.95  # Adjust mutation probability\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  \n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance convergence by intelligently adjusting exploration parameters and mutation probability based on performance improvements.", "configspace": "", "generation": 83, "fitness": 0.5115953717970659, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.512 with standard deviation 0.037. And the mean value of best solutions found was 0.352 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.463774263110603, 0.5164689459762197, 0.554542906304375], "final_y": [0.3780215200182998, 0.33409255522817105, 0.3428480312827654]}, "mutation_prompt": null}
{"id": "8b2f6f08-1af8-4500-b523-06f3635dbfb7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 0.95, self.velocity_clamp * 0.95)  # Change here\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Minimize velocity clamp more aggressively to improve global search capabilities while maintaining local exploitation.", "configspace": "", "generation": 84, "fitness": 0.6233380080696712, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.623 with standard deviation 0.046. And the mean value of best solutions found was 0.289 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5608119396514277, 0.6677806720674699, 0.6414214124901161], "final_y": [0.3217744122557823, 0.284236331594945, 0.26017131613344435]}, "mutation_prompt": null}
{"id": "37f0349b-13be-4cf9-85af-a954a339b3f4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = max(0.1, self.velocity_clamp * 0.95)  # Adjust based on solution quality\n                    self.learning_rate *= 0.98  # Decrease learning rate slightly\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance convergence by adapting learning rate and velocity clamp based on solution quality.", "configspace": "", "generation": 85, "fitness": 0.623695602896853, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5607804776696169, 0.6677863219093282, 0.6425200091116139], "final_y": [0.3217744122557823, 0.284236331594945, 0.2582638354743886]}, "mutation_prompt": null}
{"id": "67efb682-1663-404a-99ca-3e5102fc37ef", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = (self.cognitive_comp + 0.5 * np.sin(np.pi * evaluations / self.budget)) * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance convergence by incorporating a time-varying dynamic cognitive component to better balance exploration-exploitation.", "configspace": "", "generation": 86, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {}, "mutation_prompt": null}
{"id": "c2828eea-270d-4542-9fa2-e7fe85ea56ba", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6\n        self.learning_rate = 0.65 \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4\n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n        self.memory_size = 5\n        self.global_memory = []\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp, self.velocity_clamp)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def adaptive_memory_perturbation(self, particle):\n        if len(self.global_memory) > 0:\n            memory_particle = self.global_memory[np.random.randint(len(self.global_memory))]\n            perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n            return np.clip(particle + perturbation * (memory_particle - particle), 0, 1)\n        return particle\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.15:  # Increased exploration probability\n                    particles[i] = self.adaptive_memory_perturbation(np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb)\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    if len(self.global_memory) >= self.memory_size:\n                        self.global_memory.pop(0)\n                    self.global_memory.append(global_best)  # Store in memory\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce adaptive memory and perturbation strategy to balance exploration-exploitation and enhance convergence.", "configspace": "", "generation": 87, "fitness": 0.4452779101394757, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.445 with standard deviation 0.034. And the mean value of best solutions found was 0.449 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.41584610300173286, 0.49364897734514057, 0.4263386500715536], "final_y": [0.47239265783783124, 0.41008586360098187, 0.463306362305155]}, "mutation_prompt": null}
{"id": "7e2a94a7-0158-47c6-a564-034f0018af5b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                particles[i] += 0.01 * np.random.randn(self.dim)  # Mutation mechanism added\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Improve exploration by adding a mutation mechanism that slightly perturbs particles' positions.", "configspace": "", "generation": 88, "fitness": 0.49770389917201197, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.498 with standard deviation 0.035. And the mean value of best solutions found was 0.392 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.45115271759704834, 0.5353956826141429, 0.5065632973048445], "final_y": [0.4193824107920088, 0.3767529721226942, 0.3790690006196078]}, "mutation_prompt": null}
{"id": "a0cb6f6b-2da0-483d-be9f-a6dcb1c95c62", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6\n        self.learning_rate = 0.65\n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4\n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n        self.mutation_probability = 0.15\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def chaotic_sequence(self, x):\n        return 4 * x * (1 - x)\n\n    def apply_mutation(self, particle, bounds):\n        if np.random.rand() < self.mutation_probability:\n            mutation_vector = np.random.uniform(bounds.lb, bounds.ub, self.dim)\n            particle = np.clip(particle + mutation_vector, bounds.lb, bounds.ub)\n        return particle\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        chaotic_factor = np.random.rand()\n\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n\n                particles[i] = self.apply_mutation(particles[i], bounds)\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            chaotic_factor = self.chaotic_sequence(chaotic_factor)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance adaptability and performance by introducing chaotic sequences and adaptive mutation to balance exploration and exploitation.", "configspace": "", "generation": 89, "fitness": 0.445839551725578, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.446 with standard deviation 0.033. And the mean value of best solutions found was 0.448 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.4192094139534325, 0.49216930034114614, 0.42613994088215545], "final_y": [0.46946522826628423, 0.41120895382751044, 0.46347428611883335]}, "mutation_prompt": null}
{"id": "f166459c-8b81-4e3a-b0fe-71004ef09d6b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance convergence by dynamically adjusting niche radius and velocity clamp based on exploration-exploitation balance.", "configspace": "", "generation": 73, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5608540699073945, 0.6678468705802827, 0.6434223730496689], "final_y": [0.3217744122557823, 0.284236331594945, 0.25765411884287115]}, "mutation_prompt": null}
{"id": "27ab43a2-9751-458b-9cac-4a27e99a2f5a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.1, self.velocity_clamp * 1.1)  # Adjusted clamp factor\n\n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.12:  # Increased random exploration factor\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.1)  # Increased adjustment factor\n                    self.learning_rate *= 1.03  # Slightly increased learning rate\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Further refine exploitation by improving swarm communication and individual escape mechanism.", "configspace": "", "generation": 91, "fitness": 0.6114811703771046, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.611 with standard deviation 0.031. And the mean value of best solutions found was 0.310 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.6246029111812358, 0.568244892991064, 0.6415957069590139], "final_y": [0.3054009787883778, 0.331058001531947, 0.29288856223658766]}, "mutation_prompt": null}
{"id": "95cb7327-05f7-4171-a9de-202a3c953f41", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.05)  # Reduced adjustment factor\n                    self.learning_rate *= 1.01\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * (self.dynamic_inertia_factor + 0.1))  # Adjusted calculation\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 0.99)  # New decay factor\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance convergence by integrating a decay-based velocity clamp and adaptive inertia adjustment for improved exploration-exploitation balance.", "configspace": "", "generation": 92, "fitness": 0.6191154073806323, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.619 with standard deviation 0.044. And the mean value of best solutions found was 0.295 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5608066803311573, 0.6678097559062809, 0.6287297859044585], "final_y": [0.3217744122557823, 0.284236331594945, 0.27997343131369734]}, "mutation_prompt": null}
{"id": "1c064155-50c8-41e0-a1a7-cb9ef705b695", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)\n                    self.learning_rate *= 1.02 + 0.005 * (evaluations / self.budget)  # Dynamic learning rate adjustment\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor * (1 + 0.01 * (evaluations / self.budget)))  # Inertia adaptation\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Improve exploration and convergence by introducing dynamic learning rate adjustments and inertia adaptation based on evaluations.", "configspace": "", "generation": 93, "fitness": 0.6240411038419497, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.624 with standard deviation 0.046. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5608540675965419, 0.6678468705802827, 0.6434223733490245], "final_y": [0.3217744122557823, 0.284236331594945, 0.25765411884287115]}, "mutation_prompt": null}
{"id": "ddfd113d-23ef-4247-8027-7c7cb78d2281", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.2\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n        self.restarts_interval = 100  # New: Interval for random restarts\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.05, self.velocity_clamp * 1.05)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        if len(unique_particles) < len(particles) / 2:  # New: Enhance diversity maintenance\n            idx_to_restart = np.random.choice(len(particles), len(particles) // 4, replace=False)\n            bounds = func.bounds\n            for idx in idx_to_restart:\n                particles[idx] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        self.niche_radius *= self.adaptive_niche_factor\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            if evaluations % self.restarts_interval == 0:  # New: Periodic random restarts\n                particles, velocities = self.initialize_population(bounds)\n                personal_bests = np.copy(particles)\n                personal_best_values = np.array([func(p) for p in particles])\n                \n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce periodic random restarts and enhanced diversity maintenance to improve exploration and prevent premature convergence.", "configspace": "", "generation": 94, "fitness": 0.5992165063861121, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.599 with standard deviation 0.008. And the mean value of best solutions found was 0.312 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5879110626178632, 0.6047275159627021, 0.605010940577771], "final_y": [0.3083866803231953, 0.3038267448332752, 0.3233284618542538]}, "mutation_prompt": null}
{"id": "4b8c39f4-1b4a-496b-97d7-b11c2e7815ec", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.3  # Changed from 0.2 to 0.3\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.15, self.velocity_clamp * 1.15)  # Changed from 1.05 to 1.15\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        if len(unique_particles) < 0.8 * self.population_size:  # Enhanced diversity maintenance\n            additional_particles = np.random.rand(self.population_size - len(unique_particles), self.dim) * (particles[0].ub - particles[0].lb) + particles[0].lb\n            unique_particles.extend(additional_particles)\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduced adaptive velocity clamping and enhanced diversity maintenance to improve exploration-exploitation balance.", "configspace": "", "generation": 95, "fitness": 0.6265096209184505, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.627 with standard deviation 0.047. And the mean value of best solutions found was 0.286 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "6fc73e0b-1827-4eec-9773-c63ecf7f4b89", "metadata": {"aucs": [0.5613610723067836, 0.6679128525614293, 0.650254937887139], "final_y": [0.3217744122557823, 0.284236331594945, 0.25282820332085587]}, "mutation_prompt": null}
{"id": "90029980-cb96-4d85-b327-e8418cef9ea1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.3  # Changed from 0.2 to 0.3\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.01\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.15, self.velocity_clamp * 1.15)  # Changed from 1.05 to 1.15\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        if len(unique_particles) < 0.8 * self.population_size:  # Enhanced diversity maintenance\n            additional_particles = np.random.rand(self.population_size - len(unique_particles), self.dim) * (particles[0].ub - particles[0].lb) + particles[0].lb\n            unique_particles.extend(additional_particles)\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.05:  # Reduced random position reset probability\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.08)  # Increased adjustment factor\n                    self.learning_rate *= 1.02\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.dynamic_inertia_factor)\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)  # More aggressive adjustment to explore-exploit balance\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Refined particle updating by reducing random position reset probability to enhance convergence consistency.", "configspace": "", "generation": 96, "fitness": 0.5461117392472169, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.546 with standard deviation 0.038. And the mean value of best solutions found was 0.351 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "4b8c39f4-1b4a-496b-97d7-b11c2e7815ec", "metadata": {"aucs": [0.49632622461962905, 0.5870088987163, 0.5550000944057215], "final_y": [0.35345293881084694, 0.33863180785328084, 0.361889340422626]}, "mutation_prompt": null}
{"id": "7f38f9d7-f1b4-4efd-855a-6a2d53d631d6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.3\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.02  # Slightly increased to enhance diversity adaptation\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.15, self.velocity_clamp * 1.15)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        if len(unique_particles) < 0.8 * self.population_size:\n            additional_particles = np.random.rand(self.population_size - len(unique_particles), self.dim) * (particles[0].ub - particles[0].lb) + particles[0].lb\n            unique_particles.extend(additional_particles)\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.1: \n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.09)  # Further increased adjustment factor\n                    self.learning_rate *= 1.03  # Slightly increased learning rate\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * (self.dynamic_inertia_factor + 0.02))  # Adjusted dynamic inertia factor with offset\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Improved inertia weight and niche management by introducing more dynamic adjustments for enhanced exploration and exploitation balance.", "configspace": "", "generation": 97, "fitness": 0.6265142033046402, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.627 with standard deviation 0.047. And the mean value of best solutions found was 0.286 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "4b8c39f4-1b4a-496b-97d7-b11c2e7815ec", "metadata": {"aucs": [0.5613668864885688, 0.6679204975790891, 0.6502552258462628], "final_y": [0.3217744122557823, 0.284236331594945, 0.25282820332085587]}, "mutation_prompt": null}
{"id": "b49137a2-3ab9-4af2-93d0-00c146bdf5d8", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.3\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.02\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.15, self.velocity_clamp * 1.15)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        if len(unique_particles) < 0.8 * self.population_size:\n            additional_particles = np.random.rand(self.population_size - len(unique_particles), self.dim) * (particles[0].ub - particles[0].lb) + particles[0].lb\n            unique_particles.extend(additional_particles)\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.15:  # Changed from 0.1 to 0.15\n                    particles[i] = particles[i] + np.random.normal(0, 0.1, self.dim)  # Introduced local perturbation\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.11)  # Changed from 1.09\n                    self.learning_rate *= 1.04  # Changed from 1.03\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * (self.dynamic_inertia_factor + 0.03))  # Changed from 0.02\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhanced exploration by introducing local perturbation and adaptive velocity adjustment alongside niche dynamics.", "configspace": "", "generation": 98, "fitness": 0.5467804736415063, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.547 with standard deviation 0.044. And the mean value of best solutions found was 0.294 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "7f38f9d7-f1b4-4efd-855a-6a2d53d631d6", "metadata": {"aucs": [0.48397437047365843, 0.5749450307070709, 0.5814220197437894], "final_y": [0.3633225428917666, 0.29375137017968356, 0.22600060468161798]}, "mutation_prompt": null}
{"id": "e21092c4-73ea-4c2e-be85-eb8fe478b5e1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  \n        self.cognitive_comp = 1.5\n        self.social_comp = 1.6  \n        self.learning_rate = 0.65  \n        self.velocity_clamp = 0.1\n        self.min_inertia = 0.4  \n        self.max_velocity_clamp = 0.3\n        self.dynamic_inertia_factor = 0.8\n        self.niche_radius = 0.05\n        self.adaptive_niche_factor = 1.02\n\n    def initialize_population(self, bounds):\n        particles = np.random.rand(self.population_size, self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n        velocities = np.random.rand(self.population_size, self.dim) * self.velocity_clamp - (self.velocity_clamp / 2)\n        return particles, velocities\n    \n    def update_velocity(self, velocity, particle, personal_best, global_best, inertia_weight):\n        inertia = inertia_weight * velocity\n        cognitive = self.cognitive_comp * np.random.rand(self.dim) * (personal_best - particle)\n        social = self.social_comp * np.random.rand(self.dim) * (global_best - particle)\n        new_velocity = inertia + cognitive + social\n        return np.clip(new_velocity, -self.velocity_clamp * 1.15, self.velocity_clamp * 1.15)\n    \n    def maintain_diversity(self, particles):\n        unique_particles = []\n        for i, particle in enumerate(particles):\n            if all(np.linalg.norm(particle - p) >= self.niche_radius for p in unique_particles):\n                unique_particles.append(particle)\n        self.niche_radius *= self.adaptive_niche_factor\n        if len(unique_particles) < 0.8 * self.population_size:\n            additional_particles = np.random.rand(self.population_size - len(unique_particles), self.dim) * (particles[0].ub - particles[0].lb) + particles[0].lb\n            unique_particles.extend(additional_particles)\n        return np.array(unique_particles)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        particles, velocities = self.initialize_population(bounds)\n        personal_bests = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        global_best_idx = np.argmax(personal_best_values)\n        global_best = personal_bests[global_best_idx]\n        global_best_value = personal_best_values[global_best_idx]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            particles = self.maintain_diversity(particles)\n            \n            for i in range(len(particles)):\n                velocities[i] = self.update_velocity(velocities[i], particles[i], personal_bests[i], global_best, self.inertia_weight)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], bounds.lb, bounds.ub)\n                \n                if np.random.rand() < 0.15:  # Increased randomness for particle reset\n                    particles[i] = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                \n                value = func(particles[i])\n                evaluations += 1\n                \n                if value > personal_best_values[i]:\n                    personal_bests[i] = particles[i]\n                    personal_best_values[i] = value\n                \n                if value > global_best_value:\n                    global_best = particles[i]\n                    global_best_value = value\n                    self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.09)\n                    self.learning_rate *= 1.03\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * (self.dynamic_inertia_factor + 0.02))\n            \n            self.cognitive_comp = max(1.0, self.cognitive_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            self.social_comp = max(1.0, self.social_comp * (1 + self.learning_rate * 0.1 * np.exp(-evaluations/self.budget)))\n            \n            self.velocity_clamp = min(self.max_velocity_clamp, self.velocity_clamp * 1.01)\n            self.niche_radius = max(0.01, self.niche_radius * 0.98)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhanced Adaptive Swarm Optimizer with improved randomness in particle reset mechanism to escape local minima and foster exploration.", "configspace": "", "generation": 99, "fitness": 0.5573224412948776, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.557 with standard deviation 0.028. And the mean value of best solutions found was 0.331 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "7f38f9d7-f1b4-4efd-855a-6a2d53d631d6", "metadata": {"aucs": [0.560805069099252, 0.5220274478254423, 0.5891348069599385], "final_y": [0.3035719412813108, 0.3846379239719254, 0.3050402374039729]}, "mutation_prompt": null}
