{"id": "df4f0cb9-b419-42dc-b980-a3e30d395797", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        # Simple penalty for non-periodicity (encouraging periodicity)\n        period = int(self.dim / 2)  # Assuming a periodic structure\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        return periodic_deviation\n\n    def differential_evolution(self, func, lb, ub):\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation and Crossover\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Selection\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            # Update the best solution found\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        # Fine-tuning with local optimization\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "HybridDEOptimizer", "description": "A hybrid metaheuristic combining Differential Evolution with periodicity promotion and local search for effective optimization of multilayer photonic structures.", "configspace": "", "generation": 0, "fitness": 0.6731648544177017, "feedback": "The algorithm HybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.673 with standard deviation 0.011. And the mean value of best solutions found was 0.290 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": null, "metadata": {"aucs": [0.6803385320746369, 0.6569555768160058, 0.6822004543624623], "final_y": [0.28274674858327264, 0.3041766564788797, 0.2827504728967508]}, "mutation_prompt": null}
{"id": "7af1df26-81e8-4f91-819f-19acf22ed772", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\n\nclass LayeredAdaptiveStrategyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n        self.kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)\n        self.gp = GaussianProcessRegressor(kernel=self.kernel)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = int(self.dim / 2)\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        return periodic_deviation\n\n    def differential_evolution(self, func, lb, ub):\n        F_initial = 0.5\n        CR = 0.9\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            F_adaptive = F_initial * np.exp(-i / self.population_size)  # Adaptive F\n            mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def bayesian_focus(self, func, lb, ub):\n        if self.eval_count < self.budget:\n            X = self.population\n            y = -np.array([func(x) for x in X])  # Negative for maximization\n            self.eval_count += len(X)\n            self.gp.fit(X, y)\n\n            bounds = np.array([lb, ub]).T\n            res = minimize(lambda x: -self.gp.predict(x.reshape(1, -1))[0], self.best_solution, bounds=bounds, method='L-BFGS-B')\n            if res.fun > -self.best_score:\n                self.best_score = -res.fun\n                self.best_solution = res.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.bayesian_focus(func, lb, ub)\n\n        return self.best_solution", "name": "LayeredAdaptiveStrategyOptimizer", "description": "A Layered Adaptive Strategy Optimizer (LASO) leveraging adaptive weight tuning in Differential Evolution combined with Bayesian learning to focus on promising regions and accelerate convergence in multilayer photonic structure optimization.", "configspace": "", "generation": 1, "fitness": 0.5539838815908346, "feedback": "The algorithm LayeredAdaptiveStrategyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.554 with standard deviation 0.046. And the mean value of best solutions found was 0.339 (0. is the best) with standard deviation 0.045.", "error": "", "parent_id": "df4f0cb9-b419-42dc-b980-a3e30d395797", "metadata": {"aucs": [0.5039179743472784, 0.6146494046701954, 0.5433842657550298], "final_y": [0.39948979428905884, 0.2920953789847428, 0.3258379568047125]}, "mutation_prompt": null}
{"id": "025873a3-152a-4e0c-9e48-8a932f0a8eea", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        # Dynamic penalty for non-periodicity\n        period = np.random.randint(1, self.dim // 2)  # Randomized periodic structure for diversity\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        return periodic_deviation\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Adaptive differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Adaptive crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation and Crossover\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Selection\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            # Update the best solution found\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        # Enhanced local optimization with adaptive bounds\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "An enhanced hybrid optimizer utilizing adaptive Differential Evolution and dynamic periodicity adjustment for maximizing reflectivity in multilayer photonic structures.", "configspace": "", "generation": 2, "fitness": 0.7721410937492942, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.193. And the mean value of best solutions found was 0.251 (0. is the best) with standard deviation 0.109.", "error": "", "parent_id": "df4f0cb9-b419-42dc-b980-a3e30d395797", "metadata": {"aucs": [0.4991640553661101, 0.9124009221284113, 0.9048583037533613], "final_y": [0.4047682528279716, 0.181881367777043, 0.16485667110225377]}, "mutation_prompt": null}
{"id": "ce244445-1c12-4abc-aecc-91e15421ca95", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Adjusted population size for efficient exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = np.random.randint(1, self.dim // 2)  # Randomized periodic structure for diversity\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        return periodic_deviation\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.4, 0.8)  # More adaptive differential weight range\n        CR = np.random.uniform(0.7, 0.9)  # More adaptive crossover probability range\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation and Crossover\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Selection\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            # Update the best solution found\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "A refined hybrid optimizer leveraging improved dynamic Differential Evolution and local search with adaptive periodic adjustments for optimizing multilayer photonic structures.", "configspace": "", "generation": 3, "fitness": 0.741346997715988, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.741 with standard deviation 0.103. And the mean value of best solutions found was 0.254 (0. is the best) with standard deviation 0.047.", "error": "", "parent_id": "025873a3-152a-4e0c-9e48-8a932f0a8eea", "metadata": {"aucs": [0.6822759145513546, 0.8864155790166506, 0.6553494995799587], "final_y": [0.2827471194261679, 0.18813251452755342, 0.29182747175050305]}, "mutation_prompt": null}
{"id": "40c10560-a846-41b0-bc42-162a8cfb3912", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n        self.enhanced_periodicity_weight = 0.1  # New periodicity weight\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = np.random.randint(1, self.dim // 2)\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        # Added enhanced periodicity score\n        return periodic_deviation + self.enhanced_periodicity_weight * np.std(x)\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)\n        CR = np.random.uniform(0.8, 1.0)\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def stochastic_local_search(self, func, lb, ub):\n        # Using a stochastic search method\n        perturbation = np.random.uniform(-0.05, 0.05, self.dim)\n        candidate = self.best_solution + perturbation\n        candidate = np.clip(candidate, lb, ub)\n\n        candidate_score = func(candidate)\n        self.eval_count += 1\n\n        if candidate_score > self.best_score:\n            self.best_score = candidate_score\n            self.best_solution = candidate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.stochastic_local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "An optimized hybrid approach using stochastic local search combined with adaptive differential evolution and periodicity enhancement for reflectivity maximization in photonic structures.", "configspace": "", "generation": 4, "fitness": 0.583989996628985, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.584 with standard deviation 0.074. And the mean value of best solutions found was 0.317 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "025873a3-152a-4e0c-9e48-8a932f0a8eea", "metadata": {"aucs": [0.5112480454081862, 0.6858450576725786, 0.55487688680619], "final_y": [0.3575370177237204, 0.2852473541188426, 0.30752043159956255]}, "mutation_prompt": null}
{"id": "89d9bb85-8602-4adc-82c7-0ba2038d4f3b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass MultiStrategyAdaptiveMemeticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Effective population size\n        self.subcomponents = 2  # Divide problem into subcomponents\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        # Reward for solutions with periodic characteristics\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        return periodic_deviation\n\n    def coevolutionary_strategy(self, func, lb, ub):\n        # Divide the problem into subcomponents for cooperative coevolution\n        sub_size = self.dim // self.subcomponents\n        F = np.random.uniform(0.4, 0.8)  # Diverse differential weight\n        CR = np.random.uniform(0.7, 0.9)  # Diverse crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            for j in range(self.subcomponents):\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.array(self.population[i])\n                start = j * sub_size\n                end = (j + 1) * sub_size\n                mutant[start:end] = np.clip(a[start:end] + F * (b[start:end] - c[start:end]), lb, ub)\n\n                cross_points = np.random.rand(sub_size) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, sub_size)] = True\n\n                trial = np.array(self.population[i])\n                trial[start:end] = np.where(cross_points, mutant[start:end], self.population[i][start:end])\n\n                # Selection\n                trial_score = func(trial)\n                self.eval_count += 1\n                penalty = self.reflectivity_score(trial)\n                \n                if trial_score > func(self.population[i]) - penalty:\n                    self.population[i] = trial\n\n                # Update the best solution found\n                if trial_score > self.best_score:\n                    self.best_score = trial_score\n                    self.best_solution = trial\n\n    def local_periodic_search(self, func, lb, ub):\n        # Period-preserving local optimization\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='TNC')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.coevolutionary_strategy(func, lb, ub)\n            self.local_periodic_search(func, lb, ub)\n\n        return self.best_solution", "name": "MultiStrategyAdaptiveMemeticAlgorithm", "description": "Multi-Strategy Adaptive Memetic Algorithm (MSAMA) combining cooperative coevolution and period-preserving local search for enhanced exploration and exploitation in multilayer photonic structure optimization.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (5,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (5,) (10,) (10,) ')", "parent_id": "025873a3-152a-4e0c-9e48-8a932f0a8eea", "metadata": {}, "mutation_prompt": null}
{"id": "aea93cfe-9d5b-41d6-83d6-2a8da4265323", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = np.random.randint(1, self.dim // 2)\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        return periodic_deviation\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 1.0)  # Modified adaptive differential weight\n        CR = np.random.uniform(0.6, 1.0)  # Broadened adaptive crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "A refined hybrid optimizer that incorporates adaptive mutation control and periodicity-preserving local search to enhance solution accuracy and convergence speed for photonic structure optimization.", "configspace": "", "generation": 6, "fitness": 0.7109507788485679, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.711 with standard deviation 0.124. And the mean value of best solutions found was 0.233 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "025873a3-152a-4e0c-9e48-8a932f0a8eea", "metadata": {"aucs": [0.7233018205247976, 0.5537720654814188, 0.8557784505394874], "final_y": [0.2578107382717648, 0.2578107997483051, 0.18187979422690792]}, "mutation_prompt": null}
{"id": "e2fb2ff7-3007-4ae0-a99a-65649f91f781", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        return periodic_deviation\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.8)  # Adaptive differential weight\n        CR = np.random.uniform(0.9, 1.0)  # Increased crossover probability for diversity\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved hybrid optimizer using adaptive Differential Evolution with period alignment and population diversity enhancements.", "configspace": "", "generation": 7, "fitness": 0.792380320614626, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.101. And the mean value of best solutions found was 0.226 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "025873a3-152a-4e0c-9e48-8a932f0a8eea", "metadata": {"aucs": [0.6639333451455702, 0.9105928130245201, 0.8026148036737875], "final_y": [0.2918265574548812, 0.16485657059458758, 0.22065054899286218]}, "mutation_prompt": null}
{"id": "6925e6b4-c0fe-4c46-8f93-cd0f9aaa8906", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum(np.abs(x[:period] - x[period:2*period]))  # Modification: Using absolute deviation\n        return periodic_deviation\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.8)  # Adaptive differential weight\n        CR = np.random.uniform(0.9, 1.0)  # Increased crossover probability for diversity\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced hybrid optimizer using adaptive Differential Evolution with improved periodic deviation scoring for better convergence.", "configspace": "", "generation": 8, "fitness": 0.792380320614626, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.101. And the mean value of best solutions found was 0.226 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "e2fb2ff7-3007-4ae0-a99a-65649f91f781", "metadata": {"aucs": [0.6639333451455702, 0.9105928130245201, 0.8026148036737875], "final_y": [0.2918265574548812, 0.16485657059458758, 0.22065054899286218]}, "mutation_prompt": null}
{"id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer integrating adaptive DE with diversity-guided mutation and periodicity-driven local search for superior convergence.", "configspace": "", "generation": 9, "fitness": 0.9438407797761988, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e2fb2ff7-3007-4ae0-a99a-65649f91f781", "metadata": {"aucs": [0.9350168064269916, 0.9426228594618751, 0.9538826734397298], "final_y": [0.16485654456513377, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "ddefd5f4-8e7f-4103-982e-ecc0c9f2bee4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty * 0.5  # Adjusted penalty weight\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score - self.reflectivity_score(trial) > func(self.population[i]):  # Swapped condition\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined adaptive DE using enhanced diversity control and strengthened periodicity constraints for better optimization.", "configspace": "", "generation": 10, "fitness": 0.711698816929526, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.712 with standard deviation 0.025. And the mean value of best solutions found was 0.264 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.7133307296248852, 0.6803284384655346, 0.7414372826981583], "final_y": [0.2578106127726618, 0.28274841328354805, 0.25058996954769275]}, "mutation_prompt": null}
{"id": "bcbecf9f-5ab9-4b50-8979-4b328e005d96", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdvancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        # Symmetric initialization with quasi-oppositional strategy\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposites = lb + ub - self.population\n        self.population = np.vstack((self.population, opposites))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)\n        CR = np.random.uniform(0.7, 1.0)\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(lambda x: func(x) - self.reflectivity_score(x), self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "AdvancedHybridDEOptimizer", "description": "Advanced hybrid optimizer blending adaptive DE with opposition-based learning and periodicity-aware local refinement for enhanced global exploration and local exploitation.", "configspace": "", "generation": 11, "fitness": 0.6052985353875987, "feedback": "The algorithm AdvancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.605 with standard deviation 0.072. And the mean value of best solutions found was 0.320 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6258669468542507, 0.6816053714655148, 0.5084232878430307], "final_y": [0.3162135771313833, 0.2778473141380172, 0.36494607049568517]}, "mutation_prompt": null}
{"id": "75296cd0-5170-4b57-ab48-d26315233e7b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        adaptive_penalty = np.sum(np.abs(x - np.roll(x, period)) ** 1.2)  # Adaptive penalty\n        return periodic_deviation + adaptive_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.7)  # Slightly adjusted differential weight\n        CR = np.random.uniform(0.85, 1.0)  # More consistent crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial) - self.reflectivity_score(trial)  # Adjusted fitness calculation\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved DE algorithm with adaptive periodicity control and targeted diversity enhancement for optimal convergence.", "configspace": "", "generation": 12, "fitness": 0.7980459175991707, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.131. And the mean value of best solutions found was 0.222 (0. is the best) with standard deviation 0.045.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6164739798494507, 0.9187666153300137, 0.8588971576180477], "final_y": [0.28445593510966893, 0.18187853328496906, 0.2004477491026435]}, "mutation_prompt": null}
{"id": "b352971e-05f9-4add-9d30-9a3177675929", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.8)  # Adjusted differential weight\n        CR = np.random.uniform(0.7, 0.9)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined optimizer incorporating adaptive differential weight and crossover probability for enhanced convergence precision.", "configspace": "", "generation": 13, "fitness": 0.8286142030889628, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.109. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.8413351846936653, 0.9553154588088061, 0.6891919657644172], "final_y": [0.20725681107917204, 0.16486099229681694, 0.257810460442896]}, "mutation_prompt": null}
{"id": "221e3086-a8c4-4b55-8fb0-0716bb1b8345", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2) * 0.9  # Fine-tuned penalty factor\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.9)  # Slightly increased lower bound for F\n        CR = np.random.uniform(0.8, 1.0)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined adaptive DE with enhanced population diversity and fine-tuned penalty for improved optimization performance.", "configspace": "", "generation": 14, "fitness": 0.7528444686684471, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.753 with standard deviation 0.119. And the mean value of best solutions found was 0.243 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6582200982212709, 0.6802115827230899, 0.9201017250609803], "final_y": [0.2827472869701664, 0.2827482508451249, 0.16485636505537904]}, "mutation_prompt": null}
{"id": "c2e7b4f1-83a7-47d7-8646-9d0ddbaad0d3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def adaptive_periodicity(self):\n        return np.random.randint(1, self.dim // 2)  # Adaptive periodicity for diversity\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        if self.eval_count % 5 == 0:  # Dynamic interval-based local search\n            result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n            self.eval_count += result.nfev\n\n            if result.fun > self.best_score:\n                self.best_score = result.fun\n                self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer with adaptive periodicity within DE and dynamic local search intervals for improved reflectivity.", "configspace": "", "generation": 15, "fitness": 0.9319869870738037, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.899455428319806, 0.9426228594618751, 0.9538826734397298], "final_y": [0.18188019819725698, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "4d32e72c-e941-40f6-a215-e3545b7cc3df", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive population size for dynamic exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2 \n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2) - np.var(x[:period])\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  \n        CR = np.random.uniform(0.7, 0.95)  # Fine-tuned crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Optimizer leveraging adaptive DE with diversity-enhanced mutation, periodicity-aware local search, and adaptive population size for improved convergence.", "configspace": "", "generation": 16, "fitness": 0.8489764442615871, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.112. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.8856990529427634, 0.9639061208037177, 0.6973241590382804], "final_y": [0.18187881141028517, 0.1648567250329993, 0.20044534812526138]}, "mutation_prompt": null}
{"id": "99a9023c-6495-440f-af1a-be0b0a84f846", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  \n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  \n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.9)  # Adjusted differential weight range\n        CR = np.random.uniform(0.8, 1.0)\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Advanced optimizer incorporating adaptive DE with enhanced mutation strategies and periodicity-aware local fine-tuning for improved convergence.", "configspace": "", "generation": 17, "fitness": 0.7528444686684471, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.753 with standard deviation 0.119. And the mean value of best solutions found was 0.243 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6582200982212709, 0.6802115827230899, 0.9201017250609803], "final_y": [0.2827472869701664, 0.2827482508451249, 0.16485636505537904]}, "mutation_prompt": null}
{"id": "b3e62f3b-6a41-4d38-8762-a6af1f0854bc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n        # Quasi-oppositional initialization\n        opposite_population = lb + ub - self.population\n        self.population = np.vstack((self.population, opposite_population))\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty * 0.5  # Adjusted penalty weight\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size // 2):  # Adjusted for expanded population size\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced hybrid optimizer integrating adaptive DE with quasi-oppositional strategies and improved periodicity enforcement for accelerated convergence.", "configspace": "", "generation": 18, "fitness": 0.7974105613855595, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.230. And the mean value of best solutions found was 0.251 (0. is the best) with standard deviation 0.122.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.47212693635646574, 0.9548728416891713, 0.9652319061110417], "final_y": [0.4239522965175876, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "cc593e48-8983-4d11-a879-115f47623939", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Adjusted population size for balanced exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_population = lb + ub - self.population  # Oppositional initialization\n        self.population = np.vstack((self.population, opposite_population))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        # Regularization to encourage symmetry\n        symmetry_penalty = np.sum((x - x[::-1]) ** 2)\n        return periodic_deviation + symmetry_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Broadened differential weight range\n        CR = np.random.uniform(0.7, 1.0)  # Broadened crossover probability range\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(2 * self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial) - self.reflectivity_score(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(self.population[i]):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Optimizer leveraging adaptive DE with opposition-based learning and symmetry-enforced local refinement for enhanced convergence in multilayer structure optimization.", "configspace": "", "generation": 19, "fitness": 0.8689489670778423, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.101. And the mean value of best solutions found was 0.202 (0. is the best) with standard deviation 0.040.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.7294414499125792, 0.9109070038005632, 0.9664984475203843], "final_y": [0.2578121176850584, 0.18188179442829167, 0.16485793264768223]}, "mutation_prompt": null}
{"id": "50ad13d5-3ed7-4b43-a45b-cda5b3ef1cdd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.8)  # Adjusted differential weight\n        CR = np.random.uniform(0.7, 0.9)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved mutation strategy and enhanced exploration by adjusting DE parameters for better convergence.", "configspace": "", "generation": 20, "fitness": 0.8286142030889628, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.109. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.8413351846936653, 0.9553154588088061, 0.6891919657644172], "final_y": [0.20725681107917204, 0.16486099229681694, 0.257810460442896]}, "mutation_prompt": null}
{"id": "05962477-cdd4-4099-881e-77f094c78e1c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = 0.5 * np.sum((x - np.roll(x, period)) ** 2)  # Adjusted weight for periodicity\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Broader range for differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer with adaptive mutation scaling and weighted periodicity enforcement for improved convergence.", "configspace": "", "generation": 21, "fitness": 0.836749280430526, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.055. And the mean value of best solutions found was 0.206 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9050955467063241, 0.771292213897641, 0.8338600806876125], "final_y": [0.18188296030562845, 0.22804587386033115, 0.20725469324871404]}, "mutation_prompt": null}
{"id": "54dfe9ba-8912-4442-8f6f-8679d3bb3291", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Adjusted differential weight for better adaptation\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            if self.eval_count < self.budget * 0.9:  # More frequent local search\n                self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Optimized DE with adaptive mutation scaling and enhanced local search frequency for improved convergence in complex landscapes.", "configspace": "", "generation": 22, "fitness": 0.836749280430526, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.055. And the mean value of best solutions found was 0.206 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9050955467063241, 0.771292213897641, 0.8338600806876125], "final_y": [0.18188296030562845, 0.22804587386033115, 0.20725469324871404]}, "mutation_prompt": null}
{"id": "f993e13e-5f7c-426c-a790-2e50826fc3f4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved optimizer with adaptive mutation strategy and reflective boundary handling for enhanced solution quality.", "configspace": "", "generation": 23, "fitness": 0.836749280430526, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.055. And the mean value of best solutions found was 0.206 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9050955467063241, 0.771292213897641, 0.8338600806876125], "final_y": [0.18188296030562845, 0.22804587386033115, 0.20725469324871404]}, "mutation_prompt": null}
{"id": "19b26eb0-250d-4168-8a14-56130722e9de", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            trial_score -= self.reflectivity_score(trial) * 0.01 # Increased penalty influence\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved optimizer employing adaptive DE with enhanced periodicity alignment and diversity control for optimized convergence.", "configspace": "", "generation": 24, "fitness": 0.7890430837273463, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.140. And the mean value of best solutions found was 0.230 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.592988853581857, 0.9133535924109359, 0.8607868051892462], "final_y": [0.30863356079078963, 0.18187833209699567, 0.2004457553008112]}, "mutation_prompt": null}
{"id": "6be18f63-b822-4448-8a7c-3d201425ecec", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.95)  # Adjusted differential weight for greater adaptability\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n            # Hybrid crossover strategy incorporating genetic algorithm principles\n            if np.random.rand() < 0.5:\n                trial = (trial + self.population[i]) / 2\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer with adaptive F-values and hybrid DE-GA crossover for improved convergence.", "configspace": "", "generation": 25, "fitness": 0.8564879070871984, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.047. And the mean value of best solutions found was 0.188 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.7923349750137376, 0.8758358925528644, 0.9012928536949931], "final_y": [0.20044503670127156, 0.1818791667329024, 0.18188053095378331]}, "mutation_prompt": null}
{"id": "4aadf7fe-20bc-404f-865f-c86ba166177e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9) * (1 - self.eval_count / self.budget)  # Adjusted differential weight with dynamic scaling\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer integrating adaptive DE with diversity-guided mutation and periodicity-driven local search, leveraging dynamic mutation scaling for superior convergence.", "configspace": "", "generation": 26, "fitness": 0.9319869870738037, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.899455428319806, 0.9426228594618751, 0.9538826734397298], "final_y": [0.18188019819725698, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "c62801b7-1994-443c-94c3-8c53131d5f25", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 1.0)  # Adjusted differential weight for better exploration\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved exploration by adjusting the mutation strategy and enhancing periodicity encouragement in differential evolution.", "configspace": "", "generation": 27, "fitness": 0.6321961759236953, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.632 with standard deviation 0.103. And the mean value of best solutions found was 0.314 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.5459405179518333, 0.776619021995428, 0.5740289878238248], "final_y": [0.36657852897993415, 0.2280457451876614, 0.3487761692045166]}, "mutation_prompt": null}
{"id": "90eb883d-d98f-452e-b9c7-8f14db7c059b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        adaptive_bounds = np.c_[lb + 0.1 * (ub - lb), ub - 0.1 * (ub - lb)]  # Modified bounds for local search\n        result = minimize(func, self.best_solution, bounds=adaptive_bounds, method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved exploration and convergence through dynamic parameter tuning and targeted local search.", "configspace": "", "generation": 28, "fitness": 0.820818774157169, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.017. And the mean value of best solutions found was 0.209 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.7985688268984636, 0.8229956603046712, 0.8408918352683716], "final_y": [0.2089075974169673, 0.208908466351427, 0.2089082176771978]}, "mutation_prompt": null}
{"id": "7d663a79-5155-46d6-a884-b86e905eb814", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_penalty = np.sum((x[:period] - x[period:2*period]) ** 2)\n        return periodic_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 1.0)  # Adjusted differential weight\n        CR = np.random.uniform(0.7, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def hybrid_search(self, func, lb, ub):\n        if self.eval_count < self.budget * 0.8:\n            self.differential_evolution(func, lb, ub)\n        else:\n            result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n            self.eval_count += result.nfev\n            if result.fun > self.best_score:\n                self.best_score = result.fun\n                self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.hybrid_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer with adaptive DE, diversity-driven mutation, periodicity constraints, and hybrid local-global search for improved convergence on multilayer designs.", "configspace": "", "generation": 29, "fitness": 0.5301870749217743, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.530 with standard deviation 0.036. And the mean value of best solutions found was 0.374 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.5776040995657886, 0.4902299868182117, 0.5227271383813227], "final_y": [0.34713384093823274, 0.3982071075043223, 0.37610630843027393]}, "mutation_prompt": null}
{"id": "ccbad37a-919d-43a2-8912-26376d954679", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            trial_combined_score = trial_score - self.reflectivity_score(trial)\n            self.eval_count += 1\n\n            if trial_combined_score > func(self.population[i]) - self.reflectivity_score(self.population[i]):\n                self.population[i] = trial\n\n            if trial_combined_score > self.best_score:\n                self.best_score = trial_combined_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined optimizer enhancing DE's exploration with stochastic ranking for better balance between diversity and periodicity.", "configspace": "", "generation": 30, "fitness": 0.8047775127664664, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.119. And the mean value of best solutions found was 0.231 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.639177374158681, 0.9133535924109359, 0.8618015717297822], "final_y": [0.30958494639597856, 0.18187833209699567, 0.2004457553008112]}, "mutation_prompt": null}
{"id": "fa8fdda9-9427-44a4-91da-f1b814528366", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score * 1.01  # Apply a slight boost to trial score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer with adaptive scaling and strategic mutation for improved convergence and solution quality.", "configspace": "", "generation": 31, "fitness": 0.6607357001062338, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.661 with standard deviation 0.024. And the mean value of best solutions found was 0.292 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6754460194207286, 0.6803271439357597, 0.6264339369622134], "final_y": [0.28274759588661014, 0.2827492635213449, 0.3100464350321789]}, "mutation_prompt": null}
{"id": "0bfb776b-b962-47b6-8283-82e8dd532d12", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.4, 0.9)  # Adjusted differential weight for more diversity\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced DE optimizer leveraging adaptive mutation scaling and targeted exploration for improved convergence.", "configspace": "", "generation": 32, "fitness": 0.7759460735593843, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.776 with standard deviation 0.114. And the mean value of best solutions found was 0.238 (0. is the best) with standard deviation 0.054.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6677453891743887, 0.7263966609147118, 0.9336961705890523], "final_y": [0.29182858443580284, 0.2578108577146653, 0.16486120142239447]}, "mutation_prompt": null}
{"id": "75384f81-6008-44d7-b538-f91d4025b9b3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c) * (1 - self.eval_count/self.budget), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined EnhancedHybridDEOptimizer by incorporating adaptive mutation scaling for improved local exploitation and convergence.", "configspace": "", "generation": 33, "fitness": 0.8532293894076233, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.096. And the mean value of best solutions found was 0.196 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.8832257040349458, 0.7240532921689868, 0.9524091720189372], "final_y": [0.16485601162256214, 0.25781025561822113, 0.16485742150235283]}, "mutation_prompt": null}
{"id": "5a645977-d365-44c4-bca2-6ed18b5b9fdd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.85, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B', options={'ftol': 1e-9})\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved optimizer by refining differential evolution parameters and enhancing local search precision.", "configspace": "", "generation": 34, "fitness": 0.7278660607425538, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.728 with standard deviation 0.152. And the mean value of best solutions found was 0.257 (0. is the best) with standard deviation 0.094.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.5138500216094513, 0.8540055723999446, 0.8157425882182652], "final_y": [0.3900956074910734, 0.20044514711083505, 0.1818793132415223]}, "mutation_prompt": null}
{"id": "0fed19e2-c26c-4604-aa9a-9adb130c1314", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.7)  # Adjusted differential weight for better convergence\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial) - self.reflectivity_score(trial)  # Penalize non-symmetrical layers\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved DE optimizer using adaptive mutation factor and layer symmetry enforcement for enhanced solution quality.", "configspace": "", "generation": 35, "fitness": 0.8013662604666579, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.132. And the mean value of best solutions found was 0.222 (0. is the best) with standard deviation 0.045.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6164319551242967, 0.9187666153300137, 0.8689002109456637], "final_y": [0.28445593510966893, 0.18187853328496906, 0.2004477491026435]}, "mutation_prompt": null}
{"id": "0df078b1-f288-45e6-9400-7454a5d9aab4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        initial_step = (ub - lb) * 0.01  # Added adaptive scaling factor for local search\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B', options={'maxiter': 50})\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined hybrid optimizer with adaptive local search scaling for enhanced convergence efficiency.", "configspace": "", "generation": 36, "fitness": 0.9438407797761988, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9350168064269916, 0.9426228594618751, 0.9538826734397298], "final_y": [0.16485654456513377, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "b6e75636-7a19-4ef4-aaa5-4a025f36debc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c + np.random.uniform(-0.1, 0.1, self.dim)), lb, ub)  # Adaptive mutation\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved optimizer by incorporating adaptive mutation strategy and diversity retention for enhanced exploration and convergence.", "configspace": "", "generation": 37, "fitness": 0.8781783943672741, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.025. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.8926610424070749, 0.8987097103114355, 0.8431644303833121], "final_y": [0.1818791268302261, 0.18187967480728628, 0.18188038528018746]}, "mutation_prompt": null}
{"id": "b4214fed-61cc-41a7-b429-0e7bdb43cd81", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Adjusted differential weight for better balance\n        CR = np.random.uniform(0.85, 1.0)  # Modified crossover probability for enhanced exploration\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced DE optimizer with adaptive crossover and mutation parameters for improved landscape navigation and solution refinement.", "configspace": "", "generation": 38, "fitness": 0.8593937998145004, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.062. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9050955467063241, 0.771292213897641, 0.9017936388395358], "final_y": [0.18188296030562845, 0.22804587386033115, 0.18188026071567476]}, "mutation_prompt": null}
{"id": "90d18e50-c017-489f-bb06-886b86d29462", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.7, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced Hybrid DE with dynamic parameter tuning and improved periodicity constraint for better performance.", "configspace": "", "generation": 39, "fitness": 0.708196986568646, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.708 with standard deviation 0.166. And the mean value of best solutions found was 0.282 (0. is the best) with standard deviation 0.093.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9051057008312392, 0.7205892538504071, 0.498896005024292], "final_y": [0.18188296030562845, 0.2578103337734573, 0.4051421831226424]}, "mutation_prompt": null}
{"id": "7e4338fd-5019-4ea9-b1c2-bc3f8498a146", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Adjusted differential weight for dynamic exploration\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced population diversity using orthogonal initialization and dynamic mutation rate for improved convergence.", "configspace": "", "generation": 40, "fitness": 0.836749280430526, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.055. And the mean value of best solutions found was 0.206 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9050955467063241, 0.771292213897641, 0.8338600806876125], "final_y": [0.18188296030562845, 0.22804587386033115, 0.20725469324871404]}, "mutation_prompt": null}
{"id": "ce3069cc-66fc-4cbf-abfa-38a991d3b1c0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = max(self.dim // 2, 1)  # Dynamic period adjustment for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 1.0)  # Boosted mutation diversity\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined DE with boosted mutation diversity and dynamic period adjustment for optimal convergence.", "configspace": "", "generation": 41, "fitness": 0.6973851279554996, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.697 with standard deviation 0.102. And the mean value of best solutions found was 0.222 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6967042435687513, 0.8231169869302428, 0.5723341533675048], "final_y": [0.18188108942666625, 0.2004469047868238, 0.28274698406183785]}, "mutation_prompt": null}
{"id": "ebe4ab8c-d7bb-491e-a1af-11ccbd6f99b9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass ImprovedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Adaptive differential weight\n        CR = np.random.uniform(0.7, 0.95)  # Adjusted crossover probability\n        dynamic_population_size = max(4, int(self.initial_population_size * (1 - self.eval_count / self.budget)))\n\n        for i in range(dynamic_population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(dynamic_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            periodic_score = self.enforce_periodicity(trial)\n\n            if trial_score + periodic_score > func(self.population[i]):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def enforce_periodicity(self, solution):\n        period = self.dim // 2\n        periodicity_penalty = np.sum((solution[:period] - solution[period:period*2]) ** 2)\n        return -periodicity_penalty\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "ImprovedHybridDEOptimizer", "description": "Improved Adaptive Differential Evolution with Dynamic Population and Periodicity-Encouraged Mutation for Enhanced Convergence in Black Box Optimization.", "configspace": "", "generation": 42, "fitness": 0.8729118914313654, "feedback": "The algorithm ImprovedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.102. And the mean value of best solutions found was 0.185 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9357167972484679, 0.9536410531647976, 0.7293778238808306], "final_y": [0.16485616363956712, 0.16485694494011793, 0.2254196194156548]}, "mutation_prompt": null}
{"id": "e2b261b5-a708-4641-a8f7-c5fd80f75ff4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.clip(np.random.normal(0.75, 0.05), 0.6, 0.9)  # Adjusted differential weight\n        CR = np.clip(np.random.normal(0.9, 0.05), 0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer integrating adaptive DE with diversity-guided mutation, periodicity-driven local search, and dynamic parameter adjustment for improved convergence.", "configspace": "", "generation": 43, "fitness": 0.8226517985866062, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.093. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.7932980816815581, 0.7256934301797056, 0.9489638838985548], "final_y": [0.20725817836471794, 0.2578102720147909, 0.16485693128228673]}, "mutation_prompt": null}
{"id": "dc71eecb-d3d4-48cc-9050-01f74a933994", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass MultiPhaseHybridPSOOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim  # Swarm size to balance exploration and convergence\n        self.population = None\n        self.velocities = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n\n    def initialize_swarm(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        self.best_solution = self.population[0]\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.swarm_size, float('-inf'))\n\n    def update_velocities(self, global_best, w=0.5, c1=1.5, c2=1.5):\n        r1 = np.random.rand(self.swarm_size, self.dim)\n        r2 = np.random.rand(self.swarm_size, self.dim)\n        cognitive_component = c1 * r1 * (self.personal_best_positions - self.population)\n        social_component = c2 * r2 * (global_best - self.population)\n        self.velocities = w * self.velocities + cognitive_component + social_component\n\n    def apply_periodicity_penalty(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def local_refinement(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.eval_count < self.budget:\n            for i in range(self.swarm_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], lb, ub)\n                score = func(self.population[i]) - self.apply_periodicity_penalty(self.population[i])\n                self.eval_count += 1\n\n                if score > self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.population[i]\n\n                if score > self.best_score:\n                    self.best_score = score\n                    self.best_solution = self.population[i]\n\n            global_best = self.population[np.argmax(self.personal_best_scores)]\n            self.update_velocities(global_best)\n\n            if self.eval_count < self.budget / 2:\n                self.local_refinement(func, lb, ub)\n\n        return self.best_solution", "name": "MultiPhaseHybridPSOOptimizer", "description": "Multi-phase hybrid PSO algorithm combining global exploration with periodicity-driven local intensification for optimizing multilayer structures.", "configspace": "", "generation": 44, "fitness": 0.7503503735096585, "feedback": "The algorithm MultiPhaseHybridPSOOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.750 with standard deviation 0.184. And the mean value of best solutions found was 0.268 (0. is the best) with standard deviation 0.088.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9822227735149979, 0.7354560928958791, 0.5333722541180983], "final_y": [0.1648579961800185, 0.25781056335636743, 0.3803757998822157]}, "mutation_prompt": null}
{"id": "1a5ce663-9e9f-4d86-9d97-1433f79f1da9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  \n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + 0.5 * deviation_penalty  # Adjust penalty weight\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  \n        CR = np.random.uniform(0.8, 1.0)  \n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer with dynamic periodicity adaptation and diversity maintenance for improved convergence.", "configspace": "", "generation": 45, "fitness": 0.9438407797761988, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9350168064269916, 0.9426228594618751, 0.9538826734397298], "final_y": [0.16485654456513377, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "c1a0af47-66d6-45ec-9027-e4e10b317ecc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdvancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 14 * dim  # Further increased population size for extensive exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.95)  # Enhanced differential weight for better exploration\n        CR = np.random.uniform(0.85, 1.0)  # Enhanced crossover probability\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            # Improved score comparison to include periodicity\n            if trial_score > func(self.population[i]) + self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "AdvancedHybridDEOptimizer", "description": "Advanced Hybrid DE with Adaptive Periodicity and Comprehensive Diversity Control for Optimized Convergence.", "configspace": "", "generation": 46, "fitness": 0.7176701885385443, "feedback": "The algorithm AdvancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.718 with standard deviation 0.142. And the mean value of best solutions found was 0.226 (0. is the best) with standard deviation 0.048.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.519358758227128, 0.8415132443365309, 0.7921385630519739], "final_y": [0.2827476153681545, 0.16641995269653376, 0.2280467466586692]}, "mutation_prompt": null}
{"id": "dd2d24d1-4035-4388-b302-97171b8a2d48", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        periodic_constraint = lambda x: np.sum((x[:self.dim//2] - x[self.dim//2:])**2)\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B', constraints={'type': 'eq', 'fun': periodic_constraint})\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improves convergence by dynamically adjusting population size and emphasizing periodicity in local search.", "configspace": "", "generation": 47, "fitness": 0.9438407797761988, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9350168064269916, 0.9426228594618751, 0.9538826734397298], "final_y": [0.16485654456513377, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "148d60e1-345a-458a-8caf-b2d6fb9555a1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        # Modify initialization to involve a periodic strategy\n        period = self.dim // 2\n        base_layer = np.random.uniform(lb, ub, period)\n        self.population = np.array([np.tile(base_layer, 2) for _ in range(self.population_size)])\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer integrates adaptive DE with diversity-guided mutation, periodicity-driven local search, and a periodic initialization strategy for improved performance.", "configspace": "", "generation": 48, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (5,) and arg 1 with shape (10,).').", "error": "ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (5,) and arg 1 with shape (10,).')", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {}, "mutation_prompt": null}
{"id": "9e283d1a-919a-4e5d-bee7-83d7d2fc4608", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.85, 1.0)  # Fine-tuned crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.normal(F, 0.01) * (b - c), lb, ub)  # Adaptive mutation\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved EnhancedHybridDEOptimizer by fine-tuning crossover probability and introducing adaptive mutation strategy for enhanced exploration-exploitation balance.", "configspace": "", "generation": 49, "fitness": 0.6201781672596546, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.620 with standard deviation 0.089. And the mean value of best solutions found was 0.319 (0. is the best) with standard deviation 0.054.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6340022398670755, 0.5049133622296057, 0.7216188996822825], "final_y": [0.30958370880378905, 0.3900972451416884, 0.25781322256278993]}, "mutation_prompt": null}
{"id": "6d9dd9e5-d4b7-448d-bb38-a6a3b2111e47", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMemoryEnhancedOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.archive_size = int(0.2 * self.population_size)  # Archive for memory-enhanced learning\n        self.population = None\n        self.archive = []\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def adaptive_mutation(self, a, b, c, lb, ub):\n        F = np.random.uniform(0.5, 0.7)\n        mutant = np.clip(a + F * (b - c), lb, ub)\n        return mutant\n\n    def coevolutionary_update(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = self.adaptive_mutation(a, b, c, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < 0.9\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial_score = func(trial) - self.reflectivity_score(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]):\n                self.population[i] = trial\n                if trial_score > self.best_score:\n                    self.best_score = trial_score\n                    self.best_solution = trial\n\n        self.update_archive()\n\n    def update_archive(self):\n        sorted_population = sorted(self.population, key=lambda x: func(x), reverse=True)\n        self.archive = sorted_population[:self.archive_size]\n\n    def archive_based_local_search(self, func, lb, ub):\n        for solution in self.archive:\n            if self.eval_count >= self.budget:\n                break\n\n            result = minimize(func, solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n            self.eval_count += result.nfev\n\n            if result.fun > self.best_score:\n                self.best_score = result.fun\n                self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.coevolutionary_update(func, lb, ub)\n            self.archive_based_local_search(func, lb, ub)\n\n        return self.best_solution", "name": "AdaptiveMemoryEnhancedOptimizer", "description": "Adaptive Memory-Enhanced Coevolutionary Algorithm leveraging archive-based learning and periodicity-enforced mutation for efficient exploration and exploitation.", "configspace": "", "generation": 50, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {}, "mutation_prompt": null}
{"id": "5452a5ac-3c8a-48a6-9ff6-91e4747c3a4f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.95)  # Adjusted differential weight for better mutation\n        CR = 0.85  # Fixed crossover probability for consistency\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Optimized DE strategy with adaptive periodic mutation and enhanced local search balance for improved convergence.", "configspace": "", "generation": 51, "fitness": 0.7903577658380921, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.130. And the mean value of best solutions found was 0.213 (0. is the best) with standard deviation 0.068.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.7809163909569242, 0.9546505171576118, 0.6355063893997401], "final_y": [0.16485925414918057, 0.16485703386351236, 0.30958603110360483]}, "mutation_prompt": null}
{"id": "f5f11fda-569b-45ab-b45d-b307a7da3ee6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.7, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR + 0.1  # Slight increase in crossover probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer fine-tuning randomization and crossover in DE for optimal convergence.", "configspace": "", "generation": 52, "fitness": 0.8773295042235238, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.079. And the mean value of best solutions found was 0.192 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9050955467063241, 0.770281646905826, 0.9566113190584218], "final_y": [0.18188296030562845, 0.22804587386033115, 0.16485701713429324]}, "mutation_prompt": null}
{"id": "231eb277-5b8f-4d4f-92cb-0c337918ab31", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population = np.vstack((self.population, 1.0 / self.population))  # Quasi-Oppositional\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.8)  # Slightly reduced F for more control\n        CR = np.random.uniform(0.7, 0.9)  # Reduced crossover range\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if (trial_score + self.reflectivity_score(trial)) > (func(self.population[i]) + self.reflectivity_score(self.population[i])):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved hybrid optimizer blending Quasi-Oppositional DE with adaptive learning and modular search for enhanced convergence.", "configspace": "", "generation": 53, "fitness": 0.8087267266077292, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.107. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9274085456692358, 0.6687512716904652, 0.8300203624634866], "final_y": [0.16485919696504103, 0.25781117223009065, 0.20725515223990099]}, "mutation_prompt": null}
{"id": "cbf21eac-2170-4f1d-bf7a-bdc0aa23e556", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - np.roll(x, period)[:period]) ** 2)  # Adjusted to improve periodicity\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.8)  # Adjusted differential weight\n        CR = np.random.uniform(0.85, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved exploration and periodicity handling by adjusting DE parameters and the periodic deviation function for better convergence.", "configspace": "", "generation": 54, "fitness": 0.6602408932458238, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.660 with standard deviation 0.035. And the mean value of best solutions found was 0.290 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6639333451455702, 0.6160750746580939, 0.7007142599338072], "final_y": [0.2918265574548812, 0.31933096917531667, 0.25781099952276554]}, "mutation_prompt": null}
{"id": "0120afcf-1c70-4c2d-a154-4fa1ee72ee73", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        # Calculate diversity to adjust F and CR\n        diversity = np.mean(np.std(self.population, axis=0))\n        F = 0.5 + 0.4 * diversity  # Dynamic F based on diversity\n        CR = 0.7 + 0.3 * diversity  # Dynamic CR based on diversity\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved adaptive DE with dynamic crossover and mutation rates based on population diversity for enhanced convergence.", "configspace": "", "generation": 55, "fitness": 0.7405785574645528, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.741 with standard deviation 0.069. And the mean value of best solutions found was 0.252 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.7246137184660487, 0.6649240785694798, 0.8321978753581298], "final_y": [0.2578103117437339, 0.291828258689545, 0.20725500285549103]}, "mutation_prompt": null}
{"id": "59b38119-c2dc-4cd4-a7c5-1baed496533b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2) * 0.5  # Adjusted penalty scaling\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.9)  # Refined differential weight range\n        CR = np.random.uniform(0.7, 1.0)  # Refined crossover probability range\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved optimizer using adaptive control mechanisms in DE parameters and enhanced periodicity constraints for superior solution quality.", "configspace": "", "generation": 56, "fitness": 0.7108078856185477, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.711 with standard deviation 0.155. And the mean value of best solutions found was 0.277 (0. is the best) with standard deviation 0.086.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.8934399394380984, 0.5144823375290386, 0.7245013798885063], "final_y": [0.1818787065714731, 0.39009546329623546, 0.25781128381667395]}, "mutation_prompt": null}
{"id": "7e5cf8bc-686e-4904-b4d0-3d3154cc342b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        # Use symmetric initialization to enhance exploration\n        mid = (lb + ub) / 2\n        self.population = np.vstack([np.random.uniform(lb, ub, (self.population_size//2, self.dim)),\n                                     mid + np.random.uniform(lb - mid, ub - mid, (self.population_size//2, self.dim))])\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return 0.5 * (periodic_deviation + deviation_penalty)  # Adjusted for better periodicity\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced DE optimizer with dynamic periodicity consideration and improved initialization for better convergence.", "configspace": "", "generation": 57, "fitness": 0.9438407570682162, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9350167383030439, 0.9426228594618751, 0.9538826734397298], "final_y": [0.16485649072302966, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "34f3ba62-eaf0-49e2-8361-aa7557ec32a7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        # Added dynamic population scaling\n        self.population_size = max(4 * self.dim, int(self.population_size * 0.98))\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer integrating adaptive DE with diversity-guided mutation, periodicity-driven local search, and dynamic population scaling for superior convergence.", "configspace": "", "generation": 58, "fitness": 0.7908533560165959, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.062. And the mean value of best solutions found was 0.205 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.8774285947152897, 0.759327250146984, 0.735804223187514], "final_y": [0.16485736615624347, 0.24257615431754076, 0.20725479813954573]}, "mutation_prompt": null}
{"id": "44679801-559f-4b85-84e1-8d0b69e1084b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + 0.5 * deviation_penalty  # Tweak penalty scaling\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)\n        CR = np.random.uniform(0.8, 1.0)\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined optimizer leveraging adaptive DE with enhanced periodicity constraint and diversity-driven mutation for improved convergence.", "configspace": "", "generation": 59, "fitness": 0.9438407797761988, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9350168064269916, 0.9426228594618751, 0.9538826734397298], "final_y": [0.16485654456513377, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "9bd3f95c-8772-4373-8dda-906840c1fb85", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        adaptive_CR = CR * (1 - self.eval_count / self.budget)  # Dynamic crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < adaptive_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "An enhanced optimizer integrating adaptive DE with diversity-guided mutation, periodicity-driven local search, and dynamic parameter adaptation for improved convergence.", "configspace": "", "generation": 60, "fitness": 0.9319869870738037, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.899455428319806, 0.9426228594618751, 0.9538826734397298], "final_y": [0.18188019819725698, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "8615021d-0e35-46f1-9680-f400f47abbab", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.8)  # Adjusted differential weight\n        CR = np.random.uniform(0.85, 0.95)  # Narrowed crossover probability range\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='BFGS')  # Changed method\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Optimized DE algorithm with adaptive local search and enhanced periodicity constraint for better convergence.", "configspace": "", "generation": 61, "fitness": 0.5623524519561794, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.562 with standard deviation 0.055. And the mean value of best solutions found was 0.336 (0. is the best) with standard deviation 0.057.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.5163413534351732, 0.53101743122025, 0.6396985712131152], "final_y": [0.390097810998257, 0.3612540269969291, 0.25781436616841846]}, "mutation_prompt": null}
{"id": "4f705014-92ff-4c85-b210-70d7fe304748", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)\n        CR = np.random.uniform(0.7, 1.0)  # Modified crossover probability for better diversity\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c) + 0.1 * (self.best_solution - a), lb, ub)  # Improved mutation strategy\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B', options={'maxiter': 10})  # Limited number of iterations\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved EnhancedHybridDEOptimizer by refining mutation strategy and local search for enhanced periodicity and convergence.", "configspace": "", "generation": 62, "fitness": 0.7135657758758819, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.714 with standard deviation 0.066. And the mean value of best solutions found was 0.231 (0. is the best) with standard deviation 0.063.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.7586371515451297, 0.7618927306965095, 0.6201674453860068], "final_y": [0.16504866348282843, 0.2122730888031995, 0.3150732465650663]}, "mutation_prompt": null}
{"id": "4405c4c2-6e40-4cf3-bde1-8593f5f9df03", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.8)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial) - self.reflectivity_score(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined optimizer modifying mutation strategy and improving trial solution selection for enhanced convergence.", "configspace": "", "generation": 63, "fitness": 0.7974610233736291, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.137. And the mean value of best solutions found was 0.225 (0. is the best) with standard deviation 0.048.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6058684811655706, 0.9192372337646922, 0.8672773551906248], "final_y": [0.2913979296466752, 0.18187835640887673, 0.2004455099767567]}, "mutation_prompt": null}
{"id": "19c508b5-5332-4158-b7ec-c5f27de0d0d2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Keep increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            # Preferential mutation towards periodic solutions\n            r = np.random.rand()\n            if r < 0.5:\n                mutant = np.clip(a + F * (b - c), lb, ub)\n            else:\n                avg_periodic = (a[:self.dim//2] + b[:self.dim//2]) / 2\n                avg_periodic = np.tile(avg_periodic, int(self.dim / len(avg_periodic)))\n                mutant = np.clip(avg_periodic, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer with adaptive population size and preferential periodic mutation to improve convergence in multilayer optimization.", "configspace": "", "generation": 64, "fitness": 0.879989424179175, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.046. And the mean value of best solutions found was 0.184 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.8352096272376381, 0.943607545741554, 0.8611510995583329], "final_y": [0.1813555788105461, 0.16485759926856125, 0.20435369240195]}, "mutation_prompt": null}
{"id": "35fb07b4-456c-480f-a520-5bab0bffe55a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        midpoint = (lb + ub) / 2\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.population[:self.population_size // 2] = midpoint  # Adaptive initialization\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c) + self.reflectivity_score(a - b), lb, ub)  # Refined mutation\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer with adaptive initialization and periodicity-based mutation refinement for improved convergence efficiency.", "configspace": "", "generation": 65, "fitness": 0.7347183228760571, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.735 with standard deviation 0.070. And the mean value of best solutions found was 0.255 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.8333304007227519, 0.6852322578158162, 0.6855923100896033], "final_y": [0.21446109122540358, 0.2749574372436179, 0.2749577098945679]}, "mutation_prompt": null}
{"id": "9dec7294-c51d-4df2-a417-cbcf8cc543f1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.95)  # Slightly increased lower limit for differential weight\n        CR = np.random.uniform(0.85, 1.0)  # Slightly increased lower limit for crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer by introducing adaptive tuning of differential weight and crossover probability for better balance between exploration and exploitation.", "configspace": "", "generation": 66, "fitness": 0.7046210229032733, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.705 with standard deviation 0.123. And the mean value of best solutions found was 0.237 (0. is the best) with standard deviation 0.053.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6006313470570444, 0.8768994406387889, 0.6363322810139866], "final_y": [0.22064935912777495, 0.18188334970101816, 0.30958603110360483]}, "mutation_prompt": null}
{"id": "9e20f174-4406-4512-8ce8-86f11e6f925b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 4)  # Change 1: 2 to 4 for stronger penalty\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.95)  # Change 2: Adjusted range of F\n        CR = np.random.uniform(0.85, 1.0)  # Change 3: Modified range of CR\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Optimized EnhancedHybridDEOptimizer with adaptive parameters and improved periodicity enforcement for enhanced convergence.", "configspace": "", "generation": 67, "fitness": 0.7046210229032733, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.705 with standard deviation 0.123. And the mean value of best solutions found was 0.237 (0. is the best) with standard deviation 0.053.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6006313470570444, 0.8768994406387889, 0.6363322810139866], "final_y": [0.22064935912777495, 0.18188334970101816, 0.30958603110360483]}, "mutation_prompt": null}
{"id": "e6285075-b5fa-41ce-b91d-3df502ef827b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            # Enhanced diversity with scaled learning factor\n            mutant = np.clip(a + F * (b - c) + np.random.uniform(0, 0.1, self.dim) * (self.best_solution - a), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined optimizer integrating adaptive DE with enhanced diversity-guided mutation and periodicity-driven local search for superior convergence.", "configspace": "", "generation": 68, "fitness": 0.5690221017822287, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.569 with standard deviation 0.051. And the mean value of best solutions found was 0.336 (0. is the best) with standard deviation 0.045.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.502784028483544, 0.577064064785289, 0.6272182120778529], "final_y": [0.3982379571682946, 0.31933312749300646, 0.2918267382393034]}, "mutation_prompt": null}
{"id": "e4c8c281-2b40-4830-8074-1addef896782", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 14 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            if self.eval_count % (self.budget // 10) == 0:  # Reduced frequency of local search\n                self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced hybrid optimizer with adjusted population size and local search frequency for improved convergence.", "configspace": "", "generation": 69, "fitness": 0.5202741818458881, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.520 with standard deviation 0.015. And the mean value of best solutions found was 0.367 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.5288499318010789, 0.49924431124955115, 0.5327283024870343], "final_y": [0.38011644992689797, 0.3617536070655576, 0.3584372940273247]}, "mutation_prompt": null}
{"id": "d8b54d96-a5d6-452a-9eb4-e0f2579c787d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = 0.8 + 0.2 * (1 - self.eval_count / self.budget)  # Dynamic crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improves exploration and exploitation balance by dynamically adjusting crossover probability based on evaluation count.", "configspace": "", "generation": 70, "fitness": 0.7614880715423876, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.761 with standard deviation 0.112. And the mean value of best solutions found was 0.236 (0. is the best) with standard deviation 0.059.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6038864060710982, 0.8527443441032347, 0.8278334644528299], "final_y": [0.3193308219804344, 0.20044512522514468, 0.18813125822959476]}, "mutation_prompt": null}
{"id": "c5edb5d5-3670-403a-96bb-f7b25279bebb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            periodic_bias = (b + np.roll(b, self.dim // 2)) / 2\n            mutant = np.clip(a + F * (periodic_bias - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined optimizer leveraging adaptive DE with periodicity-biased mutation and hybrid local search for enhanced convergence.", "configspace": "", "generation": 71, "fitness": 0.6556067713610321, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.656 with standard deviation 0.098. And the mean value of best solutions found was 0.302 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.7217310579705962, 0.7274394961189297, 0.5176497599935702], "final_y": [0.25781274142118493, 0.2578103206068909, 0.3900957006710233]}, "mutation_prompt": null}
{"id": "b8eba0a9-3fef-4efe-8b61-45461a5912db", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)\n        CR = np.random.uniform(0.8, 1.0)\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            diversity_factor = 1 - (np.std(self.population, axis=0).mean() / (ub - lb).mean())\n            adjusted_score = trial_score - self.reflectivity_score(trial) * diversity_factor\n            \n            if trial_score > func(self.population[i]) - adjusted_score:\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined DE optimizer leveraging diversity maintenance and adaptive local search for enhanced convergence.", "configspace": "", "generation": 72, "fitness": 0.711698816929526, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.712 with standard deviation 0.025. And the mean value of best solutions found was 0.264 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.7133307296248852, 0.6803284384655346, 0.7414372826981583], "final_y": [0.2578106127726618, 0.28274841328354805, 0.25058996954769275]}, "mutation_prompt": null}
{"id": "7b75b770-f6bf-404c-8142-314b48100478", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(14 * dim)  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B', options={'gtol': 1e-7})\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced DE with adaptive population size and gradient-boosted local search for improved convergence on multi-modal landscapes.", "configspace": "", "generation": 73, "fitness": 0.7451152252499348, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.745 with standard deviation 0.128. And the mean value of best solutions found was 0.233 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.8483223464488862, 0.8228160299611771, 0.5642072993397411], "final_y": [0.20044491373944395, 0.20725426917865597, 0.2918265002358039]}, "mutation_prompt": null}
{"id": "2af424d6-ac49-4e55-be3e-0e7eac23f738", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[-period:]) ** 2)  # Replaced range to start from end\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)\n        CR = np.random.uniform(0.8, 1.0)\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial) - self.reflectivity_score(trial)  # Adjusted score computation\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(self.population[i]):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(lambda x: func(x) - self.reflectivity_score(x), self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')  # Refined search\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Optimized DE with enhanced periodic evaluation and adaptive local search for improved reflectivity convergence.", "configspace": "", "generation": 74, "fitness": 0.5630922117991056, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.563 with standard deviation 0.008. And the mean value of best solutions found was 0.338 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.5578147901666706, 0.5743807089637281, 0.5570811362669184], "final_y": [0.3629218327534609, 0.28622667243576283, 0.3642744723154381]}, "mutation_prompt": null}
{"id": "802958d0-35af-432a-9b04-df5d37694fb2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 1.0)  # Adaptive differential weight\n        CR = np.random.uniform(0.7, 1.0)  # Enhanced crossover probability\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved optimizer by incorporating adaptive control parameters and refined periodicity enforcement for enhanced search efficiency.", "configspace": "", "generation": 75, "fitness": 0.8515348672725853, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.049. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9020113099108851, 0.8671279620673459, 0.7854653298395247], "final_y": [0.18188097025716843, 0.18187984162164827, 0.22804829598108645]}, "mutation_prompt": null}
{"id": "4a71d096-a106-480e-a321-862851874f79", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.8)  # Adjusted differential weight\n        CR = np.random.uniform(0.85, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Optimized hybrid DE with adaptive mutation and enhanced local periodicity enforcement for superior convergence in multilayer photonic structure optimization.", "configspace": "", "generation": 76, "fitness": 0.6602408932458238, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.660 with standard deviation 0.035. And the mean value of best solutions found was 0.290 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6639333451455702, 0.6160750746580939, 0.7007142599338072], "final_y": [0.2918265574548812, 0.31933096917531667, 0.25781099952276554]}, "mutation_prompt": null}
{"id": "ce38ccc9-f9eb-4b74-8da0-7f2ff3c58714", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            phi = np.random.uniform(0, 2 * np.pi, self.dim)\n            superposed_state = np.where(np.random.rand(self.dim) < 0.5,\n                                        self.population[i] * np.cos(phi),\n                                        self.population[i] * np.sin(phi))\n            self.population[i] = np.clip(superposed_state, lb, ub)\n\n    def quantum_entanglement(self, func):\n        entangled_pop = np.zeros_like(self.population)\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            partner_idx = np.random.randint(self.population_size)\n            partner = self.population[partner_idx]\n            entangled_pop[i] = 0.5 * (self.population[i] + partner)  # Simple entanglement\n            score = func(entangled_pop[i])\n            self.eval_count += 1\n            \n            if score > self.best_score:\n                self.best_score = score\n                self.best_solution = entangled_pop[i]\n\n        self.population = entangled_pop\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.quantum_superposition()\n            self.quantum_entanglement(func)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "QuantumInspiredEA", "description": "Quantum-Inspired Evolutionary Algorithm (QIEA) using quantum superposition and entanglement principles to enhance search diversity and convergence in black-box optimization.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'lb' is not defined\").", "error": "NameError(\"name 'lb' is not defined\")", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {}, "mutation_prompt": null}
{"id": "b42f7abe-8dba-4490-a893-e43394d7d5ba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = 0.5 + 0.4 * (self.eval_count / self.budget)  # Adaptive differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer with adaptive mutation factor and periodicity-enhanced crossover for robust convergence. ", "configspace": "", "generation": 78, "fitness": 0.8565436983709693, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.063. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9160734236166038, 0.7687182870180282, 0.8848393844782757], "final_y": [0.16485643458724553, 0.22064951829370516, 0.18813225723399107]}, "mutation_prompt": null}
{"id": "f131e1ca-559d-4f14-8984-894628c895ad", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + 0.5 * deviation_penalty  # Adjusted penalty weight\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Expanded differential weight range\n        CR = np.random.uniform(0.85, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced hybrid optimizer using adaptive DE with periodicity-aware local search and diversity-enhancing mutations for improved convergence.", "configspace": "", "generation": 79, "fitness": 0.8593937998145004, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.062. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9050955467063241, 0.771292213897641, 0.9017936388395358], "final_y": [0.18188296030562845, 0.22804587386033115, 0.18188026071567476]}, "mutation_prompt": null}
{"id": "33c03f4e-bc06-48ad-adad-883f73e18e32", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9) * (1 - self.eval_count / self.budget)  # Adaptive mutation factor\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Introduce adaptive mutation factor in DE to enhance diversity and convergence.", "configspace": "", "generation": 80, "fitness": 0.9319869870738037, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.899455428319806, 0.9426228594618751, 0.9538826734397298], "final_y": [0.18188019819725698, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "8f6f9ba2-b713-4198-a112-408ff4f7bced", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2) * (self.eval_count / self.budget)  # Adaptive penalty scaling\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer integrating adaptive DE with diversity-guided mutation and periodicity-driven local search, now with adaptive periodicity deviation penalties for superior convergence.", "configspace": "", "generation": 81, "fitness": 0.9438407797761988, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9350168064269916, 0.9426228594618751, 0.9538826734397298], "final_y": [0.16485654456513377, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "bd8700ac-2546-4f5d-ba36-d420e7d00050", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.85, 1.0)  # Refined crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer integrating adaptive DE with diversity-guided mutation and periodicity-driven local search, now with a refined crossover strategy for improved convergence.", "configspace": "", "generation": 82, "fitness": 0.8733933368810883, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.019. And the mean value of best solutions found was 0.188 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.899455428319806, 0.8553707872785442, 0.8653537950449147], "final_y": [0.18188019819725698, 0.20045052101359218, 0.18187878849318484]}, "mutation_prompt": null}
{"id": "e5ef56f1-5b88-43b1-9e78-5383840e1def", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def adaptive_differential_evolution(self, func, lb, ub):\n        # Use learning rate adaptation for F and CR\n        F = np.random.uniform(0.5, 1.0)\n        CR = np.random.uniform(0.7, 0.9)\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def segment_based_local_search(self, func, lb, ub):\n        # Focus on segments for local tuning\n        if self.eval_count < self.budget:\n            segments = np.array_split(self.best_solution, 2)\n            for segment in segments:\n                result = minimize(func, segment, bounds=np.c_[lb, ub], method='L-BFGS-B')\n                self.eval_count += result.nfev\n                if result.fun > self.best_score:\n                    self.best_score = result.fun\n                    self.best_solution = np.concatenate([result.x if np.all(segment == s) else s for s in segments])\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.adaptive_differential_evolution(func, lb, ub)\n            self.segment_based_local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Hybrid optimizer with adaptive DE parameters and segment-based local search for enhanced reflectivity optimization.", "configspace": "", "generation": 83, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The number of bounds is not compatible with the length of `x0`.').", "error": "ValueError('The number of bounds is not compatible with the length of `x0`.')", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {}, "mutation_prompt": null}
{"id": "c00d780f-3f90-4ac8-a799-bf4ede9e9e62", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.95)  # Adjusted for more aggressive mutation\n        CR = np.random.uniform(0.65, 0.9)  # Adapt crossover probability for exploration\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial) - 0.1 * self.reflectivity_score(trial)  # Adjusted score calculation\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved optimizer with enhanced differential strategies and adaptive mutation control for effective convergence.", "configspace": "", "generation": 84, "fitness": 0.708510845095191, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.709 with standard deviation 0.149. And the mean value of best solutions found was 0.261 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.5779818530394389, 0.9169289123483187, 0.6306217698978154], "final_y": [0.3041719999594136, 0.18187831015675382, 0.29810036534797557]}, "mutation_prompt": null}
{"id": "80a24650-7229-4286-97eb-13cdcf62394c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Adjusted differential weight range for better adaptability\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined optimizer with enhanced differential weight update to boost exploration and convergence.", "configspace": "", "generation": 85, "fitness": 0.836749280430526, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.055. And the mean value of best solutions found was 0.206 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9050955467063241, 0.771292213897641, 0.8338600806876125], "final_y": [0.18188296030562845, 0.22804587386033115, 0.20725469324871404]}, "mutation_prompt": null}
{"id": "cb38a858-d4d1-4db0-aeae-a4ca137b0f82", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B', options={'maxiter': 50})\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined optimizer with enhanced local search to improve solution quality and convergence speed.", "configspace": "", "generation": 86, "fitness": 0.9438407797761988, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9350168064269916, 0.9426228594618751, 0.9538826734397298], "final_y": [0.16485654456513377, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "a4adba85-88fe-4b17-9fd4-040b6f3ddad0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.9)  # Adjusted differential weight for better balance\n        CR = np.random.uniform(0.85, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer integrating adaptive DE with diversity-guided mutation and periodicity-driven local search for superior convergence while balancing exploration and exploitation through adaptive parameters.", "configspace": "", "generation": 87, "fitness": 0.7278660607425538, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.728 with standard deviation 0.152. And the mean value of best solutions found was 0.257 (0. is the best) with standard deviation 0.094.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.5138500216094513, 0.8540055723999446, 0.8157425882182652], "final_y": [0.3900956074910734, 0.20044514711083505, 0.1818793132415223]}, "mutation_prompt": null}
{"id": "a161bd7d-651a-4c63-a052-ee1e900ebc75", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Adjusted differential weight\n        CR = 0.95  # Modified crossover probability to be constant\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer using adaptive DE with refined mutation strategies and periodicity-driven local search for improved convergence.", "configspace": "", "generation": 88, "fitness": 0.9101901318957876, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.033. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9531343708974103, 0.9035268230346265, 0.8739092017553259], "final_y": [0.16485956137458335, 0.16485839624394627, 0.1881323018359473]}, "mutation_prompt": null}
{"id": "a4d19692-4fa5-4fea-be99-2ce02f317f76", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        hybrid_ratio = np.clip(0.1 + 0.9 * (self.eval_count / self.budget), 0.1, 1.0)\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B', options={'maxiter': int(hybrid_ratio * self.budget)})\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer integrates adaptive DE with diversity-guided mutation and periodicity-driven local search, now with a dynamic hybridization ratio for improved exploitation.", "configspace": "", "generation": 89, "fitness": 0.9438407797761988, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9350168064269916, 0.9426228594618751, 0.9538826734397298], "final_y": [0.16485654456513377, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "7b9b63ab-e507-4044-9647-467d38bd6a80", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            if self.eval_count < 0.7 * self.budget:  # Adjusted local search frequency\n                self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Revised EnhancedHybridDEOptimizer by incorporating adaptive local search frequency to enhance convergence efficiency.  ", "configspace": "", "generation": 90, "fitness": 0.9438407797761988, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9350168064269916, 0.9426228594618751, 0.9538826734397298], "final_y": [0.16485654456513377, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "623b7766-05ad-4087-8b44-bfb15edb77ea", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.9, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score and self.eval_count < self.budget:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved the differential weight and crossover probability in DE and refined local search conditions for enhanced convergence.", "configspace": "", "generation": 91, "fitness": 0.8106104247835813, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.144. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.051.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6086688590559279, 0.9376595231139089, 0.8855028921809072], "final_y": [0.2827475986672088, 0.1648568463642619, 0.18813371549948332]}, "mutation_prompt": null}
{"id": "b9d7f210-354c-4d19-82f6-0fa42d2af17b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(10 * dim)  # Dynamic population size based on dimension, previously static\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.7, 0.9)  # Dynamic crossover probability, previously 0.8 to 1.0\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer using adaptive DE with diversity-focused mutation and periodicity-driven local search, now fine-tuned with dynamic population size and crossover adjustment.", "configspace": "", "generation": 92, "fitness": 0.6230816012394159, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.623 with standard deviation 0.101. And the mean value of best solutions found was 0.299 (0. is the best) with standard deviation 0.097.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.5165678108088219, 0.594650868104003, 0.7580261248054226], "final_y": [0.3900957272650777, 0.3408038301248777, 0.16486020522308142]}, "mutation_prompt": null}
{"id": "5c99100d-8a62-4625-b8d4-cfb1f8532296", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2) * 2  # Adjusted penalty factor\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            if self.eval_count < self.budget * 0.75:  # Adaptive local search based on budget usage\n                self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Optimizer with improved periodic deviation penalty and adaptive local search for enhanced convergence efficiency.", "configspace": "", "generation": 93, "fitness": 0.9438407797761988, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9350168064269916, 0.9426228594618751, 0.9538826734397298], "final_y": [0.16485654456513377, 0.16485732559886557, 0.16485696109440595]}, "mutation_prompt": null}
{"id": "e7864666-c124-4b16-9b28-7c257f13002b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.clip(self.eval_count / self.budget, 0.8, 1.0)  # Adaptive crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined hybrid optimizer enhancing DE by incorporating adaptive crossover probability to boost convergence.", "configspace": "", "generation": 94, "fitness": 0.7208665901251073, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.721 with standard deviation 0.074. And the mean value of best solutions found was 0.261 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6716253634100185, 0.6658106846283876, 0.8251637223369157], "final_y": [0.28274900558195726, 0.29182703302474333, 0.2072548851438082]}, "mutation_prompt": null}
{"id": "05794b36-6d60-4273-baa9-8255d36fcf6b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.7, 0.95)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial) - self.reflectivity_score(trial)  # Adjusted selection criteria\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(self.population[i]):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Improved optimizer leveraging adaptive DE with enhanced mutation strategies and periodicity-enforcing cost for better convergence.", "configspace": "", "generation": 95, "fitness": 0.7728863121954427, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.161. And the mean value of best solutions found was 0.240 (0. is the best) with standard deviation 0.069.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.546512552084722, 0.9120656089838041, 0.860080775517802], "final_y": [0.3376792249417385, 0.1818786528830213, 0.20044717589200323]}, "mutation_prompt": null}
{"id": "de384a3d-d087-421b-975d-493237cf0657", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(12, int(12 * dim * 0.9))  # Dynamic population size adjustment\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced optimizer employing adaptive DE with diversity-guided mutation and periodicity-driven local search, now with dynamic population size adjustment for improved convergence.", "configspace": "", "generation": 96, "fitness": 0.7227856781147696, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.723 with standard deviation 0.095. And the mean value of best solutions found was 0.264 (0. is the best) with standard deviation 0.046.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6791446244009589, 0.6347602666524583, 0.8544521432908913], "final_y": [0.28274745672017865, 0.3095838926543566, 0.20044802235378067]}, "mutation_prompt": null}
{"id": "869a2e4d-fab5-4202-aedb-8f4e0bb71c93", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.9)  # Adjusted differential weight\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(lambda x: func(x) + self.reflectivity_score(x), self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Optimizes reflectivity by integrating adaptive DE with diversity-guided mutation and enhanced periodicity preservation in local search.", "configspace": "", "generation": 97, "fitness": 0.6854132652714623, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.685 with standard deviation 0.180. And the mean value of best solutions found was 0.253 (0. is the best) with standard deviation 0.113.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.6430654939892838, 0.489034628741676, 0.9241396730834271], "final_y": [0.17305382545406844, 0.41379549904142665, 0.17304837816470442]}, "mutation_prompt": null}
{"id": "1792cacc-b652-4b86-a62c-5afe40beeac2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.6, 0.85)  # Adjusted differential weight for better convergence\n        CR = np.random.uniform(0.85, 1.0)  # Modified crossover probability for stability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Enhanced DE optimizer with improved mutation strategy and tuned parameters for better exploitation-exploration balance.", "configspace": "", "generation": 98, "fitness": 0.642183370622933, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.642 with standard deviation 0.178. And the mean value of best solutions found was 0.317 (0. is the best) with standard deviation 0.095.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.8939245049697199, 0.5170965586785397, 0.5155290482205395], "final_y": [0.18188261291023333, 0.3900962506322968, 0.37752441537368164]}, "mutation_prompt": null}
{"id": "71325577-04c3-459c-8dce-c9b2e271bfd9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.eval_count = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def reflectivity_score(self, x):\n        period = self.dim // 2  # Fixed periodic structure for stability\n        periodic_deviation = np.sum((x[:period] - x[period:2*period]) ** 2)\n        deviation_penalty = np.sum((x - np.roll(x, period)) ** 2)\n        return periodic_deviation + deviation_penalty\n\n    def differential_evolution(self, func, lb, ub):\n        F = np.random.uniform(0.5, 0.9)  # Adjusted differential weight range for better diversity\n        CR = np.random.uniform(0.8, 1.0)  # Modified crossover probability\n        \n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_score = func(trial)\n            self.eval_count += 1\n\n            if trial_score > func(self.population[i]) - self.reflectivity_score(trial):\n                self.population[i] = trial\n\n            if trial_score > self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial\n\n    def local_search(self, func, lb, ub):\n        result = minimize(func, self.best_solution, bounds=np.c_[lb, ub], method='L-BFGS-B')\n        self.eval_count += result.nfev\n\n        if result.fun > self.best_score:\n            self.best_score = result.fun\n            self.best_solution = result.x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.eval_count < self.budget:\n            self.differential_evolution(func, lb, ub)\n            self.local_search(func, lb, ub)\n\n        return self.best_solution", "name": "EnhancedHybridDEOptimizer", "description": "Refined optimizer that strengthens diversity by dynamically adjusting the differential weight F to further improve convergence.", "configspace": "", "generation": 99, "fitness": 0.836749280430526, "feedback": "The algorithm EnhancedHybridDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.055. And the mean value of best solutions found was 0.206 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "33f0d30c-a80a-4b21-9ea7-5d6dde328221", "metadata": {"aucs": [0.9050955467063241, 0.771292213897641, 0.8338600806876125], "final_y": [0.18188296030562845, 0.22804587386033115, 0.20725469324871404]}, "mutation_prompt": null}
