{"id": "b0d9dd1d-d348-441b-90b6-920e3bff005d", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "A novel metaheuristic called \"Collaborative Swarm Search\" combines principles of swarm intelligence and local search to adaptively balance exploration and exploitation in search spaces.", "configspace": "", "generation": 0, "fitness": 0.8469054081236634, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.019. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": null, "metadata": {"aucs": [0.821452232008129, 0.8686576624857639, 0.8506063298770976], "final_y": [0.14582892388706392, 0.13093906050060167, 0.13203115102354424]}, "mutation_prompt": null}
{"id": "48e8285f-bdfc-46ff-b6a4-76daa4ad9481", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.9  # Initial inertia weight\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Update inertia weight with nonlinear decay\n                self.inertia_weight = 0.9 - 0.4 * (eval_count / self.budget)**2  \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Dynamically adjust population size\n                if eval_count % (self.budget // 2) == 0:\n                    if global_best_score > 0.1:\n                        self.population_size = min(20, self.population_size + 1)\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "A refined 'Collaborative Swarm Search' enhances convergence by introducing nonlinear inertia weight decay and adaptive population size.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "b0d9dd1d-d348-441b-90b6-920e3bff005d", "metadata": {}, "mutation_prompt": null}
{"id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Collaborative Swarm Search with adaptive inertia weight dynamically balances exploration and exploitation by adjusting inertia based on progress.", "configspace": "", "generation": 2, "fitness": 0.8550756834687614, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.014. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b0d9dd1d-d348-441b-90b6-920e3bff005d", "metadata": {"aucs": [0.8358435459911989, 0.8674690227004298, 0.8619144817146553], "final_y": [0.138433883272166, 0.12774694750287263, 0.13015415513828554]}, "mutation_prompt": null}
{"id": "0d3b86ac-20cf-4a84-969f-b58a6b5fe397", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically using a non-linear function\n                self.inertia_weight = 0.9 - (0.5 * ((eval_count / self.budget)**2))\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced Collaborative Swarm Search introduces a non-linear dynamic adjustment for inertia weight to improve the balance between exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.8211829559045403, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.018. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.8013937896988018, 0.8453953819309653, 0.8167596960838538], "final_y": [0.13926416832046928, 0.12581045085028397, 0.14365107303855507]}, "mutation_prompt": null}
{"id": "d7360019-419c-4e7f-875f-ebae74c486c7", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic components\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.uniform(0.5, 1.5) * (personal_best_positions[i] - positions[i])  # Changed line\n                    + self.c2 * np.random.uniform(0.5, 1.5) * (global_best_position - positions[i])  # Changed line\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Collaborative Swarm Search with stochastic cognitive and social components enhances exploration by introducing controlled randomness in the velocity update.", "configspace": "", "generation": 4, "fitness": 0.7870814185206122, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.018. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.7617599252144303, 0.7986744359249991, 0.8008098944224074], "final_y": [0.16638759889047272, 0.13428981952009167, 0.148124692362806]}, "mutation_prompt": null}
{"id": "5a56637a-1f5a-4e2f-8c1c-fa9afbfe22bd", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight and coefficient dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                self.c1 = 1.5 + (0.5 * (eval_count / self.budget))\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced Particle Swarm Optimization with adaptive dynamic coefficients for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.8267516709409021, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.026. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.7940553015738997, 0.8570302555706729, 0.8291694556781336], "final_y": [0.15368486591830632, 0.12533894093374287, 0.14474881781926208]}, "mutation_prompt": null}
{"id": "67ab1f2e-ff1a-4aa1-925b-ed7c9929a1ef", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Initial cognitive component\n        self.c2 = 2.0  # Initial social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Dynamically adjust cognitive and social components\n                self.c1 = 2.0 - (1.5 * np.linalg.norm(personal_best_positions[i] - global_best_position) / np.linalg.norm(func.bounds.ub - func.bounds.lb))\n                self.c2 = 2.0 + (1.5 * np.linalg.norm(personal_best_positions[i] - global_best_position) / np.linalg.norm(func.bounds.ub - func.bounds.lb))\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "An improved Collaborative Swarm Search with dynamic social and cognitive components that adapt based on each particle's proximity to the best known solution to enhance convergence speed.", "configspace": "", "generation": 6, "fitness": 0.8442445478286756, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.019. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.8200524857874683, 0.8667125150638764, 0.8459686426346823], "final_y": [0.1379647415667674, 0.12596661639981221, 0.13430985901692405]}, "mutation_prompt": null}
{"id": "8f7a312e-1e09-4396-8c69-534fcd994419", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n        self.velocity_clamp = 0.1  # Maximum velocity change\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Clamp velocity to prevent overshooting\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introducing a velocity clamping mechanism to improve convergence stability and prevent particles from overshooting optimal regions.", "configspace": "", "generation": 7, "fitness": 0.724162771270783, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.724 with standard deviation 0.038. And the mean value of best solutions found was 0.189 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.6767908055793697, 0.7698199872068949, 0.7258775210260844], "final_y": [0.21041403593047436, 0.16985263566409758, 0.1879068433274952]}, "mutation_prompt": null}
{"id": "33e0ef6b-7f55-4aba-b827-ba22f3b7077c", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update cognitive and social components stochastically\n                self.c1 = 1.5 + 0.5 * np.random.rand()\n                self.c2 = 1.5 + 0.5 * np.random.rand()\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Improved Collaborative Swarm Search with stochastic cognitive and social parameters enhances exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8347893413010089, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.039. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.7800244711276452, 0.8528131986159336, 0.871530354159448], "final_y": [0.15968312105336724, 0.12188434925827962, 0.12903689360045068]}, "mutation_prompt": null}
{"id": "2c341de8-76d6-46e1-b203-5d9a68553d31", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            dynamic_population_size = 10 + int(5 * (1 - eval_count / self.budget))  # Dynamic population size\n            for i in range(dynamic_population_size):  # Adjust loop to dynamic population size\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce a dynamic population size to enhance diversity and convergence by varying the number of particles based on optimization progress.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {}, "mutation_prompt": null}
{"id": "f5e6b071-43ef-4b5f-8e23-25f6b1ecd081", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Dynamically adjust cognitive and social components\n                self.c1 = 2.0 - (1.0 * (eval_count / self.budget))\n                self.c2 = 1.0 + (1.0 * (eval_count / self.budget))\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Collaborative Swarm Search with adaptive cognitive-social coefficient balance enhances exploration and exploitation by dynamically adjusting coefficients based on progress.", "configspace": "", "generation": 10, "fitness": 0.8470383949467878, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.009. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.8364458125465006, 0.8463888864647635, 0.8582804858290993], "final_y": [0.13199321288118537, 0.12835974385345228, 0.12588928220142326]}, "mutation_prompt": null}
{"id": "b402c906-05c8-4e6f-af1d-8a0e17a89b4a", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Adapt cognitive and social components\n                self.c1 = 2.0 - (1.5 * (eval_count / self.budget))\n                self.c2 = 2.0 + (1.5 * (eval_count / self.budget))\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced Collaborative Swarm Search by introducing adaptive cognitive and social components for improved convergence.", "configspace": "", "generation": 11, "fitness": 0.837713025457175, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.010. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.8345476016137815, 0.8515662363562109, 0.8270252384015325], "final_y": [0.13216785475751958, 0.1324993945034224, 0.14574542223361608]}, "mutation_prompt": null}
{"id": "79821790-5515-4abf-9b20-84e946e453d3", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n\n                # Dynamic adjustment of cognitive and social components\n                self.c1 = 1.5 + (0.5 * (eval_count / self.budget))\n                self.c2 = 2.5 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced Collaborative Swarm Search with adaptive learning factors dynamically adjusts cognitive and social components to improve performance.", "configspace": "", "generation": 12, "fitness": 0.8344708171103764, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.019. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.8573930796049751, 0.8346144381031582, 0.811404933622996], "final_y": [0.13067125662652557, 0.13517456079973866, 0.1480550849098775]}, "mutation_prompt": null}
{"id": "ca29fe0f-1a38-4f2b-826e-fe3be5e9b9b4", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Apply dynamic velocity clamping\n                velocities[i] = np.clip(velocities[i], -(func.bounds.ub - func.bounds.lb) * (1 - eval_count / self.budget), (func.bounds.ub - func.bounds.lb) * (1 - eval_count / self.budget))\n                \n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced Collaborative Swarm Search with adaptive velocity clamping based on progress dynamically adjusts exploration and exploitation by controlling velocity magnitude.", "configspace": "", "generation": 13, "fitness": 0.8447662985461081, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.021. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.8353712117699472, 0.8738292118753046, 0.8250984719930723], "final_y": [0.13821340378719427, 0.12077216078931363, 0.1455227577632393]}, "mutation_prompt": null}
{"id": "e182214d-bdda-4f21-a7bb-c716cce6bc14", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (10 * dim)))  # Dynamically adjust population size\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced Collaborative Swarm Search with dynamic population size for improved convergence balance.", "configspace": "", "generation": 14, "fitness": 0.8550756834687614, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.014. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.8358435459911989, 0.8674690227004298, 0.8619144817146553], "final_y": [0.138433883272166, 0.12774694750287263, 0.13015415513828554]}, "mutation_prompt": null}
{"id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced Collaborative Swarm Search with stochastic velocity scaling to improve exploration in early stages.", "configspace": "", "generation": 15, "fitness": 0.8740733576641316, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.021. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2a05aa38-192e-44ac-8f19-2f3b9587e561", "metadata": {"aucs": [0.845121878862958, 0.8962610487130871, 0.8808371454163495], "final_y": [0.1386647802559614, 0.12084875228341307, 0.1299309152933974]}, "mutation_prompt": null}
{"id": "bef72a34-d3a7-4b6b-adc3-2ad2f1875f93", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update cognitive and social components dynamically\n                self.c1 = 1.5 + (0.5 * (eval_count / self.budget))\n                self.c2 = 2.5 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduced dynamic adaptation of cognitive and social components to balance exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.8545004090467723, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.017. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.8653284074020383, 0.8298922860426613, 0.868280533695617], "final_y": [0.12847780406237796, 0.14311370777904164, 0.12696696946283093]}, "mutation_prompt": null}
{"id": "019bab2f-bf74-494d-870c-5030fd4c0ef9", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            diversity = np.std(positions, axis=0).mean()  # Calculate swarm diversity\n            self.c1 = max(0.5, 2.5 - diversity)  # Adjust cognitive component\n            self.c2 = max(0.5, 2.5 + diversity)  # Adjust social component\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhance swarm convergence by dynamically adjusting cognitive and social components based on swarm diversity.", "configspace": "", "generation": 17, "fitness": 0.8016042188910836, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.046. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.7650503245769655, 0.7736926519628476, 0.8660696801334378], "final_y": [0.16858870768749423, 0.16494178591605757, 0.12210486671895127]}, "mutation_prompt": null}
{"id": "1dda1490-f564-46a2-aca3-bc734a362043", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * np.random.rand() * (personal_best_positions[i] - positions[i])  # Random cognitive scaling\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced exploration with random cognitive scaling to improve solution diversity and convergence.", "configspace": "", "generation": 18, "fitness": 0.829996694830743, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.023. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.8006209775708022, 0.8335985837166087, 0.8557705232048183], "final_y": [0.1565692026612978, 0.14421145731396534, 0.13498594779544337]}, "mutation_prompt": null}
{"id": "e029b68c-f17c-4605-81ee-849eb40fa263", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.7 - (0.3 * (eval_count / self.budget))  # Modified line\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + (self.c1 + 0.5 * np.random.rand()) * (personal_best_positions[i] - positions[i])  # Modified line\n                    + (self.c2 + 0.5 * np.random.rand()) * (global_best_position - positions[i])  # Modified line\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced velocity update with adaptive inertia weight and dynamic cognitive components for better convergence.", "configspace": "", "generation": 19, "fitness": 0.7900904481894108, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.005. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.7939630099830595, 0.7930607594902107, 0.7832475750949622], "final_y": [0.1577997865891515, 0.14444210344714248, 0.15129486092087963]}, "mutation_prompt": null}
{"id": "a13b0129-800b-4684-a606-d9bf37f1bd36", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update cognitive and social components adaptively\n                self.c1 = 1.5 + (0.5 * (eval_count / self.budget))\n                self.c2 = 2.5 - (0.5 * (eval_count / self.budget))\n\n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Collaborative Swarm Search with adaptive cognitive and social components to balance exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.8545004090467723, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.017. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.8653284074020383, 0.8298922860426613, 0.868280533695617], "final_y": [0.12847780406237796, 0.14311370777904164, 0.12696696946283093]}, "mutation_prompt": null}
{"id": "e74b48f7-36b3-4270-b601-afcbf8dbdde4", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n        self.momentum = 0.9  # Momentum coefficient for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling and momentum\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    self.momentum * velocities[i] +  # Apply momentum\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce momentum to the velocity update for smoother convergence, improving solution stability and quality.", "configspace": "", "generation": 21, "fitness": 0.7891757905118942, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.042. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.7299975553679446, 0.8186272723967267, 0.8189025437710112], "final_y": [0.18537968297245333, 0.15134444289352011, 0.1465727932498565]}, "mutation_prompt": null}
{"id": "6f4c337e-0fab-4f00-ac78-77aadc5c84cd", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n        self.velocity_clamp = 0.1  # Maximum allowed velocity change\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Clamp velocity changes\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduced velocity constriction to limit excessive velocity changes, enhancing convergence stability.", "configspace": "", "generation": 22, "fitness": 0.7215460863188947, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.722 with standard deviation 0.039. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.674267835314232, 0.7690514107259141, 0.7213190129165381], "final_y": [0.21175881656203543, 0.17018307677372746, 0.19007113895198569]}, "mutation_prompt": null}
{"id": "c7bb254f-2b3d-41b4-8982-0f9e60c0a326", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                local_best_position = personal_best_positions[np.random.choice(self.population_size)]  # Local influence\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                    + self.c2 * np.random.rand() * (local_best_position - positions[i])  # Local term addition\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Improved velocity update by incorporating local neighbor influence to enhance convergence speed.", "configspace": "", "generation": 23, "fitness": 0.8028598622818852, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.032. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.818563613529942, 0.8311401604403981, 0.7588758128753156], "final_y": [0.1359159232978996, 0.12923237766683138, 0.173658482115302]}, "mutation_prompt": null}
{"id": "2ef7242f-05f1-400d-851a-1fb790fddb4a", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.7 + (0.4 * np.random.rand()) * (1 - eval_count / self.budget)  # Adjusted weight\n\n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget and eval_count % (self.budget // 5) == 0:  # Dynamic population resizing\n                self.population_size = max(5, self.population_size - 1)\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Adaptive inertia weight and dynamic population resizing for improved exploration-exploitation balance.", "configspace": "", "generation": 24, "fitness": 0.8593417734299922, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.007. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.8522256751852741, 0.8564574568296007, 0.8693421882751019], "final_y": [0.13332063648653492, 0.13159927597788734, 0.13263546318345154]}, "mutation_prompt": null}
{"id": "e70b2480-26da-4803-b8fd-ddb170374fd9", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Updated: Calculate population diversity\n                diversity = np.std(positions, axis=0).mean()\n                \n                # Updated: Adaptive scaling factor based on diversity\n                scaling_factor = 1.0 / (1.0 + diversity)\n                \n                # Update velocity with adaptive scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply adaptive scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Improved Collaborative Swarm Search with adaptive velocity scaling based on population diversity to enhance convergence speed.", "configspace": "", "generation": 25, "fitness": 0.8138211216878194, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.030. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.7780246884997172, 0.8112533127095177, 0.8521853638542236], "final_y": [0.16293756840843898, 0.153621704859094, 0.13683285684211077]}, "mutation_prompt": null}
{"id": "e4b853d4-0064-45bc-b334-b8ef80a30498", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Initial cognitive component\n        self.c2 = 2.0  # Initial social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Adaptive learning factors\n                self.c1 = 2.5 - (1.5 * (eval_count / self.budget))\n                self.c2 = 1.5 + (1.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Collaborative Swarm Search with adaptive learning factors to enhance convergence towards optimal solutions.", "configspace": "", "generation": 26, "fitness": 0.8526168171427787, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.015. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.8582461410378377, 0.8323728381346034, 0.867231472255895], "final_y": [0.1321922290567974, 0.1447895760372505, 0.13396131450801452]}, "mutation_prompt": null}
{"id": "059755e8-8d51-44ed-ae1d-cf5cb591ba2c", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 10  # Base number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Adjust population size based on remaining budget\n        population_size = int(self.base_population_size + (self.budget - self.base_population_size) * 0.1)\n        \n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = population_size\n\n        while eval_count < self.budget:\n            for i in range(population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced Collaborative Swarm Search with adaptive population size to balance exploration and exploitation dynamically.", "configspace": "", "generation": 27, "fitness": 0.8603218964264071, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.024. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.8751450736377436, 0.8792586004256515, 0.8265620152158262], "final_y": [0.11734828635433847, 0.11903140227340248, 0.13351174092113316]}, "mutation_prompt": null}
{"id": "a0543462-5a7e-4c70-b355-06b8ccd524f9", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n                # Modify cognitive and social components adaptively\n                self.c1 = 2.0 - (eval_count / self.budget)\n                self.c2 = 1.5 + (eval_count / self.budget)\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced Collaborative Swarm Search with adaptive cognitive and social coefficients for better convergence.", "configspace": "", "generation": 28, "fitness": 0.8450900499244048, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.012. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.8359218128089559, 0.8376778515709234, 0.861670485393335], "final_y": [0.14297568782466064, 0.13991373405240604, 0.1350171097299384]}, "mutation_prompt": null}
{"id": "8ed086ac-2933-473b-9474-c6de9f319783", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling and adaptive learning factors\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                adaptive_c1 = self.c1 * (1 - (eval_count / self.budget))\n                adaptive_c2 = self.c2 * (eval_count / self.budget)\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + adaptive_c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + adaptive_c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Incorporate adaptive learning factors in velocity update to refine both exploration and exploitation phases.", "configspace": "", "generation": 29, "fitness": 0.7852293196646705, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.024. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.7676765024551725, 0.8193149931213869, 0.7686964634174519], "final_y": [0.14951814770938365, 0.14528829958440415, 0.16032127703214494]}, "mutation_prompt": null}
{"id": "3c1e6e54-f8bd-4de3-88cc-b817b5c5c50c", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n\n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                adaptive_c1 = self.c1 * (1 - eval_count / self.budget)  # Adaptive cognitive component\n                adaptive_c2 = self.c2 * (eval_count / self.budget)  # Adaptive social component\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + adaptive_c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + adaptive_c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive learning rates for cognitive and social components to enhance convergence speed and solution quality.", "configspace": "", "generation": 30, "fitness": 0.7852293196646705, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.024. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.7676765024551725, 0.8193149931213869, 0.7686964634174519], "final_y": [0.14951814770938365, 0.14528829958440415, 0.16032127703214494]}, "mutation_prompt": null}
{"id": "f13dffe3-396f-4db5-9824-b76e7efdf58d", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                # Adjust cognitive and social components dynamically\n                self.c1 = 2.5 - 1.5 * (eval_count / self.budget)  # Adaptive c1\n                self.c2 = 0.5 + 1.5 * (eval_count / self.budget)  # Adaptive c2\n                \n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Improved Collaborative Swarm Search with adaptive acceleration coefficients for balanced exploration and exploitation.", "configspace": "", "generation": 31, "fitness": 0.8149774802198341, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.024. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.829370591629687, 0.8338154208373348, 0.7817464281924806], "final_y": [0.1381579680157431, 0.1447614867012793, 0.15500259896446256]}, "mutation_prompt": null}
{"id": "e55ce106-20db-42e8-b3ab-4df0e85b5195", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.9  # Adaptive inertia weight initialized for exploration\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced Collaborative Swarm Search with adaptive inertia weight initialized to foster exploration. ", "configspace": "", "generation": 32, "fitness": 0.8740733576641316, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.021. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.845121878862958, 0.8962610487130871, 0.8808371454163495], "final_y": [0.1386647802559614, 0.12084875228341307, 0.1299309152933974]}, "mutation_prompt": null}
{"id": "9679910b-f67a-4c57-8ff9-4a3dbbc38bda", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with adaptive scaling\n                scaling_factor = np.random.rand()\n                adaptive_factor = (personal_best_scores[i] / (global_best_score + 1e-10))  # Add adaptive scaling\n                velocities[i] = (\n                    adaptive_factor * scaling_factor * self.inertia_weight * velocities[i]  # Apply adaptive scaling\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive velocity scaling based on the score relative to the global best to enhance local convergence.", "configspace": "", "generation": 33, "fitness": 0.8638160122635203, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.008. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.8628201890931786, 0.854463497070285, 0.8741643506270975], "final_y": [0.13226168974609864, 0.13407503574027135, 0.13097924672675343]}, "mutation_prompt": null}
{"id": "d2e1aae6-0647-4b7d-b6aa-0aa5a326d4e4", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with adaptive scaling\n                adaptive_scaling_factor = np.random.rand() * 0.5 + 0.5  # Change here\n                velocities[i] = (\n                    adaptive_scaling_factor * self.inertia_weight * velocities[i]  # Apply adaptive scaling\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Refined Collaborative Swarm Search with adaptive velocity scaling integrating personal and global best influence for enhanced convergence.", "configspace": "", "generation": 34, "fitness": 0.8524560511729535, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.007. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.8533447254795499, 0.860817210906689, 0.8432062171326219], "final_y": [0.1327033590686545, 0.1311287575715181, 0.1410578419122238]}, "mutation_prompt": null}
{"id": "e089c0a1-fad1-4a32-8295-0c73cba48697", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Adaptive learning rates for cognitive and social components\n                adaptive_c1 = self.c1 * (1 - eval_count / self.budget)\n                adaptive_c2 = self.c2 * (eval_count / self.budget)\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + adaptive_c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + adaptive_c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive learning rates for cognitive and social components to enhance exploitation and exploration balance.", "configspace": "", "generation": 35, "fitness": 0.7852293196646705, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.024. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.7676765024551725, 0.8193149931213869, 0.7686964634174519], "final_y": [0.14951814770938365, 0.14528829958440415, 0.16032127703214494]}, "mutation_prompt": null}
{"id": "df211487-422a-4f98-a5de-018e923669dc", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Adjust cognitive and social components dynamically\n                self.c1 = 2.5 - (1.5 * (eval_count / self.budget))\n                self.c2 = 1.5 + (0.5 * (eval_count / self.budget))\n\n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Improved Exploration-Exploitation Balance by Dynamic Component Adjustment in Collaborative Swarm Search.", "configspace": "", "generation": 36, "fitness": 0.8579898059647092, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.006. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.8494298674752996, 0.860402642416658, 0.8641369080021702], "final_y": [0.1368061067067089, 0.1332056472596106, 0.1337666440020644]}, "mutation_prompt": null}
{"id": "fd16fb11-e088-4569-95e7-32251398abcf", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 1.8  # Cognitive component\n        self.c2 = 2.2  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Slightly adjusted cognitive and social components to balance exploration and exploitation for improved convergence.", "configspace": "", "generation": 37, "fitness": 0.8578321548415034, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.016. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.8458522116432987, 0.8468986687835526, 0.8807455840976592], "final_y": [0.13729822530150937, 0.13467570771995552, 0.1295695111009102]}, "mutation_prompt": null}
{"id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Improved inertia weight scaling function for better balance between exploration and exploitation.", "configspace": "", "generation": 38, "fitness": 0.8740733576641317, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.021. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ad0db622-c1de-4412-9a4c-2a229551fac6", "metadata": {"aucs": [0.845121878862958, 0.8962610487130878, 0.8808371454163494], "final_y": [0.13866478025596152, 0.12084875228341285, 0.12993091529339762]}, "mutation_prompt": null}
{"id": "139f7308-337a-48c2-b6d6-559f251398ea", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1_initial = 2.0  # Initial cognitive component\n        self.c2_initial = 2.0  # Initial social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n\n                # Update learning factors dynamically\n                c1 = self.c1_initial - (1.5 * eval_count / self.budget)\n                c2 = self.c2_initial + (1.5 * eval_count / self.budget)\n\n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced swarm intelligence using dynamic learning factors to balance exploration and exploitation.", "configspace": "", "generation": 39, "fitness": 0.8614053173349808, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.012. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8556868267102165, 0.8510222782514723, 0.8775068470432535], "final_y": [0.13479762231193715, 0.13784007292907297, 0.12910632875464234]}, "mutation_prompt": null}
{"id": "c698669d-eab8-4741-8bf9-842830058c51", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Adaptive cognitive and social components\n                self.c1 = 1.5 + (0.5 * eval_count / self.budget)\n                self.c2 = 1.5 + (0.5 * (1 - eval_count / self.budget))\n\n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive cognitive and social components for enhanced exploration-exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.8500880708766366, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.025. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8167482983841112, 0.8568112156011991, 0.8767046986445995], "final_y": [0.15002996949542025, 0.1354942373332374, 0.1312707907644366]}, "mutation_prompt": null}
{"id": "597fe817-1dc0-42b7-99eb-b34497b35c5f", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update cognitive and social components dynamically\n                self.c1 = 1.5 + (0.5 * (1 - eval_count / self.budget))\n                self.c2 = 1.5 + (0.5 * eval_count / self.budget)\n\n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce a dynamic cognitive and social component scaling for improved adaptation throughout iterations.", "configspace": "", "generation": 41, "fitness": 0.8500458233984961, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.031. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8065428179281151, 0.8656221552638994, 0.8779724970034737], "final_y": [0.15386183339272963, 0.13129172478971518, 0.12953825725969126]}, "mutation_prompt": null}
{"id": "46d1767b-f807-4676-94e5-025603d8440c", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                nonlinear_c2 = self.c2 * (1 - (eval_count / self.budget) ** 2)  # Nonlinear adjustment\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + nonlinear_c2 * np.random.rand() * (global_best_position - positions[i])  # Adjusted social component\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Incorporate nonlinear dynamic adjustment in social component to enhance convergence speed.", "configspace": "", "generation": 42, "fitness": 0.8712519091382824, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.019. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8449935364848576, 0.8870191002253514, 0.8817430907046381], "final_y": [0.13856780304652117, 0.12505899704899792, 0.12945594632639768]}, "mutation_prompt": null}
{"id": "9b5a5e97-bcc1-423a-8fe5-1cb5498a93ff", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n\n                # Adaptive update of cognitive and social components\n                adaptive_c1 = self.c1 * (1.0 - eval_count / self.budget)\n                adaptive_c2 = self.c2 * (eval_count / self.budget)\n\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + adaptive_c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + adaptive_c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Incorporate adaptive learning rates for cognitive and social components to enhance convergence.", "configspace": "", "generation": 43, "fitness": 0.7852293196646705, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.024. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.7676765024551725, 0.8193149931213869, 0.7686964634174519], "final_y": [0.14951814770938365, 0.14528829958440415, 0.16032127703214494]}, "mutation_prompt": null}
{"id": "9c6e680e-3021-4a79-b43d-f813eb16bef7", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n                \n                # Adaptive velocity boundary control\n                velocities[i] = np.where(positions[i] == func.bounds.lb, np.abs(velocities[i]), velocities[i])\n                velocities[i] = np.where(positions[i] == func.bounds.ub, -np.abs(velocities[i]), velocities[i])\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Adaptive velocity boundary control for enhanced maneuverability within constrained search spaces.", "configspace": "", "generation": 44, "fitness": 0.864108081228031, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.034. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8585291907012143, 0.8249478036521807, 0.908847249330698], "final_y": [0.1328884168113721, 0.13295731299735947, 0.11765258932949796]}, "mutation_prompt": null}
{"id": "e81bf684-fa81-4124-8fe3-a01ffe5c1263", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update cognitive and social components dynamically\n                self.c1 = 1.5 + 1.5 * (eval_count / self.budget)\n                self.c2 = 2.5 - 1.5 * (eval_count / self.budget)\n\n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive cognitive and social components for enhanced dynamic response in swarm behavior.", "configspace": "", "generation": 45, "fitness": 0.8339950571098603, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.042. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8728274553622267, 0.8533577752209845, 0.7757999407463698], "final_y": [0.1302110854714198, 0.13440596181984887, 0.16608824507064424]}, "mutation_prompt": null}
{"id": "a243596e-cf3e-4a66-8242-325a35449cd8", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Adaptive cognitive and social components\n                self.c1 = 1.5 + 0.5 * (eval_count / self.budget)\n                self.c2 = 2.5 - 0.5 * (eval_count / self.budget)\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive cognitive and social coefficients for enhanced convergence behavior.", "configspace": "", "generation": 46, "fitness": 0.8545004090467739, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.017. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8653284074020386, 0.8298922860426617, 0.8682805336956215], "final_y": [0.12847780406237774, 0.14311370777904064, 0.1269669694628256]}, "mutation_prompt": null}
{"id": "086f9f73-aa86-46ac-854f-56a9b06c34fe", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update cognitive and social components dynamically\n                adaptive_c1 = self.c1 - (1.5 * (eval_count / self.budget))\n                adaptive_c2 = self.c2 + (1.5 * (eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + adaptive_c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + adaptive_c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced velocity update with adaptive cognitive and social coefficients to improve convergence.", "configspace": "", "generation": 47, "fitness": 0.86140531733498, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.012. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8556868267102168, 0.8510222782514711, 0.8775068470432525], "final_y": [0.13479762231193715, 0.13784007292907363, 0.12910632875464223]}, "mutation_prompt": null}
{"id": "e384b876-e959-4961-abc1-211a3d54a562", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Adaptive cognitive and social components\n                self.c1 = 1.5 + (1.0 * eval_count / self.budget)\n                self.c2 = 2.5 - (1.0 * eval_count / self.budget)\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduced adaptive cognitive and social components for enhanced convergence in Collaborative Swarm Search.", "configspace": "", "generation": 48, "fitness": 0.8255644674969785, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.033. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8697571445473785, 0.8152413435561295, 0.7916949143874279], "final_y": [0.12732600385424653, 0.1519025314912993, 0.15518951618103838]}, "mutation_prompt": null}
{"id": "5c9b2e0c-bbf0-4883-ae95-72f08515d9fd", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically using a nonlinear function\n                self.inertia_weight = 0.4 + (0.5 * (np.cos((eval_count / self.budget) * np.pi / 2) ** 2))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introducing nonlinear inertia weight adjustment to further enhance exploration-exploitation balance.", "configspace": "", "generation": 49, "fitness": 0.8614309595688333, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.012. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8563056580904113, 0.849658413365314, 0.8783288072507751], "final_y": [0.13445057452865017, 0.13707578670746556, 0.13055349501293234]}, "mutation_prompt": null}
{"id": "fb57dbc1-36b4-4a36-97da-4e560fd822ef", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update cognitive and social components dynamically\n                self.c1 = 1.5 + 0.5 * (eval_count / self.budget)\n                self.c2 = 2.5 - 0.5 * (eval_count / self.budget)\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Add dynamic adjustment to the cognitive and social components to enhance convergence and exploration balance.", "configspace": "", "generation": 50, "fitness": 0.8545004090467739, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.017. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8653284074020386, 0.8298922860426617, 0.8682805336956215], "final_y": [0.12847780406237774, 0.14311370777904064, 0.1269669694628256]}, "mutation_prompt": null}
{"id": "6a25e669-8896-4a64-b625-564eaff86b9b", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n\n                # Adaptive cognitive and social components\n                self.c1 = 2.0 - (1.5 * eval_count / self.budget)  # Adaptive cognitive component\n                self.c2 = 1.5 + (0.5 * eval_count / self.budget)  # Adaptive social component\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduced adaptive cognitive and social parameters for improved convergence in Particle Swarm Optimization.", "configspace": "", "generation": 51, "fitness": 0.8429441945113686, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.028. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8035271540147416, 0.8680118922015962, 0.8572935373177677], "final_y": [0.15524977062038237, 0.13197310575732668, 0.13686416317444272]}, "mutation_prompt": null}
{"id": "3a827b7e-8744-4ac0-bdf7-e78e385da528", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Diversity mechanism: perturb personal best positions\n                if eval_count % 10 == 0:\n                    personal_best_positions[i] += np.random.normal(0, 0.1, self.dim)\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce a diversity mechanism by perturbing personal best positions at regular intervals for improved exploration.", "configspace": "", "generation": 52, "fitness": 0.8519765887978816, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.008. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8562730004807209, 0.8582923379091514, 0.8413644280037725], "final_y": [0.13173857688683166, 0.12418417863460063, 0.13979917937989939]}, "mutation_prompt": null}
{"id": "65f98d84-2bc5-4923-b2d0-ad76874d4681", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.5\n\n    def __call__(self, func):\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n        neighborhood_size = 3  # Start with a small neighborhood\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                neighbors = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                local_best_position = min(neighbors, key=lambda idx: personal_best_scores[idx])\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[local_best_position] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n\n                positions[i] = positions[i] + velocities[i]\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                score = func(positions[i])\n                eval_count += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            neighborhood_size = min(neighborhood_size + 1, self.population_size)\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive dynamic neighborhood selection to enhance exploitation in the swarm's local search.", "configspace": "", "generation": 53, "fitness": 0.8025636050076334, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.034. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.83092599821187, 0.8213569376624877, 0.7554078791485423], "final_y": [0.1389286230601816, 0.14372494108158707, 0.17140062713053217]}, "mutation_prompt": null}
{"id": "3b47da7a-6caa-4bc8-9e25-14bb786c6833", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Dynamic population size adjustment\n            self.population_size = int(10 + 5 * (eval_count / self.budget))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n\n                # Adaptive velocity scaling\n                scaling_factor = np.random.uniform(0.5, 1.5)  # Modified scaling range\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduced dynamic population size and adaptive velocity scaling for enhanced exploration-exploitation trade-off.", "configspace": "", "generation": 54, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {}, "mutation_prompt": null}
{"id": "206083d4-5325-4e1e-ba37-94977894c864", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Updated cognitive component\n        self.c2 = 2.0  # Updated social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                adaptive_c1 = self.c1 * (1 - eval_count / self.budget)  # Adaptive cognitive component\n                adaptive_c2 = self.c2 * (eval_count / self.budget)  # Adaptive social component\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + adaptive_c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + adaptive_c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduced adaptive cognitive and social components to enhance swarm intelligence for better convergence.", "configspace": "", "generation": 55, "fitness": 0.7852293196646705, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.024. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.7676765024551725, 0.8193149931213869, 0.7686964634174519], "final_y": [0.14951814770938365, 0.14528829958440415, 0.16032127703214494]}, "mutation_prompt": null}
{"id": "6b756e5a-8e50-45c1-adb2-7404a375ae4f", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            self.population_size = max(5, self.population_size - 1)  # Adaptive population size\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Incorporate adaptive population size for enhanced exploration-exploitation balance.", "configspace": "", "generation": 56, "fitness": 0.8275038618376155, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.021. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8072739665490627, 0.8182073395981815, 0.8570302793656023], "final_y": [0.1531027126985366, 0.15078894897279393, 0.1368775901181869]}, "mutation_prompt": null}
{"id": "6a955d94-32de-4d94-aaea-e446c5dc2f7a", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                # Adaptive cognitive and social components\n                adaptive_c1 = self.c1 * (1 - eval_count / self.budget)\n                adaptive_c2 = self.c2 * (eval_count / self.budget)\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + adaptive_c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + adaptive_c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduced adaptive cognitive and social components for enhanced exploration-exploitation balance.", "configspace": "", "generation": 57, "fitness": 0.7852293196646705, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.024. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.7676765024551725, 0.8193149931213869, 0.7686964634174519], "final_y": [0.14951814770938365, 0.14528829958440415, 0.16032127703214494]}, "mutation_prompt": null}
{"id": "cec6d92f-afeb-4bde-8281-7de745b21359", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update cognitive and social components adaptively\n                self.c1 = 2.5 - 1.5 * (eval_count / self.budget)\n                self.c2 = 1.5 + 1.5 * (eval_count / self.budget)\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduced adaptive cognitive and social components for improved convergence.  ", "configspace": "", "generation": 58, "fitness": 0.8526168171427791, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.015. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8582461410378378, 0.8323728381346047, 0.867231472255895], "final_y": [0.13219222905679717, 0.14478957603724762, 0.13396131450801452]}, "mutation_prompt": null}
{"id": "87bbcc82-46d0-454f-b015-df5259abfcd4", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.5 + (0.3 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = 0.5 + np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced dynamic inertia weight and stochastic scaling for improved convergence.", "configspace": "", "generation": 59, "fitness": 0.8488689039326509, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.008. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8394604282396423, 0.8480472963529734, 0.859098987205337], "final_y": [0.13234141674461386, 0.13624759430376754, 0.128692544465277]}, "mutation_prompt": null}
{"id": "c714b7e9-76f3-426d-acac-07deb7802cdf", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(10, dim)  # Adaptive population size\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position\n                positions[i] = positions[i] + velocities[i]\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive population size for enhanced exploration-exploitation balance.", "configspace": "", "generation": 60, "fitness": 0.8740733576641317, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.021. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.845121878862958, 0.8962610487130878, 0.8808371454163494], "final_y": [0.13866478025596152, 0.12084875228341285, 0.12993091529339762]}, "mutation_prompt": null}
{"id": "45ceb80d-999c-4b4b-8858-21f85e56ff91", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Update position with adaptive random spread\n                positions[i] = positions[i] + velocities[i] + np.random.normal(0, 0.1, self.dim)\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhance position update strategy with adaptive random spread for better exploration-exploitation balance.", "configspace": "", "generation": 61, "fitness": 0.8596750103175449, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.018. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8348805644689762, 0.8655981026284556, 0.8785463638552028], "final_y": [0.13070238726286654, 0.1179480234260506, 0.12377277876149118]}, "mutation_prompt": null}
{"id": "1fc19f5b-2bbd-4649-823d-6a8d10b04ad0", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search\n                local_search_step = np.random.uniform(-0.1, 0.1, self.dim)  # Local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive local search to enhance convergence in CollaborativeSwarmSearch.", "configspace": "", "generation": 62, "fitness": 0.8766362855697651, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.016. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c5f9b571-7135-4099-9c4d-6a145ebea2b4", "metadata": {"aucs": [0.8568063241878399, 0.8776193266874527, 0.8954832058340028], "final_y": [0.1308802516602141, 0.11927227337389668, 0.11393940464851648]}, "mutation_prompt": null}
{"id": "8df5bec2-681b-4ded-9b97-24d19f31b88c", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with dynamic scaling based on progress\n                scaling_factor = np.random.uniform(0.5, 1.5) * (1 - eval_count / self.budget)  # Dynamic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply dynamic scaling\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search\n                local_search_step = np.random.uniform(-0.1, 0.1, self.dim)  # Local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Integrate dynamic velocity scaling based on evaluation progress in CollaborativeSwarmSearch.", "configspace": "", "generation": 63, "fitness": 0.8656642984575896, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.030. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "1fc19f5b-2bbd-4649-823d-6a8d10b04ad0", "metadata": {"aucs": [0.8310111781951437, 0.8609834633355136, 0.9049982538421119], "final_y": [0.13393150435575873, 0.12127328864598119, 0.1112793170409796]}, "mutation_prompt": null}
{"id": "aa432576-f29d-4177-8b11-709aef3bce33", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search\n                local_search_step = np.random.uniform(-0.1, 0.1, self.dim)  # Local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                \n                # Introduce mutation mechanism\n                mutation_prob = 0.1\n                if np.random.rand() < mutation_prob:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n                \n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhance CollaborativeSwarmSearch by integrating a mutation mechanism to improve exploration capabilities.", "configspace": "", "generation": 64, "fitness": 0.8695823670006665, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.005. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "1fc19f5b-2bbd-4649-823d-6a8d10b04ad0", "metadata": {"aucs": [0.8693869803503803, 0.8756756442308394, 0.8636844764207796], "final_y": [0.11743266919336859, 0.11967705985954091, 0.12082807946480889]}, "mutation_prompt": null}
{"id": "082fa3fc-b6f4-485b-843a-e3e5c6a1c854", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n\n                # Dynamic adjustment of cognitive and social components\n                self.c1 = 1.5 + 1.5 * (1 - eval_count / self.budget)\n                self.c2 = 1.5 + 1.5 * eval_count / self.budget\n\n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search\n                local_search_step = np.random.uniform(-0.1, 0.1, self.dim)  # Local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce dynamic adjustment of cognitive and social components to enhance convergence in CollaborativeSwarmSearch.", "configspace": "", "generation": 65, "fitness": 0.8580365523696237, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.009. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "1fc19f5b-2bbd-4649-823d-6a8d10b04ad0", "metadata": {"aucs": [0.8470591029464903, 0.8578074296907878, 0.8692431244715932], "final_y": [0.13048742422208237, 0.1282985951144886, 0.13057527520799872]}, "mutation_prompt": null}
{"id": "f99a5dec-a622-49bd-ab8a-30043d0466aa", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce dynamic population size adjustment and enhanced local search for improved convergence in CollaborativeSwarmSearch.", "configspace": "", "generation": 66, "fitness": 0.8888814362700505, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.024. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "1fc19f5b-2bbd-4649-823d-6a8d10b04ad0", "metadata": {"aucs": [0.8595534441615199, 0.887680511761766, 0.9194103528868657], "final_y": [0.13056355908973594, 0.11796272491459214, 0.11151366402527774]}, "mutation_prompt": null}
{"id": "601ce281-f27a-459b-b266-c36722e078cc", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                adaptive_lr = np.random.rand() * 0.1  # Adaptive learning rate\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * adaptive_lr * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce an adaptive learning rate to velocities and integrate a diversity mechanism to improve convergence in CollaborativeSwarmSearch.", "configspace": "", "generation": 67, "fitness": 0.7623978077989616, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.762 with standard deviation 0.040. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "f99a5dec-a622-49bd-ab8a-30043d0466aa", "metadata": {"aucs": [0.7199495153200497, 0.815414840706691, 0.7518290673701442], "final_y": [0.1883986938439881, 0.14752061283787343, 0.16108971864197386]}, "mutation_prompt": null}
{"id": "192c3e58-14bb-4b78-a027-394cd7d786ad", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            elite_threshold = np.percentile(personal_best_scores, 20)  # Elite selection threshold\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.3 + (0.7 * (1 - eval_count / self.budget))  # Enhanced adaptive inertia\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best, considering elite\n                if score < global_best_score and score < elite_threshold:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce elite selection and adaptive inertia weight for improved convergence in CollaborativeSwarmSearch.", "configspace": "", "generation": 68, "fitness": 0.8753952596340665, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.029. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f99a5dec-a622-49bd-ab8a-30043d0466aa", "metadata": {"aucs": [0.8465492627702521, 0.8640009816421712, 0.9156355344897764], "final_y": [0.1317752439394756, 0.11850050111902521, 0.11176047146271006]}, "mutation_prompt": null}
{"id": "986f717b-33f5-4bd9-b135-d97683f48f09", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Introduce chaotic inertia weight\n                self.inertia_weight = 0.5 + (0.5 * np.sin(2 * np.pi * eval_count / self.budget))\n                \n                # Update velocity with adaptive scaling\n                scaling_factor = np.random.exponential(scale=1.0)  # Adaptive scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce chaotic inertia weight and adaptive velocity scaling to improve convergence stability in CollaborativeSwarmSearch.", "configspace": "", "generation": 69, "fitness": 0.8681267381584954, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.019. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f99a5dec-a622-49bd-ab8a-30043d0466aa", "metadata": {"aucs": [0.8413942293601508, 0.8791551864878788, 0.8838307986274567], "final_y": [0.12898020508459007, 0.12114782524067857, 0.11343528806856762]}, "mutation_prompt": null}
{"id": "4d770e22-acac-46ad-9b55-abd7184a64a8", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                learning_rate = 0.1 + 0.9 * (1 - eval_count / self.budget)  # Adaptive learning rate\n                velocities[i] = (\n                    learning_rate * (scaling_factor * self.inertia_weight * velocities[i])  # Apply learning rate\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Integrate adaptive learning rates and stochastic momentum to enhance the convergence speed and robustness of CollaborativeSwarmSearch.", "configspace": "", "generation": 70, "fitness": 0.8884641309696505, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.029. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f99a5dec-a622-49bd-ab8a-30043d0466aa", "metadata": {"aucs": [0.8488916946219274, 0.8981443818040467, 0.9183563164829772], "final_y": [0.1305158516643754, 0.1166955141016035, 0.11230853666569396]}, "mutation_prompt": null}
{"id": "aae821ec-80c3-4446-8f11-fe04405200b0", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhanced velocity update using adaptive inertia and diversity promotion for improved convergence in CollaborativeSwarmSearch.", "configspace": "", "generation": 71, "fitness": 0.8888814362700505, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.024. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f99a5dec-a622-49bd-ab8a-30043d0466aa", "metadata": {"aucs": [0.8595534441615199, 0.887680511761766, 0.9194103528868657], "final_y": [0.13056355908973594, 0.11796272491459214, 0.11151366402527774]}, "mutation_prompt": null}
{"id": "19e8005a-5522-44e1-a4c6-95ce62c53d08", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i]  # Apply scaling factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce hybrid mutation strategy\n                mutation = np.random.normal(0, 0.1, self.dim)  # Hybrid mutation step\n                positions[i] = positions[i] + velocities[i] + mutation\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce hybrid mutation strategy and adaptive cognition for improved exploration in CollaborativeSwarmSearch.", "configspace": "", "generation": 72, "fitness": 0.870129558979643, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.003. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f99a5dec-a622-49bd-ab8a-30043d0466aa", "metadata": {"aucs": [0.8742337942458013, 0.8687505489178992, 0.8674043337752283], "final_y": [0.11721062564736062, 0.1264709504349436, 0.12798291691253205]}, "mutation_prompt": null}
{"id": "9918417e-a593-4e85-abcf-f391a816f11f", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce velocity damping to enhance stability and convergence in the CollaborativeSwarmSearch algorithm.", "configspace": "", "generation": 73, "fitness": 0.8891668395280717, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.026. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "f99a5dec-a622-49bd-ab8a-30043d0466aa", "metadata": {"aucs": [0.8560322866579614, 0.8917862737556337, 0.9196819581706202], "final_y": [0.13241395898923936, 0.11651472881492797, 0.11209133566725005]}, "mutation_prompt": null}
{"id": "2cac352f-360b-41dd-bb34-6ed9c45badc1", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  \n        self.c1 = 2.0  \n        self.c2 = 2.0  \n        self.inertia_weight = 0.5  \n\n    def __call__(self, func):\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                scaling_factor = np.random.rand()  \n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  \n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  \n                positions[i] = positions[i] + velocities[i] + local_search_step\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                score = func(positions[i])\n                eval_count += 1\n\n                # Adaptive adjustment of cognitive and social components\n                self.c1 = 1.5 + (1.5 * eval_count / self.budget)  # Increase cognitive component\n                self.c2 = 2.5 - (1.5 * eval_count / self.budget)  # Decrease social component\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce a fine-tuned exploration-exploitation balance by adapting the cognitive and social components dynamically.", "configspace": "", "generation": 74, "fitness": 0.8671798036938781, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.029. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8672346878839743, 0.9030077831368823, 0.8312969400607777], "final_y": [0.12578640799927432, 0.11628805054558733, 0.13775761181499713]}, "mutation_prompt": null}
{"id": "4e38d0a0-a38e-4130-b9dc-198b93e9e929", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + (self.c1 - 1.5 * eval_count / self.budget) * np.random.rand() * (personal_best_positions[i] - positions[i])  # Adaptive c1\n                    + (self.c2 + 1.5 * eval_count / self.budget) * np.random.rand() * (global_best_position - positions[i])  # Adaptive c2\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce dynamic population size control and adaptive cognitive-social balance to enhance the optimization process.", "configspace": "", "generation": 75, "fitness": 0.874841264876304, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.026. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8498736084743748, 0.864668101180589, 0.9099820849739482], "final_y": [0.131549737195786, 0.11928924849185174, 0.11137899307223398]}, "mutation_prompt": null}
{"id": "70c08124-2391-40cf-8d76-a5f8cd7d0c10", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.3 * (1 - eval_count / self.budget))  \n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                positions[i] += np.random.uniform(-0.05, 0.05, self.dim)  # Introduce position randomization\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce position randomization and dynamic inertia scaling for enhanced exploration and convergence in the CollaborativeSwarmSearch algorithm.", "configspace": "", "generation": 76, "fitness": 0.8735908424703314, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.020. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8471429535114721, 0.879297777428685, 0.8943317964708372], "final_y": [0.1315675355564555, 0.11746773607400995, 0.12028330573867085]}, "mutation_prompt": null}
{"id": "031330ec-4cbf-4877-baab-1ae38a9efe14", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * (np.random.rand() + 0.5 * (eval_count / self.budget)) * (personal_best_positions[i] - positions[i])  # Change made here\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Integrate dynamic cognitive and social weights to adaptively balance exploration and exploitation in CollaborativeSwarmSearch.", "configspace": "", "generation": 77, "fitness": 0.8889194473314755, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.030. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8463593097301212, 0.9072501878892778, 0.9131488443750277], "final_y": [0.1322744753952667, 0.11721107527858021, 0.11427695678595629]}, "mutation_prompt": null}
{"id": "8ca05f0c-5a8c-42d9-b88d-b3ceae28f418", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                perturbation = np.random.normal(0, 0.1, self.dim)  # Introduce perturbation for exploration\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.9  # Adaptive velocity scaling\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step + perturbation\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhance global exploration by introducing perturbation and adaptive velocity scaling to improve convergence in CollaborativeSwarmSearch.", "configspace": "", "generation": 78, "fitness": 0.8772265907359459, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.013. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8620535621589352, 0.8932717297889814, 0.8763544802599211], "final_y": [0.13041853831197758, 0.11563881209456761, 0.127332986011637]}, "mutation_prompt": null}
{"id": "d55342b1-d7fb-4841-a6e7-df378c6130dd", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * np.cos(np.pi * eval_count / self.budget))  # Nonlinear decay\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Apply nonlinear inertia weight decay to improve the exploitation-exploration balance in the CollaborativeSwarmSearch algorithm.", "configspace": "", "generation": 79, "fitness": 0.8869141273057446, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.030. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8460085010122622, 0.8980422282227294, 0.9166916526822422], "final_y": [0.13277324420572068, 0.11638298401045144, 0.1115844196097805]}, "mutation_prompt": null}
{"id": "19d43f72-ec8f-4a23-a061-898ecab04374", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with adaptive scaling\n                scaling_factor = 0.7 + 0.3 * np.random.rand()  # Adaptive scaling factor\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive velocity scaling to balance exploration and exploitation in the CollaborativeSwarmSearch algorithm.", "configspace": "", "generation": 80, "fitness": 0.8615170040751764, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.018. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8438093836127586, 0.8540963419622394, 0.8866452866505312], "final_y": [0.1304679525076874, 0.11750311435998395, 0.11970325765875045]}, "mutation_prompt": null}
{"id": "0675b8f9-9aa2-44dc-b96c-28951e77eb59", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n\n                # Introduce adaptive coefficients\n                self.c1 = 2.5 - 1.5 * (eval_count / self.budget)\n                self.c2 = 0.5 + 1.5 * (eval_count / self.budget)\n\n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhance exploration by introducing adaptive cognitive and social coefficients with nonlinear time-varying behavior in CollaborativeSwarmSearch.", "configspace": "", "generation": 81, "fitness": 0.8430971199523318, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.026. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.812016240574673, 0.8753965449881024, 0.8418785742942199], "final_y": [0.12436415059235695, 0.11662033596737909, 0.11612059752789772]}, "mutation_prompt": null}
{"id": "b34c8c7f-0c9a-42e4-b47f-8c1b9fe5f77c", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(8 + 2 * np.sin(np.pi * eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.3 * np.cos(np.pi * eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Refine the inertia weight and population size dynamics to enhance diversity and convergence in the CollaborativeSwarmSearch algorithm.", "configspace": "", "generation": 82, "fitness": 0.8712829070822657, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.015. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8504345646792817, 0.8785077451278455, 0.8849064114396702], "final_y": [0.13059406094239956, 0.11912497427343127, 0.11267790511550713]}, "mutation_prompt": null}
{"id": "d5b2774d-7ecc-4ce5-8bc0-e38808dc37d9", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n\n                # Update velocity with stochastic scaling and chaos factor\n                scaling_factor = np.random.rand()  \n                chaos_factor = np.random.uniform(-0.1, 0.1, self.dim)  # Introduce chaos factor\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                    + chaos_factor  # Add chaos factor to enhance exploration\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhance global exploration by introducing a chaos factor to improve solution diversity in CollaborativeSwarmSearch.", "configspace": "", "generation": 83, "fitness": 0.8841559344313765, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.033. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8375457175952725, 0.9064273988961281, 0.9084946868027288], "final_y": [0.13231000114158353, 0.11637533661296551, 0.11082348995316771]}, "mutation_prompt": null}
{"id": "40cb0d83-7c2c-42cf-9900-9f670f1f602e", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + (self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])) * (1 - eval_count / self.budget)  # Adaptive c1\n                    + (self.c2 * np.random.rand() * (global_best_position - positions[i])) * (eval_count / self.budget)  # Adaptive c2\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive cognitive and social coefficients to enhance exploration and exploitation balance in CollaborativeSwarmSearch.", "configspace": "", "generation": 84, "fitness": 0.8142236479530984, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.021. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.7938658034838921, 0.8433121470757631, 0.80549299329964], "final_y": [0.13143733717804928, 0.12051859218426242, 0.11958010681851672]}, "mutation_prompt": null}
{"id": "772460c0-4536-4f38-9dff-19ea4f8c0fbb", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling and dynamic cognitive-social trade-off\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                phi = np.random.rand()  # Dynamic trade-off factor\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + phi * self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + (1.0 - phi) * self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhance exploration by introducing a dynamic cognitive-social trade-off in the velocity update formula.", "configspace": "", "generation": 85, "fitness": 0.8628132402340616, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.016. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8468279148398619, 0.8576299464392108, 0.8839818594231122], "final_y": [0.12852253542550818, 0.12366629325630263, 0.11287707626070975]}, "mutation_prompt": null}
{"id": "cb5f3fc7-6986-400a-88b9-699f19b2b438", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.5\n\n    def __call__(self, func):\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                scaling_factor = np.random.rand()\n                leader_influence = 0.001 * np.random.randn(self.dim)  # Introduce leader influence\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.9  # Adaptive damping\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                    + leader_influence\n                )\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                score = func(positions[i])\n                eval_count += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce leader influence mechanism and adaptive damping to enhance global exploration and convergence in CollaborativeSwarmSearch.", "configspace": "", "generation": 86, "fitness": 0.8727604388702878, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.030. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8359594058085089, 0.909300262496155, 0.8730216483061992], "final_y": [0.13063991378595863, 0.11626931383270789, 0.12751949316157152]}, "mutation_prompt": null}
{"id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Increase the cognitive component slightly in CollaborativeSwarmSearch to enhance individual learning.", "configspace": "", "generation": 87, "fitness": 0.9060735889495342, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.013. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9918417e-a593-4e85-abcf-f391a816f11f", "metadata": {"aucs": [0.8881515294264608, 0.9116067531717683, 0.9184624842503734], "final_y": [0.11208435958184881, 0.11624092266131658, 0.11085781903400105]}, "mutation_prompt": null}
{"id": "61cc1040-0a9a-4b28-81fd-e54abe58650a", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                scaling_factor = np.random.rand()\n                exploration_component = np.random.uniform(-0.1, 0.1, self.dim)  # Additional exploration\n                \n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                \n                local_search_step = velocities[i] * np.random.uniform(0.8, 1.2) + exploration_component  # Adaptive scaling\n                positions[i] = positions[i] + local_search_step\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                score = func(positions[i])\n                eval_count += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhance local search with adaptive velocity scaling and additional exploration component.", "configspace": "", "generation": 88, "fitness": 0.8566198066063792, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.005. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8553758716749138, 0.8633252693181233, 0.8511582788261002], "final_y": [0.13164403359564236, 0.12365495558113726, 0.128136543380707]}, "mutation_prompt": null}
{"id": "80567531-5025-4320-baa1-73a123e38d4a", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            elite_threshold = max(1, self.population_size // 3)  # Elitism: top third retain\n            top_indices = np.argsort(personal_best_scores)[:elite_threshold]\n            elite_positions = personal_best_positions[top_indices]\n\n            for i in range(self.population_size):\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                scaling_factor = np.random.rand()\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                score = func(positions[i])\n                eval_count += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            # Reintroduce elite particles to maintain diversity\n            positions[:elite_threshold] = elite_positions\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhance collaborative learning by introducing an elitism strategy to retain the best particles, stabilizing convergence, and improving solution quality.", "configspace": "", "generation": 89, "fitness": 0.8756077396727878, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.028. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8469577147453575, 0.866377652011235, 0.9134878522617709], "final_y": [0.13471248469245423, 0.11805956764815517, 0.1110191097872798]}, "mutation_prompt": null}
{"id": "b23a7c93-632c-4ef9-b7ea-091d974acf2e", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                self.c2 = 1.5 + 0.5 * np.random.rand()  # Dynamic social component\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Randomly reinitialize some particles to prevent local stagnation\n                if np.random.rand() < 0.05:\n                    positions[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce a dynamic social component and incorporate random reinitialization to enhance exploration in CollaborativeSwarmSearch.", "configspace": "", "generation": 90, "fitness": 0.8623732076538699, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.030. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8323743317351688, 0.9029515132127863, 0.8517937780136546], "final_y": [0.13625974705059307, 0.11683332881618447, 0.12715284526266157]}, "mutation_prompt": null}
{"id": "b69db86c-3e36-48c9-aa63-934b819572bf", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                neighborhood_best_position = np.mean(personal_best_positions, axis=0)  # Neighborhood-based update\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                    + 0.5 * np.random.rand() * (neighborhood_best_position - positions[i])  # Neighborhood influence\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Enhance swarm intelligence by incorporating a neighborhood-based communication mechanism to bolster exploration and exploitation balance.", "configspace": "", "generation": 91, "fitness": 0.825312547065194, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.002. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8279928678410511, 0.8259247342622283, 0.8220200390923025], "final_y": [0.13910744325714164, 0.13367422118688943, 0.14268290003109152]}, "mutation_prompt": null}
{"id": "2d5e8f53-1d15-444e-b60d-88cb49408a01", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n        self.stagnation_threshold = 20  # New: Stagnation threshold for reinitialization\n\n    def __call__(self, func):\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n        stagnation_counter = np.zeros(self.population_size)  # New: Track stagnation for each particle\n\n        while eval_count < self.budget:\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                scaling_factor = np.random.rand()\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                score = func(positions[i])\n                eval_count += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_counter[i] = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter[i] += 1  # Increment stagnation counter\n\n                if stagnation_counter[i] > self.stagnation_threshold:  # New: Reinitialize stagnating particle\n                    positions[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                    stagnation_counter[i] = 0\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce random reinitialization for stagnating particles and enhanced diversity in CollaborativeSwarmSearch.", "configspace": "", "generation": 92, "fitness": 0.9050418034582504, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.014. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8850561880783041, 0.9116067380460735, 0.9184624842503734], "final_y": [0.11346087783638492, 0.11623710829300926, 0.11085781903400105]}, "mutation_prompt": null}
{"id": "cc636521-ba26-4fea-add4-a2d52f470297", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.3 + (0.7 * (1 - eval_count / self.budget))  # Modified line\n                \n                # Update velocity with stochastic scaling and diversity enhancement\n                scaling_factor = np.random.rand()\n                diversity_factor = np.random.uniform(-0.1, 0.1, self.dim)  # New line\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  \n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                    + diversity_factor  # New line\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  \n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introducing diversity-enhanced velocity and dynamic inertia adjustment to the CollaborativeSwarmSearch for improved exploration and exploitation balance.", "configspace": "", "generation": 93, "fitness": 0.8767821095070453, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.020. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8482540389750766, 0.8886648975155977, 0.8934273920304614], "final_y": [0.13113512758866785, 0.11640347999460621, 0.11825345850503943]}, "mutation_prompt": null}
{"id": "a1d472a5-c92b-4852-9678-df5da7611f38", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                # Introduce feedback for dynamic social component adjustment\n                self.c2 = 1.5 + 0.5 * (global_best_score / np.min(personal_best_scores))\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce a feedback mechanism to adjust the social component dynamically.", "configspace": "", "generation": 94, "fitness": 0.9060735889495342, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.013. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8881515294264608, 0.9116067531717683, 0.9184624842503734], "final_y": [0.11208435958184881, 0.11624092266131658, 0.11085781903400105]}, "mutation_prompt": null}
{"id": "76c5c652-f97b-434b-a367-2b75d307cd63", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adaptive inertia weight based on convergence speed\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with dynamic social component\n                velocities[i] = (\n                    self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + (self.c2 * (eval_count / self.budget)) * np.random.rand() * (global_best_position - positions[i])  # Dynamic social component\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce a dynamic update to the social component and adaptive inertia decay based on convergence speed in the CollaborativeSwarmSearch to enhance global exploration.", "configspace": "", "generation": 95, "fitness": 0.8437123919192069, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8323387495375086, 0.8602679680880703, 0.8385304581320417], "final_y": [0.11711742978812001, 0.11713887654913868, 0.12570528100631895]}, "mutation_prompt": null}
{"id": "2c13d184-a02b-40f3-88f4-48dbb74b6d67", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.9  # Modify velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Fine-tune velocity damping for a more balanced exploration-exploitation trade-off in CollaborativeSwarmSearch.", "configspace": "", "generation": 96, "fitness": 0.8903122695286089, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.024. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8584719169907239, 0.8972848488783827, 0.9151800427167198], "final_y": [0.1304983668320322, 0.11764358037350808, 0.11039903914028026]}, "mutation_prompt": null}
{"id": "8f26488f-1093-4ae3-b81b-ae85bb196e78", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        # Initialize chaos-based sequence\n        chaotic_sequence = np.random.uniform(0, 1, self.dim)\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step + 0.1 * chaotic_sequence\n                chaotic_sequence = np.mod(4 * chaotic_sequence * (1 - chaotic_sequence), 1)  # Update chaotic sequence\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Incorporate chaotic sequences to enhance the diversity of the swarm in CollaborativeSwarmSearch.", "configspace": "", "generation": 97, "fitness": 0.8795857215601246, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.022. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8486034208294915, 0.8996678559750965, 0.8904858878757856], "final_y": [0.13186934044622145, 0.11633749945553096, 0.12104072116638831]}, "mutation_prompt": null}
{"id": "8fec3063-252e-4758-90bf-1e7c06ed73e1", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically\n                self.inertia_weight = 0.4 + (0.5 * (1 - eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                velocities[i] += np.random.normal(0, 0.1, self.dim)  # Add adaptive velocity perturbation\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce adaptive velocity perturbation for enhanced exploration in CollaborativeSwarmSearch.", "configspace": "", "generation": 98, "fitness": 0.8630186261277797, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.022. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8335081566116745, 0.8847755286773065, 0.8707721930943579], "final_y": [0.13326519794692615, 0.11645537979300402, 0.1207982561354689]}, "mutation_prompt": null}
{"id": "d94a6bd9-39f8-4d33-a8d1-5725fecaa449", "solution": "import numpy as np\n\nclass CollaborativeSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10  # Number of particles in the swarm\n        self.c1 = 2.1  # Cognitive component slightly increased\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.5  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically based on remaining budget\n            self.population_size = max(5, int(10 * (1 - eval_count / self.budget)))\n\n            for i in range(self.population_size):\n                # Adjust inertia weight dynamically with nonlinear decrease\n                self.inertia_weight = 0.4 + (0.5 * np.exp(-3 * eval_count / self.budget))\n                \n                # Update velocity with stochastic scaling\n                scaling_factor = np.random.rand()  # Add stochastic scaling\n                velocities[i] = (\n                    scaling_factor * self.inertia_weight * velocities[i] * 0.95  # Apply velocity damping factor\n                    + self.c1 * np.random.rand() * (personal_best_positions[i] - positions[i])\n                    + self.c2 * np.random.rand() * (global_best_position - positions[i])\n                )\n                # Introduce adaptive local search with enhanced step size\n                local_search_step = np.random.uniform(-0.2, 0.2, self.dim)  # Enhanced local search step\n                positions[i] = positions[i] + velocities[i] + local_search_step\n                # Clamp the positions within bounds\n                positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                score = func(positions[i])\n                eval_count += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                # Check if budget is exhausted\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "CollaborativeSwarmSearch", "description": "Introduce a nonlinear decrease in inertia weight to enhance exploration in early stages and exploitation in later stages.", "configspace": "", "generation": 99, "fitness": 0.90056245635447, "feedback": "The algorithm CollaborativeSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "acb0efd9-c4c5-42a9-a4c8-b4d2d3994402", "metadata": {"aucs": [0.8900474449120537, 0.9005225461539595, 0.9111173779973964], "final_y": [0.11281488150766805, 0.12038813260220138, 0.112118184697792]}, "mutation_prompt": null}
