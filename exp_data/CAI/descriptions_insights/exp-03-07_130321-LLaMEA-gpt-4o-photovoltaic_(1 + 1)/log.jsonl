{"id": "041dec20-48df-4526-990f-03571e22652f", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                candidate = global_best_position + np.random.normal(0, 1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n\n        return global_best_position", "name": "HybridPSOSA", "description": "A hybrid metaheuristic algorithm combining particle swarm optimization (PSO) with a simulated annealing (SA) inspired local search to efficiently explore and exploit the search space for high-performing solutions.", "configspace": "", "generation": 0, "fitness": 0.8881647777582135, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.002. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8899193226902351, 0.8852198818502954, 0.8893551287341095], "final_y": [0.11386423576997595, 0.11974943172050734, 0.1117467784094297]}, "mutation_prompt": null}
{"id": "53843e3b-0bec-4949-a8f1-727ee6141ff4", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                candidate = global_best_position + np.random.normal(0, 1, self.dim) * np.random.standard_cauchy(self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n\n        return global_best_position", "name": "HybridPSOSA", "description": "An enhanced version of HybridPSOSA by integrating a random exploration phase inspired by LÃ©vy flights to improve global search diversity.", "configspace": "", "generation": 1, "fitness": 0.8292379954624396, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.019. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "041dec20-48df-4526-990f-03571e22652f", "metadata": {"aucs": [0.8540491739237229, 0.8088674825167934, 0.8247973299468025], "final_y": [0.1361574228295842, 0.14945967984799646, 0.1395374945322838]}, "mutation_prompt": null}
{"id": "2efaa4e2-a2ee-4ad9-acea-a0bd8dab7477", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            self.inertia_weight *= 0.98  # Dynamically reduce inertia weight\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                candidate = global_best_position + np.random.normal(0, 1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduced a dynamic inertia weight strategy to adaptively balance exploration and exploitation during search.", "configspace": "", "generation": 2, "fitness": 0.8637565156977098, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.018. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "041dec20-48df-4526-990f-03571e22652f", "metadata": {"aucs": [0.8546298432803251, 0.8478063280349253, 0.8888333757778792], "final_y": [0.1256796936073793, 0.1215116376888703, 0.12147234158441622]}, "mutation_prompt": null}
{"id": "81274b2a-fb19-471f-8310-506f06ecc8b5", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9 for better exploration in early iterations\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                candidate = global_best_position + np.random.normal(0, 1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight *= 0.99  # Gradually reduce the inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "An enhanced HybridPSOSA algorithm with adaptive inertia weight and dynamic population size for improved exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8715248738812916, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.012. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "041dec20-48df-4526-990f-03571e22652f", "metadata": {"aucs": [0.8714624372769768, 0.8565062564226433, 0.8866059279442546], "final_y": [0.12018687118853555, 0.12803719641854705, 0.12501406268283533]}, "mutation_prompt": null}
{"id": "555d8ea2-9f79-4159-8f09-6428ac50d951", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Change 1: Increase initial inertia weight for broader exploration\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.98  # Change 2: Slightly decrease cooling rate for more gradual cooling\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                candidate = global_best_position + np.random.normal(0, 1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Adaptive inertia weight adjustment: Decrease over time\n            self.inertia_weight = 0.4 + (0.5 * (self.budget - evaluations) / self.budget)  # Change 3: Adapt inertia weight\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Hybridize enhanced exploration with adaptive inertia weight to boost PSO and SA performance for complex optimization problems.", "configspace": "", "generation": 4, "fitness": 0.872843901832615, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.015. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "041dec20-48df-4526-990f-03571e22652f", "metadata": {"aucs": [0.8683863872243045, 0.856543072589425, 0.8936022456841154], "final_y": [0.120762367129572, 0.1268884783076838, 0.11779276923064275]}, "mutation_prompt": null}
{"id": "65ba8944-4b53-44d8-b515-af023e7495de", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.95  # Changed from 0.99 to 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = (self.inertia_weight - (self.inertia_weight - 0.4) * (evaluations / self.budget)) * velocities + cognitive_term + social_term  # Adaptive inertia\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                candidate = global_best_position + np.random.normal(0, 1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhancements to HybridPSOSA include adaptive inertia weight and diversified SA local search for refined exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.8735007948825751, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.015. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "041dec20-48df-4526-990f-03571e22652f", "metadata": {"aucs": [0.8683826169537964, 0.8584913022917795, 0.8936284654021494], "final_y": [0.12076197635497121, 0.12411332317456492, 0.11778156696285202]}, "mutation_prompt": null}
{"id": "be24eb17-8390-4958-a275-bf690f0e3112", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            w = self.inertia_weight * (self.budget - evaluations) / self.budget\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = w * velocities + cognitive_term + social_term\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n            else:\n                # Random restart if stuck in local optima\n                if np.random.rand() < 0.1:\n                    global_best_position = np.random.uniform(lb, ub, self.dim)\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                candidate = global_best_position + np.random.normal(0, 1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by introducing adaptive inertia weight and random restart for improved exploration-exploitation balance and escaping local optima.", "configspace": "", "generation": 6, "fitness": 0.8871248475119543, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.013. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "041dec20-48df-4526-990f-03571e22652f", "metadata": {"aucs": [0.891195556137396, 0.8691408646238286, 0.9010381217746379], "final_y": [0.11928716813278106, 0.12872635181526237, 0.11372476882664118]}, "mutation_prompt": null}
{"id": "246a67fb-f42b-482e-81cc-881a5385aaf9", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.98  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4  # New: Minimum inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)  # Adjusted perturbation\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)  # Dynamic inertia weight adjustment\n\n        return global_best_position", "name": "HybridPSOSA", "description": "An enhanced hybrid algorithm combining PSO with a more adaptive SA-inspired local search, integrating dynamic inertia and cooling schedules to improve exploration and convergence.", "configspace": "", "generation": 7, "fitness": 0.8895314112938442, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.005. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "041dec20-48df-4526-990f-03571e22652f", "metadata": {"aucs": [0.8903519790894101, 0.8833782944639683, 0.8948639603281539], "final_y": [0.11819536960997434, 0.12441863522727725, 0.1142410999166118]}, "mutation_prompt": null}
{"id": "cb122a3e-bf9f-4a4e-8e03-da0467b5f0a2", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 20 - dim // 10)  # Adjusted adaptive population size\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.98  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4  # New: Minimum inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 0.5, self.dim) * (self.temperature / 1000)  # Adjusted perturbation scale\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)  # Dynamic inertia weight adjustment\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with adaptive population size and improved SA perturbation for more efficient search and convergence.", "configspace": "", "generation": 8, "fitness": 0.8715192837674156, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.038. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "246a67fb-f42b-482e-81cc-881a5385aaf9", "metadata": {"aucs": [0.830171821191508, 0.8623952564445931, 0.9219907736661458], "final_y": [0.132751007154713, 0.12745456760262253, 0.11228462247621707]}, "mutation_prompt": null}
{"id": "014d9cb1-9875-4c47-89a1-b4a7170b8d73", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.97  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4  # New: Minimum inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)  # Adjusted perturbation\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)  # Dynamic inertia weight adjustment\n\n        return global_best_position", "name": "HybridPSOSA", "description": "By introducing a more refined and adaptive cooling schedule for the SA-inspired local search, the hybrid algorithm enhances its exploration and convergence balance.", "configspace": "", "generation": 9, "fitness": 0.8882960222542661, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.004. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "246a67fb-f42b-482e-81cc-881a5385aaf9", "metadata": {"aucs": [0.8865615353551636, 0.8849066626044179, 0.8934198688032171], "final_y": [0.12041620629109784, 0.12146353533382315, 0.11728598792247924]}, "mutation_prompt": null}
{"id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.97  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "A refined hybrid PSO and SA algorithm with improved position update strategy and adaptive cooling for enhanced convergence.", "configspace": "", "generation": 10, "fitness": 0.8921564557457803, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.007. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "246a67fb-f42b-482e-81cc-881a5385aaf9", "metadata": {"aucs": [0.9013512961635548, 0.8842933006333432, 0.8908247704404426], "final_y": [0.11445999375689642, 0.12173174143097665, 0.11686265042067268]}, "mutation_prompt": null}
{"id": "33949145-0e0b-4277-b5ea-41ab76a101af", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 2.0  # Increased social coefficient for improved convergence\n        self.temperature = 1000\n        self.cooling_rate = 0.95  # Adjusted cooling rate for more effective cooling\n        self.min_inertia_weight = 0.4\n        self.dynamic_social_coef = 1.5  # Dynamic social coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            # Implement dynamic social learning factor\n            social_term = (self.social_coef * (evaluations / self.budget) + self.dynamic_social_coef) * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + velocities  # Reverted position update to original for exploration\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "An enhanced hybrid PSO and SA algorithm with a modified position update strategy and dynamic social learning factor for improved optimization performance.", "configspace": "", "generation": 11, "fitness": 0.8705858927970015, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.019. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "metadata": {"aucs": [0.8871447128769989, 0.8440231588887883, 0.8805898066252174], "final_y": [0.12220904129646426, 0.13537578527961158, 0.12614616082081487]}, "mutation_prompt": null}
{"id": "b9907edd-c0ad-4adc-a303-c9463813c28e", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.97  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            # Randomly reset velocities for a small percentage of the population\n            if np.random.rand() < 0.1: \n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced global exploration with random reset of velocities and adaptive social coefficient for better convergence.", "configspace": "", "generation": 12, "fitness": 0.8653058450471529, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.016. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "metadata": {"aucs": [0.8472723601678387, 0.8632151237336605, 0.8854300512399594], "final_y": [0.12764637613498775, 0.12905629453508782, 0.1155262897091387]}, "mutation_prompt": null}
{"id": "565fde4e-df5f-44c4-a1da-52933e203180", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.97  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            self.population_size = max(10, int(self.population_size * 0.95))  # Dynamically adapt population size\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced Hybrid PSO and SA with dynamic population size adaptation for balanced exploration and exploitation.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (19,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (19,10) (20,10) ')", "parent_id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "metadata": {}, "mutation_prompt": null}
{"id": "ce823e6c-60a1-40ac-aa69-70108400c187", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.97  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + 0.6 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced balance between exploration and exploitation by adjusting position update scaling from 0.5 to 0.6.", "configspace": "", "generation": 14, "fitness": 0.8903121110415385, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.019. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "metadata": {"aucs": [0.8654590075174031, 0.8936759433278421, 0.9118013822793706], "final_y": [0.12169904014689392, 0.11703279391412347, 0.11289652878925127]}, "mutation_prompt": null}
{"id": "a8bf62fb-cbfc-450c-9a05-b213fba9b4a6", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7\n        self.temperature = 1000\n        self.cooling_rate = 0.97\n        self.min_inertia_weight = 0.4\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= (1 - evaluations / self.budget)  # Adaptive velocity scaling\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n            # Dynamically adjust population size\n            population_size = int(self.initial_population_size * (1 + (self.budget - evaluations) / self.budget))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with dynamic population size and adaptive velocity scaling for improved convergence.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (38,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (38,10) (20,10) ')", "parent_id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "metadata": {}, "mutation_prompt": null}
{"id": "dd809af8-86a8-4bff-91ca-30551937bd93", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.97  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, np.abs(ub-lb)/10, self.dim)  # Dynamic perturbation scale\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced Hybrid PSO and SA algorithm with adaptive population size and dynamic velocity bounds for improved convergence.", "configspace": "", "generation": 16, "fitness": 0.8034607952386524, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.018. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "metadata": {"aucs": [0.7801092127643353, 0.8078223090350144, 0.8224508639166073], "final_y": [0.15264425842628737, 0.14673863514774943, 0.14319405688033193]}, "mutation_prompt": null}
{"id": "2bc9d543-9eb5-4268-97b0-c979e9b3aeb3", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.97  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            dynamic_social_coef = self.social_coef * (1 - evaluations / self.budget)\n            social_term = dynamic_social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with dynamic social coefficient and adaptive velocity scaling for improved convergence.", "configspace": "", "generation": 17, "fitness": 0.8853095180749507, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.005. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "metadata": {"aucs": [0.8847216797411652, 0.8794095002154165, 0.8917973742682704], "final_y": [0.1185857972606158, 0.12679663103805583, 0.12098324926651705]}, "mutation_prompt": null}
{"id": "f10bf4f1-d91e-470d-ad94-4f3edc4e9916", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Increased initial inertia for better exploration\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7\n        self.temperature = 1000\n        self.cooling_rate = 0.95  # Modified cooling rate for adaptive cooling\n        self.min_inertia_weight = 0.3  # Adjusted minimum inertia weight\n        self.adaptive_perturbation = 0.05  # New adaptive perturbation factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population += 0.6 * velocities  # Adjusted position update for improved balance\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000) * self.adaptive_perturbation\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.98)  # Enhanced dynamic inertia adjustment\n\n        return global_best_position", "name": "HybridPSOSA", "description": "An enhanced hybrid PSO-SA algorithm with dynamic inertia and adaptive perturbation for improved search efficiency.", "configspace": "", "generation": 18, "fitness": 0.873780163020207, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.009. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "metadata": {"aucs": [0.872403148285213, 0.8630925172193387, 0.8858448235560692], "final_y": [0.11425966572695367, 0.12778379042841537, 0.11454656721517409]}, "mutation_prompt": null}
{"id": "7e73c25a-cb22-4790-b46b-264d50c76fb2", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.97  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = 0.9 * global_best_position + 0.1 * population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced global best position update strategy with weighted exploration for improved convergence.", "configspace": "", "generation": 19, "fitness": 0.8524263240444769, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.020. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "metadata": {"aucs": [0.8434147368017801, 0.8342581200419747, 0.8796061152896757], "final_y": [0.12681644029446892, 0.1449314084315656, 0.12502710374416182]}, "mutation_prompt": null}
{"id": "b3bd5c2b-0a36-4743-934d-62e58719f216", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.97  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic population size adjustment\n            self.population_size = max(10, int(self.budget / 10))\n            \n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                # Adaptive perturbation\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 500)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced Hybrid PSO-SA with dynamic population size and adaptive perturbation for improved performance.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (100,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (100,10) (20,10) ')", "parent_id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "metadata": {}, "mutation_prompt": null}
{"id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.96  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)  # Apply adaptive velocity scaling\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "An enhanced hybrid PSO and SA algorithm incorporating Gaussian mutation and adaptive velocity scaling for improved exploration and convergence.", "configspace": "", "generation": 21, "fitness": 0.8924993986965964, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "bbaddae8-2faf-4989-9e9a-0cfb07b78395", "metadata": {"aucs": [0.8942442754658464, 0.8779163602980582, 0.9053375603258845], "final_y": [0.11439338376692665, 0.11981230907147566, 0.1149973600737797]}, "mutation_prompt": null}
{"id": "e808be62-8e46-43aa-b834-32247aab8a39", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Dynamic population size adjustment\n        population_size = max(5, self.population_size - evaluations // 100)\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduced dynamic population size adjustment to enhance exploration and convergence balance.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'evaluations' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'evaluations' referenced before assignment\")", "parent_id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "metadata": {}, "mutation_prompt": null}
{"id": "73d38ed1-cb54-40d4-9adb-94f60a28cd29", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.7  # Adjusted cognitive coefficient for improved personal learning\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(1.0, 0.1, velocities.shape)  # Optimized adaptive velocity scaling\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "A refined hybrid PSO and SA algorithm with optimized cognitive and adaptive velocity scaling for enhanced convergence.", "configspace": "", "generation": 23, "fitness": 0.8873881090543531, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "metadata": {"aucs": [0.887387505555762, 0.8703276988524908, 0.9044491227548062], "final_y": [0.12003777729589293, 0.12134208940115598, 0.11295393808007614]}, "mutation_prompt": null}
{"id": "c6eb755f-9c98-48f0-a491-3a33977298a8", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.96  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)  # Apply adaptive velocity scaling\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation + np.random.standard_normal(self.dim) * (1 / np.abs(np.random.standard_normal(self.dim))**1.5)  # Introduced LÃ©vy flight\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduced a LÃ©vy flight component for exploring distant regions and escaping local optima.", "configspace": "", "generation": 24, "fitness": 0.8455806205454133, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.016. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "metadata": {"aucs": [0.8245925709206161, 0.8637740212534529, 0.8483752694621708], "final_y": [0.13992514631697173, 0.13490751769264764, 0.13926884038554943]}, "mutation_prompt": null}
{"id": "e6075804-193a-4bd0-8d0f-a5ec5141f1b1", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.95  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)  # Apply adaptive velocity scaling\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            dynamic_size = max(10, self.population_size - evaluations // self.budget)  # Dynamic population size adjustment\n            for i in range(dynamic_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with dynamic population size adjustment and improved adaptive cooling for superior convergence.", "configspace": "", "generation": 25, "fitness": 0.8861728431358822, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.018. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "metadata": {"aucs": [0.8743415700134666, 0.8728735614222104, 0.9113033979719696], "final_y": [0.12192211239490025, 0.12240740531673033, 0.11250744165225801]}, "mutation_prompt": null}
{"id": "0e5c5453-12b8-464a-a080-d31b81edf3b3", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.96  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update population size dynamically based on remaining budget\n            dynamic_population_size = max(1, int((self.budget - evaluations) / self.population_size))\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)  # Apply adaptive velocity scaling\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "An enhanced hybrid PSO and SA algorithm with dynamic population size scaling for improved balance between exploration and exploitation.", "configspace": "", "generation": 26, "fitness": 0.8924993986965964, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "metadata": {"aucs": [0.8942442754658464, 0.8779163602980582, 0.9053375603258845], "final_y": [0.11439338376692665, 0.11981230907147566, 0.1149973600737797]}, "mutation_prompt": null}
{"id": "f33fe51e-15de-4d28-8a4d-91eec12ad0d7", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.96  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)  # Apply adaptive velocity scaling\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= (self.cooling_rate * (1 - evaluations/self.budget))  # Adaptive cooling rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n            if evaluations/self.budget > 0.5:  # Dynamic population adjustment\n                self.population_size = max(5, int(self.population_size * 0.9))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduced adaptive cooling rate and dynamic population size adjustment to enhance convergence in HybridPSOSA.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (18,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (18,10) (20,10) ')", "parent_id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "metadata": {}, "mutation_prompt": null}
{"id": "deec01ef-f7e2-4557-be9f-d7f7d2ae3d51", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.9  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.96  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)  # Apply adaptive velocity scaling\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "A refined Hybrid PSO and SA algorithm with enhanced social learning by adjusting the social coefficient.", "configspace": "", "generation": 28, "fitness": 0.8758425665938162, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.011. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "metadata": {"aucs": [0.8858531657638743, 0.8611180430704246, 0.8805564909471496], "final_y": [0.12029322560567457, 0.1264204250351454, 0.11593036463917294]}, "mutation_prompt": null}
{"id": "25e1ce84-165b-4362-8fe1-0baf3c7c6718", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96\n        self.min_inertia_weight = 0.4\n        self.max_population_size = 40  # New: Max population size for dynamic resizing\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # New: Increase population size periodically for exploration\n            if evaluations % (self.budget // 5) == 0 and self.population_size < self.max_population_size:\n                additional_population = np.random.uniform(lb, ub, (5, self.dim))\n                population = np.vstack((population, additional_population))\n                velocities = np.vstack((velocities, np.random.uniform(-1, 1, (5, self.dim))))\n                self.population_size += 5\n\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n            # New: Stochastic restarts if no improvement for a while\n            if evaluations > self.budget * 0.8 and evaluations % (self.budget // 10) == 0:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Improved HybridPSOSA with dynamic population resizing and stochastic restarts for enhanced exploration and convergence.", "configspace": "", "generation": 29, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,10) (25,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,10) (25,10) ')", "parent_id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "metadata": {}, "mutation_prompt": null}
{"id": "602d4754-d066-45d1-b39e-69af4f5a2ec7", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.96  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)  # Apply adaptive velocity scaling\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 1, self.dim) * (self.temperature / 1000)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.985)  # Modified decay rate for inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Improved convergence by modifying the inertia weight decay rate for better exploration-exploitation trade-off.", "configspace": "", "generation": 30, "fitness": 0.8906071217369438, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.010. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "metadata": {"aucs": [0.8885691904160202, 0.879112705866232, 0.9041394689285791], "final_y": [0.11836613088003411, 0.12021728493298278, 0.11591601009257657]}, "mutation_prompt": null}
{"id": "ef2f2704-a331-46c9-bd60-9aa860ae9ca1", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8  # Adjusted social coefficient for enhanced social learning\n        self.temperature = 1000\n        self.cooling_rate = 0.96  # Adjusted cooling rate for more gradual cooling\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.8, 0.05, velocities.shape)  # Optimized adaptive velocity scaling\n            population = population + 0.5 * velocities  # Adjusted position update for better exploration-exploitation balance\n            population = np.clip(population, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            # Perform SA-inspired local search around the global best\n            for i in range(self.population_size):\n                perturbation = np.random.normal(0, 0.8, self.dim) * (self.temperature / 1000)  # Enhanced local search\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # SA acceptance criterion\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Cooling down\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "An optimized hybrid PSO and SA algorithm with improved Gaussian mutation scaling and enhanced local search for better convergence.", "configspace": "", "generation": 31, "fitness": 0.8896859770014148, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.021. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "metadata": {"aucs": [0.8774004347490946, 0.8717506558787423, 0.9199068403764075], "final_y": [0.1226617651953179, 0.12297103772285156, 0.11349140796574475]}, "mutation_prompt": null}
{"id": "df5ab4ee-d4f9-4c71-a51d-d9bafa55c469", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))  # Adaptive Gaussian perturbation\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced Hybrid PSO and SA with adaptive Gaussian perturbation and momentum-based local search for improved convergence.", "configspace": "", "generation": 32, "fitness": 0.8929971806763626, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.015. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a8d4e381-5382-4b0f-ae52-911f42a3a2b0", "metadata": {"aucs": [0.8925551572705557, 0.874745171378269, 0.9116912133802632], "final_y": [0.11686555297364765, 0.11938435817970594, 0.11371668689264369]}, "mutation_prompt": null}
{"id": "9e7aeb38-1f1b-42a3-93f8-77d796249925", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 2.0  # Increased social coefficient\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))  # Adaptive Gaussian perturbation\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.98)  # Slightly faster inertia decay\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Improved HybridPSOSA with increased social influence and adaptive inertia weight adjustment for faster convergence.", "configspace": "", "generation": 33, "fitness": 0.8870117782147808, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.003. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "df5ab4ee-d4f9-4c71-a51d-d9bafa55c469", "metadata": {"aucs": [0.8851595978572082, 0.8847639155784185, 0.8911118212087155], "final_y": [0.12032947026242857, 0.11743284948196453, 0.11726978846844505]}, "mutation_prompt": null}
{"id": "96ef7abd-ae24-4cdd-8ee0-8a2b8a215111", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget))  # Enhanced Gaussian perturbation\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.975)  # Adaptive inertia weight decay\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Improved Hybrid PSO-SA algorithm with adaptive inertia weight decay and enhanced Gaussian perturbation.", "configspace": "", "generation": 34, "fitness": 0.890254170596401, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.017. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "df5ab4ee-d4f9-4c71-a51d-d9bafa55c469", "metadata": {"aucs": [0.8843749525119365, 0.872892381102746, 0.9134951781745201], "final_y": [0.12081267450128985, 0.12604863486029483, 0.11336790363348959]}, "mutation_prompt": null}
{"id": "2522c8be-9d83-46ff-96d5-363f68b83e66", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))  # Adaptive Gaussian perturbation\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.975)  # Slightly adjusted decay\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Slightly adjusted the inertia weight decay to enhance exploration-exploitation balance in the search process.", "configspace": "", "generation": 35, "fitness": 0.8910297300698033, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.017. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "df5ab4ee-d4f9-4c71-a51d-d9bafa55c469", "metadata": {"aucs": [0.888046845831075, 0.8724039842863036, 0.9126383600920316], "final_y": [0.11892563039871962, 0.12624166574771278, 0.11405596146134611]}, "mutation_prompt": null}
{"id": "18405944-a69c-40ec-8dd2-925eb452eb61", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            self.social_coef = 1.8 + 0.2 * (self.budget - evaluations) / self.budget  # Dynamic increase in social coefficient\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))  # Adaptive Gaussian perturbation\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Incorporate a dynamic increase in social coefficient and adaptive local search based on performance to improve global convergence.  ", "configspace": "", "generation": 36, "fitness": 0.883162279821307, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.006. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "df5ab4ee-d4f9-4c71-a51d-d9bafa55c469", "metadata": {"aucs": [0.8821620295040258, 0.8763578319324586, 0.8909669780274367], "final_y": [0.12127260007007346, 0.12066085544520011, 0.11848827246958016]}, "mutation_prompt": null}
{"id": "b1eac875-c97b-442f-9fd1-1c5b1a51a931", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))  # Adaptive Gaussian perturbation\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introducing adaptive inertia weight adjustment to balance exploration and exploitation dynamically.", "configspace": "", "generation": 37, "fitness": 0.8934008174917926, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "df5ab4ee-d4f9-4c71-a51d-d9bafa55c469", "metadata": {"aucs": [0.8931064904171037, 0.8768953475728208, 0.9102006144854531], "final_y": [0.11712841109377037, 0.11748766142747535, 0.11454990628462747]}, "mutation_prompt": null}
{"id": "89db79c2-e351-47d1-a296-81d0f2a248f2", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            adaptive_cognitive_coef = self.cognitive_coef * (1 - evaluations / self.budget) + 0.5\n            adaptive_social_coef = self.social_coef * (evaluations / self.budget) + 0.5\n            cognitive_term = adaptive_cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = adaptive_social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive learning rates for cognitive and social coefficients, enhancing convergence speed and solution quality.", "configspace": "", "generation": 38, "fitness": 0.8693963977991369, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.022. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b1eac875-c97b-442f-9fd1-1c5b1a51a931", "metadata": {"aucs": [0.8407182848370406, 0.874548580451917, 0.8929223281084534], "final_y": [0.1285936380430197, 0.11615323389553156, 0.11390399785807026]}, "mutation_prompt": null}
{"id": "79641bba-d4b0-4e12-97c3-70dc8a30b1b1", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))  # Adaptive Gaussian perturbation\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n            \n            # Introduce dynamic population resizing\n            self.population_size = int(20 * (1 - evaluations / self.budget) + 5)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introducing dynamic population resizing to enhance exploration during early stages and exploitation in later stages.", "configspace": "", "generation": 39, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (23,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (23,10) (20,10) ')", "parent_id": "b1eac875-c97b-442f-9fd1-1c5b1a51a931", "metadata": {}, "mutation_prompt": null}
{"id": "9600315c-456a-419f-9496-de2b5cb3dd7c", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Dynamic population size based on budget and dimensionality\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            # Introduce nonlinear adaptive factors\n            cognitive_term = self.cognitive_coef * (r1 ** 2) * (personal_best_positions - population)\n            social_term = self.social_coef * (r2 ** 2) * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhancing convergence by introducing nonlinear adaptive factors and dynamic population size control to improve exploration-exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.8999518977941768, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.026. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b1eac875-c97b-442f-9fd1-1c5b1a51a931", "metadata": {"aucs": [0.9211271459276424, 0.8638671818275644, 0.9148613656273239], "final_y": [0.11043365953683382, 0.12252026955600193, 0.11306395528434887]}, "mutation_prompt": null}
{"id": "00a663ad-96db-40f8-85df-385f79f47a3c", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * (r1 ** 2) * (personal_best_positions - population)\n            social_term = self.social_coef * (r2 ** 2) * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))\n                adaptive_mutation_rate = 0.1 * (1 - evaluations / self.budget)\n                perturbation = np.random.normal(0, perturbation_strength * adaptive_mutation_rate, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introducing adaptive mutation rate based on iteration count to enhance exploration-exploitation trade-off.", "configspace": "", "generation": 41, "fitness": 0.88215751139367, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.036. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "9600315c-456a-419f-9496-de2b5cb3dd7c", "metadata": {"aucs": [0.897797106001099, 0.8322746590638119, 0.9164007691160992], "final_y": [0.11600647853726509, 0.14260526491451364, 0.11368116731289257]}, "mutation_prompt": null}
{"id": "7339c4f0-ff5a-427f-a1fc-6c30b2bd1211", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.momentum_coef = 0.1  # New line\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * (r1 ** 2) * (personal_best_positions - population)\n            social_term = self.social_coef * (r2 ** 2) * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term + self.momentum_coef * velocities  # Modified line\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                if np.random.rand() < 0.1:  # New condition\n                    candidate = global_best_position + perturbation\n                else:\n                    candidate = global_best_position\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introducing momentum-based velocity updates and adaptive mutation to enhance exploration and convergence.", "configspace": "", "generation": 42, "fitness": 0.8765341318775007, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.026. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9600315c-456a-419f-9496-de2b5cb3dd7c", "metadata": {"aucs": [0.8604913389575821, 0.8555618670316452, 0.913549189643275], "final_y": [0.12924935907254442, 0.11845688971093993, 0.11263543876996662]}, "mutation_prompt": null}
{"id": "ce45413f-0cfd-4fe7-b1af-da6b7a596197", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * (r1 ** 2) * (personal_best_positions - population)\n            # Adaptive social coefficient\n            self.social_coef = 1.5 + 0.5 * np.exp(-evaluations / self.budget)\n            social_term = self.social_coef * (r2 ** 2) * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            # Dynamic cooling schedule\n            self.temperature *= np.exp(-evaluations / (2 * self.budget))\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a dynamic cooling schedule and adaptive social coefficient to enhance convergence speed and accuracy.  ", "configspace": "", "generation": 43, "fitness": 0.893977400610494, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.033. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9600315c-456a-419f-9496-de2b5cb3dd7c", "metadata": {"aucs": [0.927929703868648, 0.8491380470102461, 0.9048644509525879], "final_y": [0.11072449063467205, 0.12978251346483938, 0.1139207656112533]}, "mutation_prompt": null}
{"id": "d580e8a2-79c5-4d29-842c-a7e15a9b1f2a", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n        self.num_swarms = 5  # Introduce multiple swarms\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Dynamic population size based on budget and dimensionality\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        evaluations = 0\n        swarms = [np.random.uniform(lb, ub, (self.population_size, self.dim)) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.population_size, self.dim)) for _ in range(self.num_swarms)]\n        personal_best_positions = [np.copy(swarm) for swarm in swarms]\n        personal_best_scores = [np.array([func(ind) for ind in swarm]) for swarm in swarms]\n        global_best_position = min((pos[np.argmin(scores)] for pos, scores in zip(personal_best_positions, personal_best_scores)), key=lambda x: func(x))\n        global_best_score = func(global_best_position)\n        evaluations += sum(len(scores) for scores in personal_best_scores)\n\n        while evaluations < self.budget:\n            for i, (swarm, velocity) in enumerate(zip(swarms, velocities)):\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                # Adaptive velocity update\n                cognitive_term = self.cognitive_coef * (r1 ** 2) * (personal_best_positions[i] - swarm)\n                social_term = self.social_coef * (r2 ** 2) * (global_best_position - swarm)\n                velocity = self.inertia_weight * velocity + cognitive_term + social_term\n                swarm += 0.5 * velocity\n                swarm = np.clip(swarm, lb, ub)\n                scores = np.array([func(ind) for ind in swarm])\n                evaluations += self.population_size\n\n                better_mask = scores < personal_best_scores[i]\n                personal_best_scores[i][better_mask] = scores[better_mask]\n                personal_best_positions[i][better_mask] = swarm[better_mask]\n                if min(scores) < global_best_score:\n                    global_best_score = min(scores)\n                    global_best_position = swarm[np.argmin(scores)]\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / min(map(np.mean, personal_best_scores))))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Improving exploration and convergence speed by introducing a dynamic multi-swarm strategy and adaptive velocity updates.", "configspace": "", "generation": 44, "fitness": 0.859017519203893, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.030. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "9600315c-456a-419f-9496-de2b5cb3dd7c", "metadata": {"aucs": [0.8186984170198579, 0.8680506433763054, 0.8903034972155156], "final_y": [0.13972666442909987, 0.12874638371797076, 0.11772465724551973]}, "mutation_prompt": null}
{"id": "5b08f748-560f-4d0c-8404-085459d0862c", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * (r1 ** 2) * (personal_best_positions - population)\n            social_term = self.social_coef * (r2 ** 2) * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n            \n            # Adaptive mutation and diversity enhancement\n            if evaluations < 0.8 * self.budget:\n                mutation_prob = 0.1\n                diversity_factor = np.std(population)\n                for i in range(self.population_size):\n                    if np.random.rand() < mutation_prob:\n                        mutation = np.random.normal(0, diversity_factor, self.dim)\n                        population[i] = np.clip(population[i] + mutation, lb, ub)\n                        score = func(population[i])\n                        if score < personal_best_scores[i]:\n                            personal_best_scores[i] = score\n                            personal_best_positions[i] = population[i]\n                        if score < global_best_score:\n                            global_best_score = score\n                            global_best_position = population[i]\n                        evaluations += 1\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introducing adaptive mutation and diversity enhancement techniques to improve exploration and solution quality.", "configspace": "", "generation": 45, "fitness": 0.8938698755279834, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.021. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9600315c-456a-419f-9496-de2b5cb3dd7c", "metadata": {"aucs": [0.8999780763211842, 0.8661755508713409, 0.915455999391425], "final_y": [0.11627519360207139, 0.12066026292500842, 0.11323641115763661]}, "mutation_prompt": null}
{"id": "c789337c-0559-4692-ac26-190c41bf14f1", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive_term = self.cognitive_coef * (r1 ** 2) * (personal_best_positions - population)\n            social_term = self.social_coef * (r2 ** 2) * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape) * np.random.uniform(0.8, 1.2, velocities.shape)  # Introducing stochastic perturbation\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introducing stochastic perturbation in the velocity update to enhance exploration capability while retaining convergence speed.", "configspace": "", "generation": 46, "fitness": 0.8864720204988924, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.020. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9600315c-456a-419f-9496-de2b5cb3dd7c", "metadata": {"aucs": [0.9080387751054786, 0.8595493149012073, 0.8918279714899912], "final_y": [0.11113717576796911, 0.12766742873981218, 0.11828321071270453]}, "mutation_prompt": null}
{"id": "b0a0fd56-7294-4fcc-a337-0278a79e91e5", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Dynamic population size based on budget and dimensionality\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            # Introduce nonlinear adaptive factors\n            cognitive_term = self.cognitive_coef * (r1 ** 2) * (personal_best_positions - population)\n            social_term = self.social_coef * (r2 ** 2) * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.8, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))\n                perturbation = np.random.normal(0, perturbation_strength * 1.2, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introducing adaptive velocity scaling and enhanced perturbation strategy for improved convergence in black box optimization.", "configspace": "", "generation": 47, "fitness": 0.8620834110299603, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.037. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "9600315c-456a-419f-9496-de2b5cb3dd7c", "metadata": {"aucs": [0.8583013697790304, 0.8189610275963648, 0.9089878357144859], "final_y": [0.13192800008292804, 0.14633462388654284, 0.11562532576393236]}, "mutation_prompt": null}
{"id": "313e9010-31b4-434c-9a3b-9b7971abc7f7", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.1 * self.budget))\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Improving convergence by rebalancing exploration-exploitation through adaptive coefficients based on fitness variance.", "configspace": "", "generation": 48, "fitness": 0.9069752344065657, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.026. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9600315c-456a-419f-9496-de2b5cb3dd7c", "metadata": {"aucs": [0.9223995496894206, 0.8709734950014292, 0.9275526585288472], "final_y": [0.11166686053681163, 0.12740060728049518, 0.11339817992155432]}, "mutation_prompt": null}
{"id": "09f667a6-f357-4e5f-9f96-292e8dbeaf3f", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget))  # Enhanced perturbation scaling\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introducing dynamic population resampling and enhanced perturbation scaling to improve exploration and adaptation in HybridPSOSA.", "configspace": "", "generation": 49, "fitness": 0.9102297739314112, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.029. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "313e9010-31b4-434c-9a3b-9b7971abc7f7", "metadata": {"aucs": [0.9296161591528029, 0.8685979350192342, 0.932475227622197], "final_y": [0.11077722530892076, 0.12778501356624583, 0.11233707710359842]}, "mutation_prompt": null}
{"id": "f349d78f-4137-4276-97fd-48d497900ac7", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            improvement_factor = np.abs(global_best_score - np.min(scores)) / (global_best_score + 1e-10)  # New line\n            self.social_coef = 1.8 + 0.5 * np.tanh(improvement_factor)  # New line\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget))  # Enhanced perturbation scaling\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introducing adaptive social coefficient scaling based on global best improvement to enhance convergence in HybridPSOSA.", "configspace": "", "generation": 50, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'scores' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'scores' referenced before assignment\")", "parent_id": "09f667a6-f357-4e5f-9f96-292e8dbeaf3f", "metadata": {}, "mutation_prompt": null}
{"id": "49ad834e-b196-4629-9603-9d59e8219341", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            adaptive_factor = (1 - evaluations/self.budget)  # Adaptive scaling factor\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= adaptive_factor * np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget))  # Enhanced perturbation scaling\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Implementation of adaptive scaling in velocity updates to refine exploration-exploitation balance in HybridPSOSA.", "configspace": "", "generation": 51, "fitness": 0.8912103004577775, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.026. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "09f667a6-f357-4e5f-9f96-292e8dbeaf3f", "metadata": {"aucs": [0.9035094478841026, 0.8553890592784341, 0.9147323942107961], "final_y": [0.11976496453033914, 0.13429394095217306, 0.11829464542229251]}, "mutation_prompt": null}
{"id": "17af30b8-2cb4-4722-9b42-2f324e97773d", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance  # Enhance social coefficient scaling\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget))  # Enhanced perturbation scaling\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance the social coefficient scaling to improve global exploration and convergence in HybridPSOSA.", "configspace": "", "generation": 52, "fitness": 0.9102788426957799, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.029. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "09f667a6-f357-4e5f-9f96-292e8dbeaf3f", "metadata": {"aucs": [0.9297100640023209, 0.8686844557932889, 0.9324420082917301], "final_y": [0.11070137197838847, 0.12764667375292904, 0.11240107705418734]}, "mutation_prompt": null}
{"id": "fadfdd55-1f3e-4b30-b4a8-958ce5b9558a", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n        self.mutation_rate = 0.05  # New mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  \n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance  \n            adaptive_vel_factor = np.exp(-evaluations / (0.1 * self.budget))  # New adaptive velocity factor\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= adaptive_vel_factor\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:  # Apply mutation\n                    mutation = np.random.uniform(lb, ub, self.dim)\n                    candidate = (global_best_position + mutation) / 2\n                else:\n                    perturbation_strength = np.exp(-evaluations / (0.05 * self.budget))\n                    perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                    candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Integrate adaptive velocity update and dynamic mutation for enhanced exploration and exploitation in HybridPSOSA.", "configspace": "", "generation": 53, "fitness": 0.8259754070365748, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.025. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "17af30b8-2cb4-4722-9b42-2f324e97773d", "metadata": {"aucs": [0.7922078068817027, 0.8350935053318962, 0.8506249088961255], "final_y": [0.15796928068063176, 0.1445783466459587, 0.13890476808766916]}, "mutation_prompt": null}
{"id": "5891c1fa-5b63-4c14-85eb-fc0fa1dd1357", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance  # Enhance social coefficient scaling\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget))  # Enhanced perturbation scaling\n                perturbation = np.random.normal(0, perturbation_strength, self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n            self.inertia_weight = self.min_inertia_weight + (0.7 - self.min_inertia_weight) * np.exp(-evaluations / self.budget)  # Dynamic inertia weight adaptation\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a dynamic inertia weight adaptation to accelerate convergence and enhance solution quality.", "configspace": "", "generation": 54, "fitness": 0.9071309030011981, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.032. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "17af30b8-2cb4-4722-9b42-2f324e97773d", "metadata": {"aucs": [0.930279721350774, 0.8617456363275324, 0.9293673513252878], "final_y": [0.11049305571893486, 0.13105667034980217, 0.11354426483246594]}, "mutation_prompt": null}
{"id": "e9f0ed53-7ae1-4851-b2c3-01963190718e", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance  # Enhance social coefficient scaling\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget))  # Enhanced perturbation scaling\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim)  # Adaptive mutation\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99 + 0.01 * (global_best_score / np.mean(personal_best_scores)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive mutation to perturbation step for maintaining diversity and convergence in HybridPSOSA.", "configspace": "", "generation": 55, "fitness": 0.9102889820606244, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "17af30b8-2cb4-4722-9b42-2f324e97773d", "metadata": {"aucs": [0.9215779929579362, 0.8980025227342421, 0.9112864304896946], "final_y": [0.11450622674019595, 0.1192567513735564, 0.11527324356558066]}, "mutation_prompt": null}
{"id": "15107447-173a-416e-9fe1-df861698254d", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget))\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Integrate adaptive inertia weight and dynamic neighborhood search to enhance exploration and exploitation balance in HybridPSOSA.", "configspace": "", "generation": 56, "fitness": 0.911240371831663, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e9f0ed53-7ae1-4851-b2c3-01963190718e", "metadata": {"aucs": [0.9250197287613857, 0.9002266392852715, 0.9084747474483317], "final_y": [0.11219455727305983, 0.11769055828709152, 0.11586589012483817]}, "mutation_prompt": null}
{"id": "70042270-3e2f-48bd-83bb-984c7a06f3d1", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            local_elite = personal_best_positions[np.random.choice(self.population_size)]  # Local elite strategy\n            global_elite = np.mean(personal_best_positions, axis=0)\n            velocities += np.random.rand(self.population_size, self.dim) * (local_elite - global_elite) \n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget))\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by incorporating a Gaussian mutation strategy and updating velocity based on local and global elites.", "configspace": "", "generation": 57, "fitness": 0.8629656939890312, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.035. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "15107447-173a-416e-9fe1-df861698254d", "metadata": {"aucs": [0.8295586241529316, 0.8476079186239798, 0.9117305391901822], "final_y": [0.13277838852572377, 0.13395822625306486, 0.11304575458186972]}, "mutation_prompt": null}
{"id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)  # Changed line\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance exploration by modifying perturbation strength to adapt based on the current global best score.", "configspace": "", "generation": 58, "fitness": 0.9128705354249753, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "15107447-173a-416e-9fe1-df861698254d", "metadata": {"aucs": [0.9189770033349057, 0.9051130266712104, 0.9145215762688095], "final_y": [0.11292141929832711, 0.11712875491377484, 0.11411254594437048]}, "mutation_prompt": null}
{"id": "47ab6def-3189-446f-b108-790ba0e94a5a", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.95  # Changed line\n        self.min_inertia_weight = 0.35  # Changed line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0: \n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.6 + 0.5 * fitness_variance  # Changed line\n            self.social_coef = 1.7 + 0.6 * fitness_variance  # Changed line\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.04 * self.budget)) * (global_best_score + 1)  # Changed line\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Improve convergence by enhancing the exploration-exploitation balance through adaptive coefficients and perturbation control.", "configspace": "", "generation": 59, "fitness": 0.9093110983517816, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9263546266632451, 0.8918960371083983, 0.9096826312837016], "final_y": [0.11167617650265171, 0.12248060729336896, 0.11512667903312801]}, "mutation_prompt": null}
{"id": "00055b08-b669-4b4d-96e0-e0ec1567b6cb", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n        self.stagnation_threshold = 10  # Added line\n        self.mutation_rate = 0.1  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n        stagnation_counter = 0  # Added line\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0 or stagnation_counter > self.stagnation_threshold:  # Modified line\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n                stagnation_counter = 0  # Reset stagnation counter\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n                stagnation_counter = 0  # Reset stagnation counter\n            else:\n                stagnation_counter += 1  # Increment stagnation counter\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim)\n                candidate = global_best_position + perturbation + self.mutation_rate * np.random.randn(self.dim)  # Modified line\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance convergence by integrating adaptive mutation rate and diversity re-initialization based on stagnation detection.", "configspace": "", "generation": 60, "fitness": 0.892538671178623, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.019. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9180529991903863, 0.871766973377827, 0.8877960409676554], "final_y": [0.11483638090424975, 0.12434222970238418, 0.11564711359682589]}, "mutation_prompt": null}
{"id": "cf5fcbe7-fcc2-45ef-802a-d3cc01eb41f1", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 2)  # Changed line\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive random resampling and increased exploration strength for improved convergence.", "configspace": "", "generation": 61, "fitness": 0.8916921149740181, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.023. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.8600278577105867, 0.902530529373739, 0.9125179578377286], "final_y": [0.12916026255294544, 0.11814938118287244, 0.11385448689457445]}, "mutation_prompt": null}
{"id": "0bc08b5a-4608-4cce-8d9b-812b12cb23d3", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            diversity = np.std(population, axis=0).mean()  # Added line\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1) * (1 + diversity)  # Changed line\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Integrate a dynamic mutation strategy based on diversity and adaptivity to enhance exploration and exploitation balance.", "configspace": "", "generation": 62, "fitness": 0.8322319270965561, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.009. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.826007062851837, 0.825754344358037, 0.8449343740797944], "final_y": [0.14146131803637563, 0.14257519948696928, 0.13331387469453793]}, "mutation_prompt": null}
{"id": "8eb1737d-6534-4136-9a59-41bd789fc2f5", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.95  # Adjusted cooling rate\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            diversity = np.mean(np.std(population, axis=0))  # New line for diversity\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1 + diversity)  # Changed line\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate * (1 + diversity)  # Adjust temperature with diversity\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Integrate a self-adaptive mutation mechanism to improve exploration by dynamically adjusting perturbation and temperature based on current solution diversity.", "configspace": "", "generation": 63, "fitness": 0.8807211106376863, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.028. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.8779311164767513, 0.8483419259854292, 0.9158902894508782], "final_y": [0.12119794313803778, 0.13345017144513938, 0.11060822491825872]}, "mutation_prompt": null}
{"id": "695a5a66-9e7c-446e-957d-4566c1139dc1", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)  # Changed line\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            non_linear_scaling = np.sin((evaluations / self.budget) * np.pi / 2)  # Changed line\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * non_linear_scaling))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a non-linear scaling factor for inertia to improve balance between exploration and exploitation.", "configspace": "", "generation": 64, "fitness": 0.9126433868662623, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.006. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9160054199669794, 0.9043991031864217, 0.9175256374453863], "final_y": [0.11467853067604905, 0.11869982781117039, 0.11322606935087809]}, "mutation_prompt": null}
{"id": "1607bd6a-91c7-4a64-b289-7a3e2a0b7893", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)  # Changed line\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / (self.temperature * (1 + evaluations/self.budget))):  # Changed line\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance exploration by adapting perturbation strength and cooling rate dynamically based on the current budget usage.", "configspace": "", "generation": 65, "fitness": 0.9128705354249753, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9189770033349057, 0.9051130266712104, 0.9145215762688095], "final_y": [0.11292141929832711, 0.11712875491377484, 0.11411254594437048]}, "mutation_prompt": null}
{"id": "88a9da03-387d-47be-917e-fa9b0d0a6940", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 4) == 0:  # Dynamic resampling update\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength, self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive mutation and dynamic resampling to improve the convergence speed while maintaining diversity.", "configspace": "", "generation": 66, "fitness": 0.8995927624373179, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.016. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9153087550348997, 0.8772502871309691, 0.9062192451460851], "final_y": [0.11067100157030252, 0.11675362203569595, 0.11449638739997992]}, "mutation_prompt": null}
{"id": "954d4d10-3605-4209-a389-e679c003be9e", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities * (1 - evaluations / self.budget)  # Changed line\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Integrate a dynamic velocity scaling factor to optimize exploration and exploitation balance in the HybridPSOSA algorithm.", "configspace": "", "generation": 67, "fitness": 0.8993278291980297, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.009. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9122123494228477, 0.8952298483855579, 0.8905412897856834], "final_y": [0.11697656357512642, 0.12221962818493226, 0.11850086279128047]}, "mutation_prompt": null}
{"id": "5ba1c598-c600-46d8-b0cf-01ecff1781a8", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                local_diversity = np.std(personal_best_positions, axis=0)\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand() * local_diversity), self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.6 - (0.4 * (evaluations / self.budget)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce local search enhancement using adaptive Gaussian perturbations based on local diversity and adaptive inertia weight scaling for improved convergence.", "configspace": "", "generation": 68, "fitness": 0.8904160089891633, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.015. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9097943318136277, 0.8868904226357466, 0.8745632725181158], "final_y": [0.11437967690977213, 0.12215999867334348, 0.12412232653374833]}, "mutation_prompt": null}
{"id": "c75ee971-7089-4fcb-80d7-10aedf918471", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        # Modified line below to diversify the initial population\n        population = np.random.uniform(lb * 0.9, ub * 1.1, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)  # Changed line\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Improve convergence by modifying initial population diversity with a wider search space factor.", "configspace": "", "generation": 69, "fitness": 0.8752588951588868, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.006. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.8691444044932797, 0.873811770771653, 0.8828205102117278], "final_y": [0.12893308122339853, 0.12716747565163944, 0.12153045977171517]}, "mutation_prompt": null}
{"id": "32ec7f91-548d-4d28-b274-1fc6ae670747", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n                \n                # Gradient-based local refinement\n                gradient_step = 0.01 * (global_best_position - candidate)\n                refined_candidate = candidate - gradient_step\n                refined_candidate = np.clip(refined_candidate, lb, ub)\n                refined_score = func(refined_candidate)\n                evaluations += 1\n                if refined_score < global_best_score:\n                    global_best_position = refined_candidate\n                    global_best_score = refined_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Incorporate adaptive gradient-based local search to refine global best candidates and improve exploitation.", "configspace": "", "generation": 70, "fitness": 0.8920845120266526, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.007. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.899883141223535, 0.8828301567638706, 0.8935402380925521], "final_y": [0.11274039917291012, 0.12014071258952752, 0.11592250017631922]}, "mutation_prompt": null}
{"id": "064de44a-53a9-44f8-ac0a-3158d0484561", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.sin(np.pi * evaluations / self.budget) * (global_best_score + 1)  # Changed line\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Dynamically adjust the perturbation strength using sine function for enhanced exploration near global optima.", "configspace": "", "generation": 71, "fitness": 0.9033531242624512, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.017. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9254509922807475, 0.9004363822850266, 0.8841719982215794], "final_y": [0.11047671975713969, 0.11632583755676817, 0.12028098103099183]}, "mutation_prompt": null}
{"id": "d1c6083f-8930-4c6a-ab09-ce4308542504", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1) \n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive cognitive and social coefficients based on fitness variance to improve convergence.", "configspace": "", "generation": 72, "fitness": 0.9128705354249753, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9189770033349057, 0.9051130266712104, 0.9145215762688095], "final_y": [0.11292141929832711, 0.11712875491377484, 0.11411254594437048]}, "mutation_prompt": null}
{"id": "6079ab77-4cad-4b87-8810-78f6d23c3eca", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            velocity_scaling_factor = 1 + (evaluations / self.budget)  # Changed line\n            population = population + velocity_scaling_factor * velocities  # Changed line\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1) \n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget))) \n\n        return global_best_position", "name": "HybridPSOSA", "description": "Incorporate adaptive velocity scaling to balance exploration and exploitation in dynamic environments.", "configspace": "", "generation": 73, "fitness": 0.876696177705259, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.006. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.8740567358192337, 0.8712127384765977, 0.8848190588199454], "final_y": [0.12388978718757515, 0.12325456128579293, 0.12356793252565768]}, "mutation_prompt": null}
{"id": "f55a8eee-f4db-4234-af6c-e50dc33edf81", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance * (1 - evaluations / self.budget)  # Changed line\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a decay factor in social_coef to balance exploration and exploitation dynamically over time.", "configspace": "", "generation": 74, "fitness": 0.9128699401860413, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9189743778470607, 0.9051130327113854, 0.9145224099996777], "final_y": [0.1129224291719435, 0.11712889188788578, 0.11411244186177416]}, "mutation_prompt": null}
{"id": "4e2ebd86-b9a6-4f7f-bab9-91b4033944f8", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + fitness_variance\n            self.social_coef = 1.8 + 0.5 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            if evaluations % (self.budget // 10) == 0:  # Dynamic mutation\n                mutation_strength = 0.1 * (1 - evaluations / self.budget)\n                population += mutation_strength * np.random.normal(0, 1, population.shape)\n                population = np.clip(population, lb, ub)\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Integrate a dynamically adaptive mutation mechanism inspired by natural evolution to enhance exploration and convergence.", "configspace": "", "generation": 75, "fitness": 0.9128705354249753, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9189770033349057, 0.9051130266712104, 0.9145215762688095], "final_y": [0.11292141929832711, 0.11712875491377484, 0.11411254594437048]}, "mutation_prompt": null}
{"id": "8dcb3ffe-089e-43f5-ab57-b8efd27ab601", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance  # Changed line\n            self.social_coef = 1.8 + 0.3 * fitness_variance  # Changed line\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:  # Diversity injection - Changed line\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))  # Changed line\n                population += random_offsets  # Changed line\n                population = np.clip(population, lb, ub)  # Changed line\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive velocity adjustment and periodic diversity injection to improve solution exploration.", "configspace": "", "generation": 76, "fitness": 0.9129673959244977, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f4ba6580-f0c9-4276-aa48-9debffedb935", "metadata": {"aucs": [0.9189033853021393, 0.9050613782791673, 0.9149374241921866], "final_y": [0.11300099782121187, 0.11716948089960388, 0.11384261205378643]}, "mutation_prompt": null}
{"id": "38ccb453-f316-4a15-a182-a92f424d7849", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96\n        self.min_inertia_weight = 0.4\n        self.adaptive_learning_rate = 0.1  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1 + self.adaptive_learning_rate, velocities.shape)  # Changed line\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n                    self.adaptive_learning_rate *= 1.05  # Changed line\n                else:\n                    self.adaptive_learning_rate *= 0.95  # Changed line\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by introducing adaptive learning rates and dynamic velocity scaling for improved convergence.", "configspace": "", "generation": 77, "fitness": 0.8038159078189503, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.001. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8dcb3ffe-089e-43f5-ab57-b8efd27ab601", "metadata": {"aucs": [0.8058430053770371, 0.8024597525729699, 0.803144965506844], "final_y": [0.1540900937430708, 0.15641680891289145, 0.15613137737123517]}, "mutation_prompt": null}
{"id": "7aa51046-c289-43c4-9023-11d30931e4a2", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance  # Changed line\n            self.social_coef = 1.8 + 0.3 * fitness_variance  # Changed line\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:  # Diversity injection - Changed line\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))  # Changed line\n                population += random_offsets  # Changed line\n                population = np.clip(population, lb, ub)  # Changed line\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1.5 + np.random.rand()), self.dim)  # Changed line\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive velocity perturbation to enhance exploration while preserving convergence stability.", "configspace": "", "generation": 78, "fitness": 0.9046381593350373, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.017. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "8dcb3ffe-089e-43f5-ab57-b8efd27ab601", "metadata": {"aucs": [0.9238105435085606, 0.8831767760329002, 0.9069271584636512], "final_y": [0.11227229824788498, 0.12592713414723966, 0.11651213065370192]}, "mutation_prompt": null}
{"id": "e1de7f24-1097-422e-9e75-a26ca8c0d0ad", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            random_damping = np.random.uniform(0.95, 1.05, velocities.shape)  # Added line\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= random_damping  # Changed line\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance velocity adjustment by incorporating a random damping factor to promote exploration.", "configspace": "", "generation": 79, "fitness": 0.8974328159344133, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8dcb3ffe-089e-43f5-ab57-b8efd27ab601", "metadata": {"aucs": [0.892051936094751, 0.8836066314455787, 0.9166398802629102], "final_y": [0.11337882079005523, 0.12004773960859161, 0.11411746086467445]}, "mutation_prompt": null}
{"id": "2adc6241-0582-42b4-af52-21f72b05f965", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations ** 1.2 / self.budget)))  # Changed line\n            mutation = np.random.uniform(-0.05, 0.05, self.dim)  # Changed line\n            global_best_position = np.clip(global_best_position + mutation, lb, ub)  # Changed line\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Utilize a non-linear adaptive inertia weight and introduce a mutation mechanism to enhance exploration and convergence stability.", "configspace": "", "generation": 80, "fitness": 0.8810292004793157, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.038. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "8dcb3ffe-089e-43f5-ab57-b8efd27ab601", "metadata": {"aucs": [0.8447606994650061, 0.8652099677892803, 0.9331169341836605], "final_y": [0.13813313063667187, 0.13138181561836482, 0.1119229344378937]}, "mutation_prompt": null}
{"id": "50f7de82-659d-4c60-8eab-4507d46207ba", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.sqrt(evaluations / self.budget) * (1 - global_best_score)  # Changed line\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            if evaluations % (self.budget // 4) == 0:  # Changed line\n                for j in range(self.population_size):  # Changed line\n                    velocities[j] += np.random.normal(0, 0.05, self.dim)  # Changed line\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))\n        \n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive mutation and dynamic social interactions to enhance exploration and convergence.", "configspace": "", "generation": 81, "fitness": 0.9001537205332889, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8dcb3ffe-089e-43f5-ab57-b8efd27ab601", "metadata": {"aucs": [0.9195662697734793, 0.900739051969021, 0.8801558398573661], "final_y": [0.11186502306907076, 0.11764839033920504, 0.12253552187987016]}, "mutation_prompt": null}
{"id": "f573b64e-4452-4241-b2c6-013534ccde0f", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance  # Changed line\n            self.social_coef = 1.8 + 0.3 * fitness_variance  # Changed line\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:  # Diversity injection - Changed line\n                random_offsets = np.random.uniform(-0.1 * fitness_variance, 0.1 * fitness_variance, (self.population_size, self.dim))  # Changed line\n                population += random_offsets  # Changed line\n                population = np.clip(population, lb, ub)  # Changed line\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * (evaluations / self.budget)))  # Adaptive inertia weight\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Adaptive mutation scale adjustment based on diversity to enhance exploration while preserving current performance.", "configspace": "", "generation": 82, "fitness": 0.9129673959244977, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8dcb3ffe-089e-43f5-ab57-b8efd27ab601", "metadata": {"aucs": [0.9189033853021393, 0.9050613782791673, 0.9149374241921866], "final_y": [0.11300099782121187, 0.11716948089960388, 0.11384261205378643]}, "mutation_prompt": null}
{"id": "189333d0-8534-4cf4-84c4-7bafc0e14036", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96\n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.05, 0.05, (self.population_size, self.dim))  # Changed line\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.03 * self.budget)) * (global_best_score + 1)  # Changed line\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim)\n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 * (1 - (evaluations / self.budget)))  # Changed line\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Utilize adaptive perturbation scaling and nonlinear inertia adjustment to enhance convergence speed and prevent premature stagnation.", "configspace": "", "generation": 83, "fitness": 0.9112455021793727, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.007. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8dcb3ffe-089e-43f5-ab57-b8efd27ab601", "metadata": {"aucs": [0.9197290052256504, 0.9033537533705764, 0.9106537479418911], "final_y": [0.11447159916675964, 0.11919900167817388, 0.11582426591025652]}, "mutation_prompt": null}
{"id": "0fab3c61-b364-4d95-95c7-6eb1f92df777", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive inertia weight smoothing to enhance convergence stability.", "configspace": "", "generation": 84, "fitness": 0.9152341780309978, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8dcb3ffe-089e-43f5-ab57-b8efd27ab601", "metadata": {"aucs": [0.9285190954600975, 0.9069905438689762, 0.9101928947639196], "final_y": [0.11309434493912063, 0.11964389399339048, 0.1124209547563183]}, "mutation_prompt": null}
{"id": "9e4faecf-8b8f-4a87-9046-4c7b7119b05f", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:\n                selected_indices = np.random.choice(self.population_size, self.population_size // 2, replace=False)\n                elite_candidates = population[selected_indices]\n                elite_differential = np.mean(np.abs(elite_candidates - global_best_position))\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1) * (1 + elite_differential)\n                perturbation = np.random.normal(0, perturbation_strength, self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce elite differential migration and adaptive inertia cooling to enhance exploration and exploitation balance.", "configspace": "", "generation": 85, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'elite_differential' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'elite_differential' referenced before assignment\")", "parent_id": "0fab3c61-b364-4d95-95c7-6eb1f92df777", "metadata": {}, "mutation_prompt": null}
{"id": "3b23f095-1ada-4463-a5e3-204a5849c69c", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * 0.05\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Integrate diversity enhancement via periodic random mutations to improve exploration.", "configspace": "", "generation": 86, "fitness": 0.9161767277714783, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0fab3c61-b364-4d95-95c7-6eb1f92df777", "metadata": {"aucs": [0.9297238503910564, 0.9078038758064108, 0.9110024571169676], "final_y": [0.11170019075441551, 0.11860638122377531, 0.11148457279686841]}, "mutation_prompt": null}
{"id": "3522a0e5-22c9-4935-b0de-5eb72c9aed02", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation * np.sin(evaluations/self.budget * np.pi)  # Time-varying perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * 0.05\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce time-varying random perturbations to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 87, "fitness": 0.9081664368190675, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3b23f095-1ada-4463-a5e3-204a5849c69c", "metadata": {"aucs": [0.9213612457755427, 0.9071331743504873, 0.8960048903311724], "final_y": [0.11303770011368197, 0.11699281694734365, 0.11503418752844752]}, "mutation_prompt": null}
{"id": "558adcc6-d7a4-4bfc-9769-399d531b2b76", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= (self.cooling_rate + 0.01 * np.random.rand())  # Slight randomness in cooling rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * (0.05 + 0.01 * np.random.rand())  # Slight randomness in mutation strength\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive cooling and mutation strategies for enhanced convergence in HybridPSOSA.", "configspace": "", "generation": 88, "fitness": 0.8766660047500049, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.031. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "3b23f095-1ada-4463-a5e3-204a5849c69c", "metadata": {"aucs": [0.8697580365206494, 0.8431791319610717, 0.9170608457682934], "final_y": [0.12368950826720115, 0.13163897933687085, 0.11452215214731465]}, "mutation_prompt": null}
{"id": "d7593700-cb1c-4f75-8d96-16d406d4e04f", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * 0.05 * (1 + fitness_variance)  # Adaptive mutation rate\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive mutation rate based on fitness variance to enhance diversity.", "configspace": "", "generation": 89, "fitness": 0.9161767277714826, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3b23f095-1ada-4463-a5e3-204a5849c69c", "metadata": {"aucs": [0.9297238503910591, 0.9078038758064148, 0.9110024571169737], "final_y": [0.11170019075441195, 0.11860638122376743, 0.11148457279686064]}, "mutation_prompt": null}
{"id": "396c73de-aa1a-4959-93ec-06e2b1dbeb1e", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n                self.cognitive_coef += 0.05  # Slightly increase coefficients\n                self.social_coef += 0.05\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * 0.05 * (1 + fitness_variance)  # Adaptive mutation rate\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance exploitation by increasing cognitive and social coefficients slightly when a candidate improves the global best.", "configspace": "", "generation": 90, "fitness": 0.9161767277714826, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d7593700-cb1c-4f75-8d96-16d406d4e04f", "metadata": {"aucs": [0.9297238503910591, 0.9078038758064148, 0.9110024571169737], "final_y": [0.11170019075441195, 0.11860638122376743, 0.11148457279686064]}, "mutation_prompt": null}
{"id": "37fcebf2-ebae-44e6-9710-33a7a36fa7cb", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * 0.05 * (1 + fitness_variance)  # Adaptive mutation rate\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                mutation_probability = np.clip(0.05 * fitness_variance, 0, 1) # New line for fitness-based mutation probability\n                mutations *= (np.random.rand(*mutations.shape) < mutation_probability) # New line for fitness-based mutation probability\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a fitness-based mutation probability to enhance exploration during stagnation.", "configspace": "", "generation": 91, "fitness": 0.9152330559315246, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d7593700-cb1c-4f75-8d96-16d406d4e04f", "metadata": {"aucs": [0.9285161255131145, 0.9069894258384413, 0.910193616443018], "final_y": [0.11309845378772154, 0.11964608384949238, 0.112416845918754]}, "mutation_prompt": null}
{"id": "7069cbf9-5401-40b6-9809-f71b034099d7", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            progress_ratio = evaluations / self.budget\n            self.cognitive_coef = 1.5 + 0.5 * (1 - progress_ratio)  # Adjust cognitive coefficient\n            self.social_coef = 1.8 + 0.5 * progress_ratio  # Adjust social coefficient\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * 0.05 * (1 + fitness_variance)  # Adaptive mutation rate\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce dynamic adjustment of cognitive and social coefficients based on iteration progress to improve exploration-exploitation balance.", "configspace": "", "generation": 92, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'fitness_variance' is not defined\").", "error": "NameError(\"name 'fitness_variance' is not defined\")", "parent_id": "d7593700-cb1c-4f75-8d96-16d406d4e04f", "metadata": {}, "mutation_prompt": null}
{"id": "4ff9b8e0-04f3-41aa-8e82-6c6cbdc5cf09", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        restart_threshold = 0.15 * self.budget  \n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  \n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 2) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n                \n            if evaluations % (self.budget // 10) == 0 and fitness_variance < 1e-5:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  \n\n            if evaluations % (self.budget // 7) == 0:  \n                mutation_strength = (ub - lb) * 0.05 * (1 + fitness_variance)  \n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a dynamic restart mechanism and more sophisticated local search to boost solution exploration and exploitation.", "configspace": "", "generation": 93, "fitness": 0.9132461259367143, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d7593700-cb1c-4f75-8d96-16d406d4e04f", "metadata": {"aucs": [0.9272677712213167, 0.9056467123873879, 0.9068238942014382], "final_y": [0.11372390251988163, 0.12002149213736313, 0.1140921355247807]}, "mutation_prompt": null}
{"id": "e7215d2a-ca7f-4a5d-9849-639773b56350", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.uniform(0.8, 1.0, velocities.shape)  # Adjusted to reduce randomness\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            for i in range(self.population_size):\n                local_search_strength = 0.1 * (ub - lb) * (0.5 ** (evaluations / self.budget))\n                local_candidate = global_best_position + np.random.uniform(-local_search_strength, local_search_strength, self.dim)\n                local_candidate = np.clip(local_candidate, lb, ub)\n                local_score = func(local_candidate)\n                evaluations += 1\n                if local_score < global_best_score:\n                    global_best_position = local_candidate\n                    global_best_score = local_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))\n\n            if evaluations % (self.budget // 7) == 0:\n                mutation_strength = (ub - lb) * 0.02 * (1 + fitness_variance)  # Adjusted mutation rate\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Integrate local search with adaptive velocity and mutation rate to enhance exploitation and exploration balance.", "configspace": "", "generation": 94, "fitness": 0.9004980839946012, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.033. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d7593700-cb1c-4f75-8d96-16d406d4e04f", "metadata": {"aucs": [0.8558355995653345, 0.9133234491152717, 0.9323352033031971], "final_y": [0.13249013222118144, 0.11623062633465531, 0.11099952755249065]}, "mutation_prompt": null}
{"id": "b4972f4a-4ae0-4f22-875f-91c298cefbe4", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * 0.05 * (1 + fitness_variance) * np.sqrt(fitness_variance)  # Refined adaptive mutation rate\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Refine adaptive mutation strategy by introducing fitness variance scaling to better balance exploration and exploitation.", "configspace": "", "generation": 95, "fitness": 0.9152362496806932, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d7593700-cb1c-4f75-8d96-16d406d4e04f", "metadata": {"aucs": [0.9285213544098977, 0.9069916516356757, 0.9101957429965059], "final_y": [0.11309034106628779, 0.11964202706271554, 0.11241703509812695]}, "mutation_prompt": null}
{"id": "8eeb7a10-2e4e-4095-add5-fa07045eaa46", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n        \n        # Differential Evolution parameters\n        self.de_mutation_factor = 0.8\n        self.de_crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                for i in range(self.population_size):\n                    a, b, c = population[np.random.choice(self.population_size, 3, replace=False)]\n                    mutant = a + self.de_mutation_factor * (b - c)\n                    mutant = np.clip(mutant, lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.de_crossover_rate\n                    trial = np.where(cross_points, mutant, population[i])\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < scores[i]:\n                        population[i] = trial\n                        scores[i] = trial_score\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * 0.05 * (1 + fitness_variance)  # Adaptive mutation rate\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a differential evolution component to enhance exploration and exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.9161767277714826, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d7593700-cb1c-4f75-8d96-16d406d4e04f", "metadata": {"aucs": [0.9297238503910591, 0.9078038758064148, 0.9110024571169737], "final_y": [0.11170019075441195, 0.11860638122376743, 0.11148457279686064]}, "mutation_prompt": null}
{"id": "6abe11cd-711c-40ed-b7d6-e013e7b8757f", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * 0.05 * (1 + fitness_variance)  \n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                proximity = np.linalg.norm(population - global_best_position, axis=1) / self.dim\n                mutations *= proximity[:, np.newaxis]\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance exploitation by introducing non-uniform mutation based on proximity to global best.", "configspace": "", "generation": 97, "fitness": 0.9152663372947277, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d7593700-cb1c-4f75-8d96-16d406d4e04f", "metadata": {"aucs": [0.9285408739754589, 0.9070568990754899, 0.9102012388332342], "final_y": [0.11306801771937447, 0.11956425007556193, 0.11240966987962442]}, "mutation_prompt": null}
{"id": "17e2b1e8-87de-414d-8119-63298faa1f81", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef = 1.5 + 0.1 * fitness_variance\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.6 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * 0.05 * (1 + fitness_variance)  # Adaptive mutation rate\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Refine inertia weight formula to enhance exploration-exploitation balance.", "configspace": "", "generation": 98, "fitness": 0.8972682780518042, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.021. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d7593700-cb1c-4f75-8d96-16d406d4e04f", "metadata": {"aucs": [0.9157782358598494, 0.868601550836422, 0.9074250474591414], "final_y": [0.11492754773783076, 0.12588456856977448, 0.11708242435069638]}, "mutation_prompt": null}
{"id": "4440e997-766d-42c2-882f-868258edb088", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.8\n        self.temperature = 1000\n        self.cooling_rate = 0.96 \n        self.min_inertia_weight = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population_size = int(max(5, self.budget / (10 * self.dim)))\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 5) == 0:  # Dynamic population resampling\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            fitness_variance = np.var(personal_best_scores)\n            self.cognitive_coef *= np.exp(-evaluations / (0.1 * self.budget))\n            self.social_coef = 1.8 + 0.3 * fitness_variance\n            cognitive_term = self.cognitive_coef * r1 * (personal_best_positions - population)\n            social_term = self.social_coef * r2 * (global_best_position - population)\n            velocities = self.inertia_weight * velocities + cognitive_term + social_term\n            velocities *= np.random.normal(0.9, 0.1, velocities.shape)\n            population = population + 0.5 * velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = population[better_mask]\n            if min(scores) < global_best_score:\n                global_best_score = min(scores)\n                global_best_position = population[np.argmin(scores)]\n\n            if evaluations % (self.budget // 3) == 0:\n                random_offsets = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n                population += random_offsets\n                population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                perturbation_strength = np.exp(-evaluations / (0.05 * self.budget)) * (global_best_score + 1)\n                perturbation = np.random.normal(0, perturbation_strength * (1 + np.random.rand()), self.dim) \n                candidate = global_best_position + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if candidate_score < global_best_score or np.random.rand() < np.exp((global_best_score - candidate_score) / self.temperature):\n                    global_best_position = candidate\n                    global_best_score = candidate_score\n\n            self.temperature *= self.cooling_rate\n            self.inertia_weight = max(self.min_inertia_weight, 0.9 - (0.5 * ((evaluations / self.budget) ** 0.5)))  # Adaptive inertia weight with smoothing\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic random mutation for diversity\n                mutation_strength = (ub - lb) * 0.05 * (1 + fitness_variance)  # Adaptive mutation rate\n                mutations = np.random.uniform(-mutation_strength, mutation_strength, population.shape)\n                population += mutations\n                population = np.clip(population, lb, ub)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance convergence by implementing an adaptive strategy for dynamically adjusting cognitive and social coefficients using exponential decay.", "configspace": "", "generation": 99, "fitness": 0.9029565035115601, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.017. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d7593700-cb1c-4f75-8d96-16d406d4e04f", "metadata": {"aucs": [0.9224569467031788, 0.9058475246277498, 0.8805650392037516], "final_y": [0.11382047390411076, 0.11647804347347124, 0.12119653279809084]}, "mutation_prompt": null}
